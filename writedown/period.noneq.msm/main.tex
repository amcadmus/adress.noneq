\documentclass[aps, pre, preprint,unsortedaddress,a4paper,onecolumn]{revtex4-1}
% \documentclass[acs, jctcce, a4paper,preprint,unsortedaddress,onecolumn]{revtex4-1}
% \documentclass[aps,pre,twocolumn,unsortedaddress]{revtex4-1}
% \documentclass[aps,jcp,groupedaddress,twocolumn,unsortedaddress]{revtex4}

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage[dvips]{graphicx}
\usepackage{color}
\usepackage{tabularx}
\usepackage{algorithm}
\usepackage{algorithmic}

\makeatletter
\makeatother

\newcommand{\recheck}[1]{{\color{red} #1}}
\newcommand{\redc}[1]{{\color{red} #1}}
\newcommand{\bluec}[1]{{\color{red} #1}}
\newcommand{\greenc}[1]{{\color{green} #1}}
\newcommand{\vect}[1]{\textbf{\textit{#1}}}
\newcommand{\dd}[1]{\textsf{#1}}
\newcommand{\fwd}[0]{\textrm{fwd}}
\newcommand{\bwd}[0]{\textrm{bwd}}
\newcommand{\period}[0]{T_{\textrm{P}}}
\newcommand{\ml}[0]{\mathcal {L}}
\newcommand{\mo}[0]{\mathcal {O}}
\newcommand{\mbp}[0]{\mathbb {P}}
\newcommand{\mc}[0]{\mathcal {C}}
\newcommand{\dt}[0]{\Delta t}

\newcommand{\confaa}[0]{{\alpha_{\textrm{R}}}}
\newcommand{\confab}[0]{{\alpha_{\textrm{R}}'}}
\newcommand{\confba}[0]{{\textrm{C}7_{\textrm{eq}}}}
\newcommand{\confbb}[0]{{\textrm{C}5}}
\newcommand{\confc}[0]{{\alpha_{\textrm{L}}}}



\begin{document}

\title{Building Markov State Model for a Periodically Driven Non-Equilibrium System}
\author{Han Wang}
\email{han.wang@fu-berlin.de}
\affiliation{Zuse Institut Berlin, Germany}
\author{Christof Sch\"utte}
\email{Christof.Schuette@fu-berlin.de}
\affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}
\affiliation{Zuse Institut Berlin, Germany}
   
\begin{abstract}
\end{abstract}

\maketitle

\section{Introduction}
Non-equilibrium, especically periodically driven system. Interesting.

MSM tools for analyzing, provide profund understanding.

Current achievement of MSM in equilibrium cases.

Importance: first application of MSM in a non-equilibrium system.

\section{Discretization of the non-equilibrium molecular dynamics}

We denote the phase space by $\Omega$, and the variable by $\vect
x$. The time-dependent probability distribution on the phase space is
denoted by $\rho(\vect x, t)$. The dynamics of the system is governed
by
\begin{align}
  \label{eqn:tmp1}
  \frac{\partial \rho(\vect x, t)}{\partial t} = \ml(t) \rho(\vect x,t),
\end{align}
where the generator $\ml(t)$ is time-dependent and assumed to be
periodic, i.e.~$\ml(t) = \ml(t+T)$, with period denoted by $T$.  Now
we discretize the phase space $\Omega$ into finite number of disjoint
sets $\{ S_1, \cdots, S_n\}$, which satisfy $\Omega = \cup_i S_i$,
$S_j\cap S_j = \emptyset,\ \forall i\neq j$.
Now the original dynamics of the system can be discretized to a time-dependent
Markov jump process:
\begin{align}
  \label{eqn:tmp2}
  \frac{d\vect p(t)}{dt} = \vect M(t)\cdot \vect p(t)
\end{align}
where
\begin{align}
  \vect p(t) = (p_1(t), \cdots, p_n(t))^T, \quad \textrm{with}\ p_i(t) = \int_{S_i} \rho(\vect x,t)d\vect x,
\end{align}
and the generator is approximated by finite difference scheme:
\begin{align}
  \label{eqn:tmp4}
  M_{ij}(t) \approx \frac{1}{\tau} \,[\, \mbp (\vect x_{t+\tau} \in S_j \vert \vect x_{t} \in S_i) - \delta_{ij} \,]
\end{align}
From Eqn.~\eqref{eqn:tmp1} to Eqn.~\eqref{eqn:tmp2} involves several
approximations:
\begin{enumerate}
\item Eqn.~\eqref{eqn:tmp2} assumes Markovianity, which is not
  necessarily true for a reduce dynamics $\vect p(t)$.
\item Numerical error from the finite difference introduced in
  Eqn.~\eqref{eqn:tmp4}. The lag-time $\tau$ should not be too large
  to control the finite difference error, and at the same time should
  not be too small, because otherwise the statistical error would be
  large, and the Markovianity would be disturbed.
\item Although the original dynamics defined by generator $\ml(t)$ is
  periodic, the reduced one defined by $\vect M(t)$ is not necessary
  periodic, i.e.~$\vect M(t) \neq \vect M(t+T)$ in general.  In the
  simulation of biomolecules, it is reasonable, in most cases to
  assume a time-scale separation in the system. For example, the
  conformational change of the molecules is much faster than the
  covalent bond vibrations. Therefore, if the discretion $\{ S_1,
  \cdots, S_n\}$ properly captures the slow dynamics of interest, in
  the sense that within the lag-time $\tau$, the system is fully
  relaxed to a local equilibrium in the set $S_i$, then it is clear
  that the reduce system is periodic. It suggests that the lag-time
  should be right in the spectrum gap: it is shorter than the dominant
  implied timescale, and longer than the fast-relaxing time-scales.
\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{fig/confs/fig-begin-1.eps}
  \caption{The Ramachandran plot presents the main conformations of the alanine dipeptide.}
  \label{fig:tmp1}
\end{figure}

At this stage we do have any analytical result regarding the quality
of approximating Eqn.~\eqref{eqn:tmp1} by
Eqn.~\eqref{eqn:tmp2}. However, it would be useful to do some
numerical experiments. We have studied the alanine dipeptide system
under oscillatory EF, which was studied by
Ref.~\cite{wang2014exploring}. We use the two dihedral angles $\phi$
and $\psi$ as slow variables. The definition of the conformations
$\confaa$, $\confab$, $\confba$, $\confbb$ and $\confc$ are presented
by Fig.~\ref{fig:tmp1}.  We are interested in the time-dependent
probability of the conformations. In Fig.~\ref{fig:tmp2}, the brute
force molecular dynamics simulation result
(i.e.~Eqn.~\eqref{eqn:tmp1}) is compared with different discretization
methods, which give different generator in Eqn.~\eqref{eqn:tmp2}. For
clarity, only the probability of conformation $\confc$ is plotted.  In
the figure, ``5 sets'' means the $\phi$-$\psi$ space is discretized by
5 sets as shown in Fig.~\ref{fig:tmp1}, ``Uni. $M=$'' stands for the
uniform discretization on $\phi$-$\psi$ space, and $M$ denotes the
number of bins on both $\phi$ and $\psi$ directions.  Both $M=10$ and
20 methods present very good accuracy.  Please notice that for $M=10$,
for example, the number of discretized sets is $n=M^2=100$.  The
lag-time in all cases is chosen to be $\tau = 0.5$~ps. A test with
$\tau = 1.0$~ps shows good consistency with $\tau = 0.5$~ps.
The generator
$\vect M(t)$ is assumed to be periodic, and is estimated from the
trajectories from $t=300$ to 1000~ps.

The phenomena presented by Fig.~\ref{fig:tmp2} is very similar to the
equilibrium MSM: the quality of the MSM depends on how accurate the
eigenfunctions are approximated by the discretization. The ``5 sets''
method achieve better accuracy than the uniform $M=5$ method by using
much less DOFs, because it captures the positive and negative signs of
the eigenfunctions. With larger $M$ the discretization error of the
eigenfunctions becomes smaller, so the accuracy of the MSM is improved.

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{fig/t040/fig-cg-prob.eps}  
  \caption{The time-dependent probability of conformation
    $\confc$. The brute force MD simulation is compared with different
    discretization methods.}
  \label{fig:tmp2}
\end{figure}



\section{Floquet theory}

The Floquet theory states that for a periodic system
Eqn.~\ref{eqn:tmp2}, the solution can be written as
\begin{align}
  \label{eqn:tmp5}
  \vect p(t)  = \vect Q(t) e^{t\vect B} \vect p(0)
\end{align}
where $\vect Q(t)$ is periodic and $\vect B$ is a constant matrix.  To
analyze the spectrum, it is not difficult to infer the implied
timescales, on which the system relaxes to the periodic steady states
defined by $\vect Q(t)$.
Assume that the fundamental solution to Eqn.~\ref{eqn:tmp2} is denoted by $\boldsymbol \Phi(t)$, then
the matrix $\vect B$ can be expressed by
\begin{align}
  e^{T\vect B} = \boldsymbol \Phi^{-1}(0)\cdot \boldsymbol \Phi(T)
\end{align}
It is fully justified by choosing $ \boldsymbol \Phi(0) = I$, then
$e^{T\vect B}$ is estimated by evolving the fundamental solutions by
one period.  Calculating the eigenvalues of $e^{T\vect B}$ reveals the
implied timescales on which the non-equilibrium dynamics converges to
the periodic steady state. However, it can only resolve the processes that are longer than the period $T$.
The largest non-trivial timescales is given in table
Tab.~\ref{tab:tmp1}, which corresponds very well to the dynamics of the  $\confc$ probability.


\begin{table}
  \centering
  \caption{The first four non-trivial timescales calculated from $e^{T\vect B}$. The unit of time in the table is ps.
    $\tau$ is the lag time used to calculate the generator~\eqref{eqn:tmp4}. $[T_0,T_1]$ is the time interval,
    in which the generator is estimated from the MD trajectories. The 5th eigenvalue of uniform decomposition with $\tau=8.0$~ps is not real, so
    the corresponding timescale is not calculated.
  }
  \begin{tabular*}{0.9\textwidth}{@{\extracolsep{\fill}}c ccc rrrr}\hline\hline
    Method  &  $M$ & $\tau$ & $[T_0,T_1]$ &   $t_2$ &   $t_3$ &   $t_4$ &   $t_5$  \\\hline
    5 sets  & --   & 0.5    & $[300,1000]$    &  72.4 & 17.8 &  2.1 & 2.8    \\
    Uniform & $05$ & 0.5    & $[300,1000]$    &  53.6 & 17.4 &  9.4 & 2.8    \\
    Uniform & $10$ & 0.5    & $[300,1000]$    & 107.2 & 27.0 & 16.4 & 3.6    \\
    Uniform & $20$ & 0.5    & $[300,1000]$    & 118.6 & 30.4 & 20.3 & 4.3    \\
    Uniform & $30$ & 0.5    & $[300,1000]$    & 120.6 & 31.1 & 20.9 & 4.4    \\\hline
    Uniform & $20$ & 0.5    & $[0,40]$    & 156.5 & 34.4 & 20.7 & 4.4    \\
    Uniform & $20$ & 0.5    & $[0,80]$    & 133.8 & 32.8 & 20.4 & 4.4    \\
    Uniform & $20$ & 0.5    & $[0,120]$   & 127.5 & 32.0 & 20.3 & 4.3    \\
    Uniform & $20$ & 0.5    & $[0,200]$   & 122.0 & 31.3 & 20.3 & 4.3    \\
    Uniform & $20$ & 0.5    & $[0,320]$   & 120.4 & 31.0 & 20.3 & 4.3    \\\hline
    Uniform & $20$ & 1.0    & $[300,1000]$    & 119.8 & 30.5 & 21.7 & 4.9   \\
    Uniform & $20$ & 2.0    & $[300,1000]$    & 117.8 & 29.2 & 21.5 & 5.3   \\
    Uniform & $20$ & 4.0    & $[300,1000]$    & 114.2 & 27.0 & 20.2 & 4.8   \\
    Uniform & $20$ & 8.0    & $[300,1000]$    & 110.6 & 25.0 & 18.1 & --   \\
    \hline\hline
  \end{tabular*}
  \label{tab:tmp1}
\end{table}


\section{Discussions}
\subsection{The periodicity of the reduced dynamics}


As discussed before, if the reduced dynamics captures the slow
dynamics of interest, then the reduced dynamics is also periodic,
which implies that the generator $M(t)$ can be estimated from any time
interval by Eq.~\eqref{eqn:tmp4}. In practice, the reduced dynamics
may not be perfectly periodic. The generator calculated from
different time intervals can be used to test the periodicity of the
reduced dynamics. The results are shown in Tab.~\ref{tab:tmp1} and
Fig.~\ref{fig:tmp2}.  The dependency with respect to the time
interval, in which the generator is calculated, indicates the reduced
dynamics is not perfectly periodic. The reduced dynamics from $[0,40]$
reproduces the best probability in interval $[0,40]$, and worst in the
steady state. Moreover, the leading non-trivial timescale is also off
(see Tab.~\ref{tab:tmp1}), while the accuracy of the second and third
non-trivial timescales are better, because they are comparable to the
period, 40~ps, in which the dynamics is relaxed. The reduced dynamics
from $[300,1000]$ reproduces the best steady state probability, while
worst in reproducing the initial relaxation process. The reduced
dynamics from $[0,320]$ is indistinguishable from the one from
$[300,1000]$, which implies that in practice, one only have to
simulation relatively short non-equilibrium trajectories (that are
almost relaxed), and compute the generator from it to build the reduced dynamics. \redc{This saves a great
amount of computational resources comparing with calculating the
reduced dynamics only from steady state trajectories.}


\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{fig/t040/fig-cg-prob-range.eps}  
  \caption{The time-dependent probability of conformation
    $\confc$. The brute force MD simulation is compared with reduced
    dynamics, the transition matrix of which are calculated from
    different ranges. The red shadow region is the statistical uncertainty of the brute force MD simulation.
    The inserts show the zoom-ined probability at the relaxation stage $[0,120 ]~\textrm{ps}$ and at the steady state $[800,880 ]~\textrm{ps}$.}
  \label{fig:tmp2}
\end{figure}

\subsection{The choice of lag time $\tau$}
Table~\ref{tab:tmp1} shows a clear trend of worse accuracy with
increased $\tau$, however, the timescales are not very sensitive to
the choice of lag time $\tau$.

\section{To do}

\begin{itemize}
\item Theoretical analysis of the accuracy of the discretization, a
generalization of the equilibrium case. the numerical results indicate
a very close link. The perodicity is very nice, if the generator is
``continuous'', then it should be uniformly continuous, then it should
be possible to develop estimates that are similar to the equilibrium
case.
\item More tests on the effect of choosing different lag-time $\tau$ (0.5 and 1.0~ps are done).
\item More theoretical consideration on the Floquet theory, what is the
explict form of matrix $\vect B$, and does it has any nice properties,
such as self-joint.
\end{itemize}


\section{Numerical results}
\subsection{Steady state distribution}
\begin{figure}
  \centering  
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-dist.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-dist-msm.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-floquet-vec-1.eps}
  \caption{The steady state distribution calculated by brute force non-equilibrium comparing with MSM.}
  \label{fig:num-1}
\end{figure}
\begin{figure}
  \centering  
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-floquet-vec-2-simple.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-floquet-vec-3-simple.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-floquet-vec-4-simple.eps}
  \caption{The steady state distribution calculated by brute force non-equilibrium comparing with MSM.}
  \label{fig:num-2}
\end{figure}

\subsection{Committors}
\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-msm-1.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-msm-1.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-msm-1.eps}
  \caption{The forward and backward committors computed by MSM is compared with those computed by brute force non-equilibrium simulations.}  
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-msm-2.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-msm-2.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-msm-2.eps}
  \caption{The forward and backward committors computed by MSM is compared with those computed by brute force non-equilibrium simulations.}  
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-msm-3.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-msm-3.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-msm-3.eps}
  \caption{The forward and backward committors computed by MSM is compared with those computed by brute force non-equilibrium simulations.}  
  \label{fig:num-2}
\end{figure}


\section{Reversibility of the original dynamics}

Now we assume the overdamped dynamics
\begin{align}\label{eqn:tmp7}
  dx_t = -\nabla_x V(x_t,t) dt + \sigma dw_t
\end{align}
where $V$ is the time-dependent and $T$-periodic potential. For simplicity we denote the force by $F(x_t,t) = -\nabla_x V(x_t, t)$. $dw_t$ is
the standard Wiener process.
According to Girsanov, we have
\begin{align}
  \label{eq:tmp8}
  \frac{dp[x_t]}{dw[x_t]}  =
  \exp \bigg\{
  \frac 1{\sigma^2}\int_0^T F(x_t,t) dx_t -
  \frac1{2\sigma^2}\int_0^T F^2(x_t,t) dt
  \bigg\}
\end{align}
where $dp$ is the probability measure of trajectory $x_t$, while $dw$ is the
probability measure of the standard Wiener process $dx_t = \sigma dw_t$.
Assuming a discretization of the
stochastic process at time $0 < t_1 < t_2 < \cdots < t_N = T$, where
$t_i = iT / N$. We denote $x_i = x_{t_i}$, and $w_i = w_{t_i}$, then we have,
in the sense of Ito,
\begin{align}\label{eq:tmp9}
  \frac{dp[x_t]}{dw[x_t]}  \approx
  \exp\bigg\{\frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{i},t_{i})(x_{i+1} - x_i) -\frac1{2\sigma^2}\sum_{i=0}^{N-1}F^2(x_i,t_i)\dt\bigg\} 
\end{align}
Now, consider a conjugate trajectory $x^\dagger_t = x_{T-t}$ that starts at $x_T$, ends at $x_0$. The conjugate dynamics is driven by  $F^\dagger(x^\dagger_t,t) = F(x^\dagger_t, T-t)$.
Writting the Girsanov for the conjugate dynamics
\begin{align}\label{eq:dagger-0}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\ \nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},T - t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, T-t_i)]^2\dt\bigg\} \\\nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{N-i},t_{N-i})(x_{N-i-1} - x_{N-i}) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x_{N-i},t_{N-i})]^2\dt\bigg\} \\
  = \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=N}^{1} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=N}^{1}F^2(x_i,t_i)\dt\bigg\}
\end{align}
% Therefore,
% \begin{align}\nonumber
%   \frac{dp[x^\dagger_t]}{dw[x^\dagger_t]}  =
%   \,&
%   \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]} \\\nonumber
%   \approx\,&
%   \exp\bigg\{
%   \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
%   \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\\nonumber
% \end{align}
Since it is obvious that $dw[x^\dagger_t] / dw[x_t] = 1$,
\begin{align}
  \label{eq:tmp10}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x_t]}
  \approx \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=1}^{N} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=1}^{N}F^2(x_i,t_i)\dt\bigg\}
\end{align}
The difference between the single trajectory probabilities is
\begin{align}\label{eqn:tmp12}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
  -\frac1{\sigma^2}\sum_{i=1}^{N-1}
  \bigg[
  F(x_i,t_i)(x_{i+1} - x_{i}) + F(x_i,t_i)(x_{i} - x_{i-1})
  \bigg]
  \bigg\}
\end{align}
Assuming the smoothness of the external perturbation, consider the differentiation:
\begin{align}\nonumber
  F(x_{i},t_{i}) - F(x_{i-1},t_{i-1}) =
  &\,
  F(x_{i},t_{i}) - F(x_{i-1},t_{i}) + F(x_{i-1},t_{i}) -  F(x_{i-1},t_{i-1})\\\nonumber
  =&\,
  \nabla_x F(x_{i-1},t_{i})(x_i - x_{i-1}) + \mo(\dt) \\\label{eqn:tmp13}
  =&\,
  \nabla_x F(x_{i-1},t_{i-1})(x_i - x_{i-1}) + \mo(\dt)
\end{align}
The second order expansion w.r.t.~$x_i - x_{i-1}$ is of order $\dt$, so it is absorbed into $ \mo(\dt)$.
Then the \eqref{eqn:tmp12} becomes
\begin{align}\label{eqn:tmp14}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\sum_{i=0}^{N-1} F(x_i,t_i)(x_{i+1} - x_{i}) 
 -\frac1{\sigma^2}\sum_{i=0}^{N-1}\nabla_xF(x_i,t_i)(x_{i+1} - x_{i})^2
 \bigg\}
\end{align}
Using the identity
$  dt = (dw_t)^2 = {\sigma^{-2}} dx_t^2$,
Eq.~\eqref{eqn:tmp14} is written in the integral form
\begin{align}\label{eqn:tmp14-0}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\int_0^T F(x_t,t) dx_t
 -\int_0^T\nabla_xF(x_t,t)dt
 \bigg\}  
\end{align}
One would not have the second integral on the exponent if the first integral of the exponent were defined in the sense of Stratonovich.

We notice that
\begin{align}\nonumber
  dV(x, t) = &\, \frac{\partial V}{\partial x} dx + \frac{\partial V}{\partial t} dt\\\nonumber
  =&\,
  \frac12 \sigma^2 \nabla^2_x V dt +  \nabla V dx_t + \frac{\partial V}{\partial t} dt \\
  =&\,
  -\frac12 \sigma^2 \nabla_x F dt -  F dx_t + \frac{\partial V}{\partial t} dt
\end{align}
Eq.~\eqref{eqn:tmp14-0} becomes
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \exp\bigg\{
  \frac2{\sigma^2}\bigg[
  V(x_T,T) - V(x_0,t_0) - \int_0^T\partial_tV(x_t,t)dt
  \bigg]
  \bigg\}
\end{align}
According to the  Einstein relation, the temperature $\mathcal T = \sigma^2/2$, we denote $\beta = 1/{\mathcal T} = 2/\sigma^2$.
Take the limit of infinite small time interval, and notice the equilibrium
invariant probability density with respect to potential $V(x,0)$ satisfies $\mu(x) \propto e^{-\beta V(x,0)}$,
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \frac{\mu(x_0)}{\mu(x_T)}\times
  \exp\bigg\{
  - \beta\int_0^T\partial_tV(x_t,t)dt
  \bigg\}
\end{align}

In Eq.~\eqref{eq:dagger-0}, we assume the periodicity of the perturbation $F(x,t) = F(x,t+T)$, and the symmetry of the external perturbation, i.e.~$F(x, -t) = F(x, t)$, we have
\begin{align}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, t_i)]^2\dt\bigg\}  
\end{align}
By changing notation $x^\dagger$ back to $x$, and comparing with~\eqref{eq:tmp9}, the reversed dynamics is subject to the Eq.~\eqref{eqn:tmp7},
i.e.~$dp^\dagger = dp$.
Therefore
\begin{align}\nonumber
  p(x_0,T\vert x_T,0)
  =&\,\int_{\mc\{x_T,0;x_0,T\}}
  dp[x^\dagger_t] \\\nonumber  
  =&\,
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\nonumber
  =&\,
  % \lim_{N\rightarrow\infty} 
  % \frac{1}{(2\pi\sigma^2\dt)^{(N-1)/2}} \int dx_{N-1}\cdots\int dx_{1}
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\label{eqn:tmp18}
  = &\,
  \frac{\mu(x_0)}{\mu(x_T)}
  \int_{\mc\{x_0,0;x_T,T\}}
  \exp\bigg\{
  -\beta\int_0^T \partial_t V(x_t,t)dt 
  \bigg\} \cdot dp[x_t]
\end{align}
where $\mc\{x_0,0;x_T,T\}$ denotes all continuous trajectories starting at $x_0$ and ending at $x_T$.
If $\partial_t V = 0$, i.e.~equilibrium, we have
\begin{align}
  p(x_0,T\vert x_T,0)e^{-\beta V(x_T,T)} =  p(x_T,T\vert x_0,0) e^{-\beta V(x_0,0)},
\end{align}
which proves the reversibility of the equilibrium dynamics.
The term
\begin{align}
  W[x_t] = \int_0^T \partial_t V(x_t,t)dt
\end{align}
is the non-equilibrium work associated to all possible
the dynamics $x_t$ starting at $x_0$ and ending at $x_T$ (see e.g.~Ref.~\cite{seifert2012stochastic}).
Therefore Eq.~\eqref{eqn:tmp18} is the detailed Jarzynski relation.
% Now the problem becomes if we can write a nice form (e.g.~the difference of a state function measured at $x_T$ and $x_0$) for the non-equilibrium work.
Noticing that
\begin{align}
  \label{eq:tmp21}
  p(x_T,T\vert x_0,0) = \int_{\mc\{x_0,0;x_T,T\}}dp[x_t],
\end{align}
From Eq.~\eqref{eqn:tmp18} we have
\begin{align}
  \label{eq:tmp22}
  \frac{p(x_0,T\vert x_T,0)}{  p(x_T,T\vert x_0,0)  }
  =
  \frac{\mu(x_0)}{\mu(x_T)}
  \mathbb E_{x_0\rightarrow x_T} [e^{-\beta W}]
\end{align}
% Maybe we want a more symmetric form.
% The expectation value of the reversed dynamics reads,
% \begin{align}\nonumber
%   \mathbb E_{x^\dagger_0\rightarrow x^\dagger_T} [e^{-\beta W^\dagger}]
%   =\,&
%   \int_{\mc\{x^\dagger_0,0;x^\dagger_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x^\dagger_t,t)dt 
%   \bigg\} \cdot dp[x^\dagger_t]   \\\nonumber
%   =\,&
%   \int_{\mc\{x_0,0;x_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x_{T-t},t)dt 
%   -\beta\int_0^T \partial_t V(x_{t},t)dt 
%   \bigg\}
%   \cdot dp[x_t]   \\  \nonumber
%   =\,&
%   \int_{\mc\{x_T,0;x_0,T\}}
%   \exp\bigg\{
%   \beta\int_0^T \partial_t V(x_t,t)dt 
%   \bigg\} \cdot dp[x_t]   \\
%   \label{eq:tmp23}
%   = \,&
%   \mathbb E_{x_0\rightarrow x_T} [e^{- 2\beta W}]  
% \end{align}
% Noticing that \eqref{eq:tmp22}  is true for the reversed dynamics, we have
% \begin{align}
%   \label{eq:24}
%   \frac{p(x_T,T\vert x_0,0)}{  p(x_0,T\vert x_T,0)  }
%   =
%   \frac{\mu(x_T)}{\mu(x_0)}
%   \mathbb E_{x_T\rightarrow x_0} [e^{\beta W}]  
% \end{align}


\bibliography{ref}{}
\bibliographystyle{unsrt}



\end{document}

\documentclass[journal=jctcce,manuscript=article]{achemso}
% \documentclass[aps, pre, preprint,unsortedaddress,a4paper,onecolumn,showkeys]{revtex4}
% \documentclass[aps, pre, reprint,unsortedaddress,a4paper,twocolumn]{revtex4}
% \documentclass[acs, jctcce, a4paper,preprint,unsortedaddress,onecolumn]{revtex4-1}
% \documentclass[aps,pre,twocolumn,unsortedaddress]{revtex4-1}
% \documentclass[aps,jcp,groupedaddress,twocolumn,unsortedaddress]{revtex4}
\usepackage[version=3]{mhchem} % Formula subscripts using \ce{}
\setkeys{acs}{keywords = true}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
% \usepackage{color}
% \usepackage{tabularx}
% \usepackage{algorithm}
% \usepackage{algorithmic}

\makeatletter
\makeatother

\newcommand{\recheck}[1]{{\color{red} #1}}
\newcommand{\redc}[1]{{\color{red} #1}}
\newcommand{\bluec}[1]{{\color{blue} #1}}
\newcommand{\greenc}[1]{{\color{green} #1}}
% \newcommand{\vect}[1]{\textbf{\textit{#1}}}
\newcommand{\vect}[1]{#1}
\newcommand{\dd}[1]{\textsf{#1}}
% \newcommand{\fwd}[0]{\textrm{fw}}
% \newcommand{\bwd}[0]{\textrm{bw}}
\newcommand{\fwd}[0]{+}
\newcommand{\bwd}[0]{-}
\newcommand{\period}[0]{T_{\textrm{P}}}
\newcommand{\ml}[0]{\mathcal {L}}
\newcommand{\mo}[0]{\mathcal {O}}
\newcommand{\mbp}[0]{\mathbb {P}}
\newcommand{\mc}[0]{\mathcal {C}}
\newcommand{\dt}[0]{\Delta t}
\newcommand{\id}{\mathrm{Id}}
% \newcommand{\myphi}{\boldsymbol\Phi}
% \newcommand{\mymu}{\boldsymbol\mu}
\newcommand{\myphi}{\Phi}
\newcommand{\mymu}{\mu}
\newcommand{\prob}{\textrm{P}}
\newcommand{\dih}{\textrm{dih}}

\newcommand{\confaa}[0]{{\alpha_{\textrm{R}}}}
\newcommand{\confab}[0]{{\alpha_{\textrm{R}}'}}
\newcommand{\confba}[0]{{\textrm{C}7_{\textrm{eq}}}}
\newcommand{\confbb}[0]{{\textrm{C}5}}
\newcommand{\confc}[0]{{\alpha_{\textrm{L}}}}



\title{Building Markov State Models for Periodically Driven Non-Equilibrium Systems}
\author{Han Wang}
\email{han.wang@fu-berlin.de}
\affiliation{CAEP Software Center for High Performance Numerical Simulation, Beijing, China}
\alsoaffiliation{Zuse Institute Berlin (ZIB), Germany}
\author{Christof Sch\"utte}
\email{schuette@zib.de}
\affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}
\alsoaffiliation{Zuse Institute Berlin (ZIB), Germany}


\begin{document}
   
\begin{abstract}
Recent years have seen an increased interest in non-equilibrium molecular dynamics (NEMD) simulations, especially for molecular systems with periodic forcing by external fields, e.g., in the context of studying  effects of electromagnetic radiation on the human body tissue. Lately, an NEMD methods with local thermostating has been proposed that allows for studying 
non-equilibrium processes in a statistically reliable and thermodynamically consistent way. In this article, we demonstrate how to construct Markov State Models (MSMs) for such NEMD simulations. MSM building has been well-established for systems in equilibrium where MSMs with just a few (macro-)states allow for accurate reproduction of the essential kinetics of the molecular system under consideration. Non-equilibrium MSMs have been lacking so far. The article presents how to construct such MSMs and illustrates their validity and usefulness for the case of conformation dynamics of alanine dipeptide in an external electric field.  \\
\textbf{Keywords:} {Non-equilibrium, Markov states model, Alanine dipeptide, Electric field, Floquet theory}
\end{abstract}


\maketitle

\section{Introduction}
% \textbf{Non-equilibrium, especially periodically driven system. Interesting.}

Biomolecular systems under non-equilibrium conditions caused by external fields, especially
systems under periodic forcing, have attracted increasing
interest recently.  For example, the potential effects of electromagnetic
radiation on the human body tissue (e.g.~DNA, protein, and membrane)  has been extensively
investigated in a vast number of articles, with the following list just representing an incomplete selection~\cite{bohr2000microwave, bohr2000microwave-1, dePomerai2000cell,
  dePomerai2003microwave, mancinelli2004non, inskip2001cellular, bekard2013electric, budi2005electric,
  budi2007effect, budi2008comparative, astrakas2012structural,
  damm2012can, english2009nonequilibrium, solomentsev2012effects}.  Molecular dynamics (MD) simulations have proved particularly useful for understanding
the response of biomolecular conformations to external fields because of their ability to  resolve molecular
details that sometimes cannot be resolved in experiments. Only
recently, a non-equilibrium MD simulation (D-NEMD) method with local thermostating has been proposed~\cite{wang2014exploring} that allows for studying 
non-equilibrium processes in a statistically reliable and thermodynamically consistent way. 
Despite the significance of the non-equilibrium phenomena, the
analysis of the non-equilibrium MD simulations mainly follows standard approaches, and reliable tools for quantitative description of
the essential conformational dynamics of the molecular system under external forcing are still lacking. 

% \textbf{MSM tools for analyzing, provide profound understanding.}

Despite their many advantages, MD simulations have severe limitations. For example, one has to assume that the underlying force fields are appropriately describing the internal and external molecular interactions, and the maximal possible simulation length often is shorter than the timescale of interest. 
This article is mainly concerned with circumventing the latter obstacle by introducing non-equilibrium Markov State Models. Markov State Models
(MSM) have been well developed over the
past decade in theory~\cite{A19-31,prinz2011markov} and applications (see the recent book~\cite{A19-1} for an overview), and software implementations~\cite{A19-49, MSMBuilder}, but for systems under equilibrium conditions only!  
The principal idea of equilibrium MSMs is to approximate the original high-dimensional MD system by
a reduced Markovian dynamics over a finite number of (macro-)states. These (macro-)states
have to be identified with the dominant metastable sets, in the sense that
typical MD trajectories stay in the vicinity of a metastable set substantially longer than
the systems needs for a transition to another such state~\cite{A19-31,schuette2011markov}. In this case, the metastable sets are the main conformations of the molecular system under consideration which, often enough, are given by the main wells in the energy landscape. 
It has been shown that for molecular systems exhibiting such metastable sets the Markovian dynamics given by an MSM allows very close approximation of the longest relaxation processes of the underlying molecular system, at least under equilibrium conditions~\cite{sarich2010approximation,Eigenvalues}. 
Moreover, it has been demonstrated that in such cases MSM building requires short MD trajectories only, much shorter than the timescales of interest~\cite{PNAS09,kohlhoff2014cloud}.  
Thus, MSM building often allows to study the dynamical behavior on long timescales without requiring MD trajectories of comparable length.
Moreover, MSMs are utilized for understanding very long MD simulations: Extracting the essential structures and dynamical properties from long MD runs is
becoming increasingly difficult as the system size and trajectory length grow; MSMs have been used to construct kinetic fingerprints from MD simulations~\cite{A19-39} that help understanding the essential dynamics and in comparison with experiments~\cite{PrinzKellerNoe_PCCP11_Perspective}.


% Current achievement of MSM in equilibrium cases:
% \begin{itemize}
% \item well developed in theory and applications \cite{A19-31, A19-1}
% \item software for MSM building \cite{A19-49, MSMBuilder}
% \end{itemize}

% \textbf{Importance: first application of MSM in a non-equilibrium system.}
To the knowledge of the authors this work is the first attempt of using MSMs for analyzing non-equilibrium systems under periodic external forcing.
More precisely, we will demonstrate how to use MSMs for investigate the conformational dynamics of a peptide (alanine dipeptide) under an oscillating electric field (EF).
To this end, we will show how to generalize Markov state modeling to periodic non-equilibrium conditions where one cannot assume reversibility of the dynamics as it is mostly done in the literature on MSM building.

The outline of the article is as follows: 
In Sec.~\ref{sec:disc}, we discuss the temporal and spatial
discretizations needed to construct an MSM. We consider spatial discretization
of the dihedral angle space in the traditional sense of full partition MSMs~\cite{pande2010everything,A19-29}.
In the temporal direction, the non-equilibrium process
is discretized utilizing Floquet's theorem. This results in a time-homogeneous, 
but not necessarily reversible, that is, irreversible Markov process. Since  full spatial partition does not make any sense
for high-dimensional systems, we next show how to construct a \emph{few-state} MSM based on milestoning~\cite{schuette2011markov,A19-29} of the discretized irreversible Markov process in Sec.~\ref{sec:build-msm}.
The validity of the discretizations and the resulting MSM is checked in Sec.~\ref{sec:alanine}
by comparing the kinetic fingerprints given by the MSM to brute force
non-equilibrium MD simulations of alanine dipeptide under oscillating EF.
The findings are summarized in Sec.~\ref{sec:conclusion} including a chart presenting
the workflow of MSM building for non-equilibrium systems, and a list of open questions.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Non-equilibrium molecular dynamics and its discretization}
\label{sec:disc}
We consider diffusive molecular dynamics in an energy landscape $V$ driven by the time-dependent external driving force $E(t)D(x_t)$ with the
$T$-periodic external field $E(t)$:
\begin{align}
  \label{eq:disc-1}
  d\vect x_t = \Big(-\nabla V(\vect x_t) + E(t) D(\vect x_t)\Big)dt + \sqrt{2\beta^{-1}} d\vect w_t, 
\end{align}
where $x_t\in\Omega$ denotes the state of the molecular system at time $t$ in state space $\Omega$, $\vect w_t$ denotes standard $n$-dimensional Brownian motion, and $\beta$ the inverse temperature,
i.e.~$\beta = 1/(k_B\mathcal T)$.
Thermostatted Hamiltonain or Langevin dynamics can be treated in the same way as explained herein, so for sake of simplicity we focus on the discussion of diffusive dynamics.
The propagation of probability
densities $\rho=\rho(\vect x,t)$ based on this kind of dynamics in the sense
of $\rho(\vect x,t)dx=\prob[\vect x_t\in [\vect x,\vect x+d\vect x)]$ is governed by
Fokker-Planck equation:
\begin{align}
  \label{eq:disc-fp}
  \frac{\partial \rho}{\partial t} = \ml^\dagger(t) \rho,
\end{align}
where $\ml^\dagger(t)$ is the adjoint of the generator
\begin{align}
  \label{eq:disc-3}
  \ml(t)=\beta^{-1}\Delta_{\vect x}+\Big(-\nabla_x V(\vect x) + E(t)D(\vect x)\Big)\cdot\nabla_{\vect x},
\end{align}
where $\Delta_{\vect x}$ denotes the Laplacian operator and $\nabla_{\vect x}$
the nabla-operator wrt to $\vect x$. 
The periodicity of the external driving force induces the periodicity of the generator,
i.e.~$\ml(t) = \ml(t+T)$.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spatial discretization: Master equation}
We will now introduce an appropriate spatial discretization of this kind of non-equilibrium MD --  this is done for reasons of simplicity only; we could completely avoid it for the price of more technical arguments.
For achieving this discretization, we 
introduce a partition of state space $\Omega$ into a finite number of disjoint
sets $\{ \Omega_1, \cdots, \Omega_N\}$ satisfying $\Omega = \cup_i \Omega_i$,
$\Omega_j\cap \Omega_j = \emptyset,\ \forall i\neq j$.
Utilizing the procedure described in Ref.~\cite{latorre2011structure} the original Fokker-Planck equation~(\ref{eq:disc-fp})
is discretized, resulting in a time-inhomogeneous Markov jump process in state
space $S = \{1, \cdots, N\}$ with time-dependent rate
matrix $\vect L(t) \in \mathbb R^{N\times N}$ satisfying
\begin{align}\label{eq:disc-4}
\sum\limits_{j=1}^N L_{ij}(t) & =  0\\ \label{eq:disc-5}
L_{ij}(t) & \ge  0, \quad i\not= j\\
L_{ij}(t) & =  L_{ij}(t+T)
\end{align}
for all real time $t\geq 0$.
Moreover, the rate matrix $L$ has the form $\vect L(t)=\vect L_0+E(t)\vect L_1$
where $E(t)$ is periodic with period $T>0$.
In analogy to \eqref{eq:disc-fp}, the Markov jump process generated by
$\vect L(t)$ transports probability distributions according to the associated Master equation
\begin{align}
  \label{eq:disc-master}
  \frac{d\vect p(t)}{dt} = \vect L^{\top}(t)\cdot \vect p(t)
\end{align}
where $\vect L^{\top}(t)$ denotes the matrix transpose of $\vect L(t)$, $\vect p(t)$ is an $N$-vector denoting the probability distribution on $S$ at time $t$, $p(i,t)$, for example, the probability to be in state $i$ (which corresponds to set $\Omega_i$) at time $t$.
As usual the properties (\ref{eq:disc-4}) and (\ref{eq:disc-5}) of
$\vect L(t)$ guarantee that the total probability mass is conserved,
i.e., if $p(i,0)\ge 0$ componentwise, then $p(i,t)\ge 0$ and $\sum_i
p(i,t) = \sum_ip(i,0)$.
% The solution of the master equation need no be
% periodic.
The temporal evolution of the probability distribution $\vect p(t)$ can be formally written
\begin{align}  \label{eq:disc-8}
\vect p(t)=\myphi(t)\vect p(0)
\end{align}
by using the
associated propagator matrix $\myphi(t)\in\mathbb R^{N\times N}$ that solves
\begin{align}
  \label{eq:disc-master-phi}
  \frac{d}{dt}\myphi(t) = \vect L^{\top}(t)\myphi(t), \quad \myphi(0) = \id .
\end{align}
Since the last equation can be considered column-wise, the propagator matrix inherits column-wise conservation properties:
$\Phi_{ij}(t) \ge  0$
and $\sum\limits_{i=1}^N \Phi_{ij}(t)  =  1$,
that is, $\myphi^{\top}(t)$ is a
stochastic matrix satisfying $\myphi^{\top}(t)\vect e=\vect e$
with $\vect e=(1,\ldots,1)^{\top}\in \mathbb R^N$.
Regarding these considerations, we find
\begin{align}
\label{eq:disc-10}  
\myphi_{ij}(t)=\prob\left(\vect X_t=i\mid \vect X_0=j \right),
\end{align}
where $\vect X_t$ denotes the Markov process generated by $\vect L(t)$.
 
The discretization sets that we used to go from $\vect x_t$ and $\ml(t)$ to $\vect X_t$
and $\vect L(t)$, respectively, can be assumed to provide an arbitrarily fine
partition of the original state space; then the transport properties
of $\vect L(t)$ are almost perfect approximations of the transport properties
of $\ml(t)$, in particular the approximation $p(i,t)\approx \prob(x_t\in \Omega_i)$ is almost perfect.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Temporal discretization: Floquet theorem}
\label{sec:floquet}

As an effect of the periodicity of $\vect L(t)$ the propagator $\myphi(t+T)$
satisfies
\begin{equation}\label{compo-1}
\myphi(t+T)=\myphi(t)\myphi(T),
\end{equation}
for all $t\ge 0$. This can be seen by considering $\vect Y(t)=\myphi(t+T)$. It satisfies
\[
\frac{d\ }{dt}\vect Y(t)=\vect L^{\top}(t+T) \vect Y(t)=\vect L^{\top}(t)\vect Y(t),\quad \vect Y(0)=\myphi(T).
\]
When we consider this identity column-wise and use the propagator property of $\myphi(t)$ we get $\myphi(t+T)=\vect Y(t)=\myphi(t)\myphi(T)$. As a consequence of (\ref{compo-1}) we get for all integers $m=0,1,2,\ldots$ that 
\begin{equation}\label{compo-2}
\myphi(t+mT)=\myphi(t)\myphi^m(T).
\end{equation}
In combination with Eq.~\eqref{eq:disc-8}, we therefore
know the solution $\vect p(t)$ of the Master equation for all $t\ge 0$,
if we can compute $\myphi(t)$ for $t\in (0,T)$.
This is known as the Floquet theorem~\cite{floquet1883equations}.
In particular we get the long-term evolution of the propagator:
\begin{align}
\label{eq:floq-13}  
\myphi(mT)=\myphi^m(T),
\end{align}
where $\myphi^m(T)$ denotes the $m$th power of $\myphi(T)$. Thus, for the probability at integral periods we have
\begin{align}
  \label{eq:floq-dynamics}
  p(mT) =  \myphi(mT)\, p(0) = \myphi^m(T)\, p(0).
\end{align}


Using the Floquet theorem, the time-inhomogeneous Markov jump process $X_t$
is therefore discretized into a \emph{time-homogeneous} (not necessarily
reversible) Markov jump process $\tilde X_{m} = X_{mT}, \ m\in\mathbb
N$, which is generated by transition matrix
\begin{equation}\label{P}
\vect P=\myphi^{\top}(T).
\end{equation}
We prefer to consider the discrete-time process $\tilde X_{m}$ instead of the time-continuous process $X_t$
because the powerful theories and
computational tools for time-homogeneous Markov processes can be directly applied. It worth noting that many of these tools require the transition matrix $P$ to satisfy the detailed balance condition. The computations in the Appendix~\ref{sec:app-revs} show that $P$ will in general \emph{not} satisfy this condition; in fact  the deviation {from} reversibility can be estimated from the work of the periodic driving does to the system.
There is no doubt that information within one period is lost by using this temporal
discretization, however, information regarding the long-term behavior of the system on timescales
much longer than the period will be perfectly described because of $\tilde X_{m} = X_{mT}\approx x_{mT}$ whenever our spatial discretization is fine enough.
At the same time,
the computational cost of generating $\tilde X_{m}$ is much less demanding
than the brute force simulations of NEMD, which implies lower
statistically uncertainty in calculating the observables of interest.


Since $P$ is a stochastic matrix, its eigenvalues are contained in the unit circle in
the complex plane, i.e., each eigenvalue $\lambda$ (potentially complex-valued)
satisfies $|\lambda|\le 1$. Furthermore $\lambda=1$ is an
eigenvalue with right eigenvector $\vect e=(1,\ldots,1)^{\top}$ and a left eigenvector $\mymu$
satisfying
$\mymu^{\top}P=\mymu^{\top}$.
From now on, we assume $P$ to be irreducible and aperiodic such that the Perron-Frobenius theorem holds, so the eigenvector corresponding to the eigenvalue $\lambda=1$ is  non-negative componentwise, and unique (up to normalization $\sum_i\mu(i)=1$). In this case $\mymu$ is the stationary measure in the sense that
$
 \mymu^{\top} P^m = \mymu^{\top},\ m\in\mathbb N
$,
% \begin{align}
% \label{eq:floq-14}  
% \end{align}
and (more precisely) the asymptotic evolution of an initial probability distribution $\vect p(t=0)$ by the process satisfies
$
\vect p^{\top}(0)\,P^m \to \mymu^{\top},\ m\to\infty,
$
% \begin{align}
% \label{eq:floq-15}  
% \end{align}
so that $\mymu$ can be seen as the quasi-stationary distribution of the non-stationary process.


% due to the discretization in both the spacial and temporal directions.
% In the numercal example in Sec.~\ref{sec:alanine}, we
% compute the 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Markov State Model}
\label{sec:build-msm}


% \subsection{Building the Markov State Model from the Floquet transition matrix}
If the discretization cells $\Omega_i$, $i=1,\ldots,N$ form a fine
partition of the molecular state space, the Markov chain defined via
the transition matrix $P$
 is discrete in time, but in space it still is a fine-scale description of the transport properties of the
dynamics with a very large number $N$ of states.  Now we want to coarse our description much further by
constructing a Markov State Model (MSM) for $\vect P$ with $K\ll N$
\emph{macrostates} that should be the metastable states of the system: The resulting $K\times K$ MSM transition matrix $\hat{\vect P}$
then defines the coarse grained long term kinetics that shall
approximate the original long term kinetics well. 
The idea behind MSM building is that given the molecular system under consideration exhibits metastable conformations then it is usually possible to construct a
relatively small number of discrete sets --the metastable sets that form the so-called macrostates-- that
correctly describe the slow  dynamics, and 
in each set the fast dynamics relaxes on some timescales significantly shorter than the metastable timescales.
Then if the MSM dynamics reproduces the slow timescales and the corresponding transitions
of the original dynamics~\eqref{eq:disc-1},
the former is considered to be a good approximation of the latter.

MSM building has been attracted a lot of attention recently, and theory  \cite{A19-31} as well as algorithms \cite{A19-1}, applications (see e.g. \cite{A19-26,PNAS09} for two of hundreds of articles) and software \cite{A19-49, MSMBuilder} have been developed to quite an extend. However, 
by far most of the literature is related to building \emph{standard} MSMs for equilibrium MD. In standard MSM also the transition region has to be discretized, a feature that often forces the user to incorporate more macrostates than essentially needed to approximate the long-term kinetics.
In Ref.~\cite{sarich2010approximation, A19-31,schuette2011markov,BucheteHummer} it has been shown how to construct \emph{non-standard} MSM that avoid this problem for equilibrium MD, i.e., if $\vect P$ satisfies the detailed balance
condition: (1) Identify the cores of the metastable sets of the
dynamics, (2) use them as milestones to construct an MSM in which the
macrostates are the metastable core sets and $\hat{\vect P}$ is the transition
matrix of the milestone process \cite{A19-31,schuette2011markov,A19-29} that models the jumping behavior of
the original dynamics between the metastable regions. 

However, since we cannot assume $P$ to satisfy detailed balance, we
instead follow the approach to non-standard MSMs recently proposed in Ref.~\cite{sarich2014utilizing} which allows to identify the metastable core sets for the
non-reversible transition matrix $P$. Assume that this approach leads
to the $K$ core sets $C_1,\ldots, C_K\subset S$ that are appropriate metastable sets. 
Following~\cite{A19-31,schuette2011markov} the process $(\tilde X_m)$ associated with $P$ is coarse grained into the so-called milestone process $(\hat{X}_m)$ in the following way: 
\begin{itemize}
\item $\hat{X}_m$ just has $K$ states associated with the sets $C_j$, $j=1,\ldots,K$. 
\item The sequence of random variables $(\hat{X}_m)$ is defined via the sequence $(\tilde X_m)$, i.e., trajectories of $(\tilde X_m)$ induce trajectories of $(\hat{X}_m)$: We set $\hat{X}_m=j$ if the last core set that the process $(\tilde X_m)$ entered prior to or at time $m$ has been the core set $C_j$.
\end{itemize}
Now consider an arbitrary infinitely long trajectory of $(\tilde X_m)$. Because of ergodicity we know that the states in this trajectory will be distributed due to the quasi-stationary distribution $\mu$. Based on such an infinitely long trajectory we can consider the probability $q_j^\bwd(i)$ that conditioned on $\tilde X_m=i$ the last core set hit has been $C_j$.
This function is called the backward committor of $(\tilde X_m)$ associated with the set $C_j$ and is associated with the milestone process via
\begin{align}
\label{eq:msm-bwd-committor}  
q^\bwd_j(i)=\prob_\mu(\hat{X}_m=j \mid X_m=i),
\end{align}
where  the index $\mu$ refers to the fact that $\hat{X}_m$ is distributed due to $\mu$.
%\recheck{\underline{QUESTION}: Here it is a \emph{conditional} probability,
%  due to the time-homogeneity,
%  it does not matter whether it is defined from quasi-stationary probability
%  or not.}
From the last equation we get that the stationary distribution of the milestone process is given by
\begin{align}  
\hat{\mu}_j=\sum_{i\in S} q^\bwd_j(i)\mu(i),
\end{align}
that is, the probability to find $\hat{X}_m=j$ in (infinitely) long trajectories of the milestoning process is $\hat{\mu}_j$.

Following \cite{discreteTPT} one also has to consider the forward committor $q^\fwd_j(i)$ identical to the probability  that conditioned on $\tilde X_m=i$ the next core set to be hit will be $C_j$.
The forward and backward committors $q^\fwd_j$ and $q^\bwd_j$  for each core set $C_j$ can be computed from $P$ by solving the linear equations \cite{discreteTPT}
\begin{align}
(P-\id) q^\fwd_j(i) & =  0, \quad i\in C\label{qfwd}\\
q^\fwd_j(i) & =  1,\quad i\in C_j\nonumber\\
q^\fwd_j(i) & =  0,\quad i\in C_k,k\not=j\nonumber
\end{align}
where $C=S\setminus\cup_j C_j$, and
\begin{align}
(P^b-\id) q^\bwd_j(i) & =  0, \quad i\in C\label{qbwd}\\
q^\bwd_j(i) & =  1,\quad i\in C_j\nonumber \\
q^\bwd_j(i) & =  0,\quad i\in C_k,k\not=j\nonumber
\end{align}
where $P^b$ denotes the transition matrix of the time-reversed process
given by $P^b_{ji}=\mu(i) P_{ij}/\mu(j)$.

We define the one-step transition matrix $\hat{\vect P}$ for the milestone process by
\begin{equation}\label{hatP_prob}
\hat{\vect P}_{jk}=\prob_\mu\Big(\hat{X}_{m+1}=k\,\vert\, \hat{X}_m=j\Big).
\end{equation}
Then Following
Ref.~\cite{djurdjevac2010markov}, Thm.~3.1, 
$\hat{\vect P}$ can be computed by matrix multiplication using the committors:
  \begin{align}
    \label{eq:msm-tmatrix-00}
    \begin{split}      
    \hat{\vect P}_{jk}
    = &
    \frac{1}{\hat{\mu}_j}
    \langle (\vect P^b - \id) q^\bwd_j,q^\fwd_k \rangle_\mu,\qquad j\not= k, \\    %\label{eq:msm-tmatrix-01}
    \hat{\vect P}_{jj}
    =&
    1-\sum_{k\not=j} \hat{\vect P}_{jk}
    \end{split}
  \end{align}
where the inner product is defined by
$\langle u,v \rangle_\mu=\sum_{i\in S} u(i) v(i) \mu(i)$. 
In general the milestone process need not be a Markov process. The results in \cite{A19-31,sarich2014utilizing} show, however, that it is an approximate Markov process as long as the core sets are proper metastable sets, i.e., if the typical timescale on which $(X_m)$ leaves $C$ is much smaller than the typical expected hitting times between the core sets.
Thus, by taking $\hat{P}$ as our MSM transition matrix, we introduce an additional modeling error that is the smaller the more metastable the core sets are.
With this MSM transition matrix, we can define the MSM kinetics:
If we start from some initial probability $\hat{p}_j(0)$ of being in state $j$ at time $t=0$ then its evolution $\hat{p}_j(t)$ in time is discrete in multiples of period $T$ and given by
\begin{equation}\label{eq:num-29}
\hat{p}_j(T)=\sum_k \hat{p}_k(0)\hat{\vect P}_{kj}.
\end{equation}
In our approach $\hat p_j(mT)$ is a good approximation of $\prob(\hat{X}_m=j)$ (for appropriately chosen core sets).

\textbf{Remark 1:} Our definition of the milestoning process in terms of the process $(\tilde X_m)$ generated by $P$ guarantees that we can directly compute $\hat{P}$ via (\ref{hatP_prob})  from trajectories of $(\tilde X_m)$ without computing the committor functions. 
This is of importance if the spatial discretization underlying $(\tilde X_m)$ is fine enough, because then the kinetics of $(\tilde X_m)$
approximates the original kinetics of $(x_{mT})$ so that we can directly compute   $\hat{P}$ via (\ref{hatP_prob})  from NEMD trajectories without computing $P$ first (which substantially simplified the MSM building if the core sets are already known).

\textbf{Remark 2:}
Following \cite{A19-31} we can also define another pair of stochastic MSM matrices: 
\begin{align}\label{eq:msm-ht-1}
  \hat T_{jk} &= \frac{\langle q_j^\bwd, P q_k^\fwd \rangle_\mu}{\hat \mu_j},\\\label{eq:msm-hm-1}
  \hat M_{jk} &= \frac{\langle q_j^\bwd, q_k^\fwd \rangle_\mu}{\hat \mu_j},
\end{align}
that are connected to $\hat{P}$ by the following identity
\[
\hat{P}=\hat{T}-\hat{M}+\id,
\]
That can be seen by means of direct computation: For the off-diagonal entries we have
\begin{align}\label{eq:msm-tmp26}
  \hat T_{jk} - \hat M_{jk}
  = \frac{\langle q_j^\bwd, P q_k^\fwd \rangle_\mu}{\hat \mu_j}
  - \frac{\langle q_j^\bwd,  q_k^\fwd \rangle_\mu}{\hat \mu_j}
  = \frac{\langle (P^b - \id) q_j^\bwd, q_k^\fwd \rangle_\mu}{\hat \mu_j}
  = \hat P_{jk}, \quad j\neq k
\end{align}
Stochasticity yields
$\hat T_{jj} - \hat M_{jj} + 1 = \hat P_{jj}$ for the diagonal entries.  Furthermore, as shown in the Appendix~\ref{sec:app-prove}, $\hat{T}$ as well as $\hat{M}$ can be computed from trajectories without need to have the committors. 
The importance of the pair $\hat{T}$ and $\hat{M}$ for MSM building comes from the following observation: The main NEMD relaxation timescales are given by the dominant eigenvalues of $P$ \cite{A19-31, A19-1}.
These dominant eigenvalues can be approximated by discretizing the related eigenvalue problem $Pu=\lambda u$ by means of a Galerkin approximation with the finite dimensional ansatz space 
spanned by the forward committors $q^+_j$, $j=1,\ldots,K$ together  with the finite dimensional test function space spanned by the backward committors $q^-_j$, $j=1,\ldots,K$ (test functions multiplied from the left by the inner product $\langle\cdot,\cdot\rangle_\mu$). The thus discretize eigenproblem takes the form  of a generalized eigenproblem
\begin{align}
  \label{eq:msm-gen-ev}
\hat{T}\hat{u}=\hat{\lambda}\hat{M}\hat{u},\quad\mathrm{or, equivalently}\quad \hat{M}^{-1}\hat{T}\hat{u}=\hat{\lambda}\hat{u},.  
\end{align}
For the reversible case it is known that its $k$ eigenvalues $\hat{\lambda}$ are very good approximation of the dominant eigenvalues $\lambda$ of the original problem if the core sets are proper metastable sets~\cite{Eigenvalues}. Whether this is true for the non-reversible case is not known yet, but if the deviation from reversibility is weak and the dominant eigenvalues of $P$ are real-valued then the results should hold analogously, see~\cite{A19-31}, Thm.~4.19. 

If all of its entries are positive such that it is a stochastic matrix, $\hat{M}^{-1}\hat{T}$ thus can also be taken as MSM transition matrices. In the case of $\hat{M}^{-1}\hat{T}$ the MSM modeling error results from Galerkin discretization, while the MSM modeling error of $\hat{P}$ results from ignoring the potential non-Markovianity of $\hat{X}_m$.

\textbf{Remark 3:} As a matter of fact, if $\hat X_m$ were Markovian, the following identity would hold: $\hat P = \hat T \hat M^{-1}$ (see~Appendix~\ref{sec:app-ptm} for the proof). In this case, we would have $\hat{M}^{-1}\hat{T}=\hat{M}^{-1}\hat{P}\hat{M}$ and the eigenvalues of $\hat{P}$ and $\hat{M}^{-1}\hat{T}$ would be identical.
Therefore, in practice, the deviation of the eigenvalues of $\hat P$ from those of $\hat{M}^{-1}\hat{T}$ indicates the deviation from Markovianity regarding the process $\hat{X}_m$.
%The lesson learnt in the reversible case are that $\hat{P}$ is better suited to approximate the molecular kinetics on large timescales while $\hat{M}^{-1}\hat{T}$ should be used for approximating eigenvalues and long relaxation timescales.

% Given core sets $\{C_1, \cdots, C_k\}$, the procedure \eqref{eq:msm-ht}--\eqref{eq:msm-tmatrix-10}
% If assuming that we have the core sets $\{C_1, \cdots, C_k\}$, no matter how they are identified,



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Numerical example:
  Alanine dipeptide under oscillatory electric field}
\label{sec:alanine}

We know that --in theory-- whenever the spatial discretization is fine enough, the Markov jump
process $X_t$ associated with the Master equation \eqref{eq:disc-master} is a good approximation to the original
MD process $x_t$ governed by \eqref{eq:disc-1}.  In practice, however, it is difficult to predict
how many discrete sets we need to be fine enough. Moreover, since the
total dimension of $x_t$ is $3N_{\textrm{atom}}$ ($N_{\textrm{atom}}$ being the number of atoms), it is prohibitive to do a really fine discretization
over all degrees of freedom for most systems of practical interest.

One possible way to define appropriate discretization sets is firstly to find a few collective
variables, and then to discretize these collective variables as finely as needed either by uniform or adaptive
discretization~\cite{chodera2007automatic, prinz2011markov}.
% This process also suggests that the choice of the lag-time should be 
% shorter than the dominant implied timescale so that they can be resolved,
% and be longer than the fast timescales to relax the unresolved dynamics
% within the discretized sets.
However, it is difficult to give a general answer in prior regarding
how to choose the collect variables and how fine their discretization should be.
For large or high dimensional systems, these questions usually become non-trivial. 

\begin{figure}
  \centering
  \includegraphics[width=0.3\textwidth]{c-2.eps}
  \caption{A schematic plot of the alanine dipeptide molecule and the dihedral angles $\phi$ and $\psi$.}
  \label{fig:tmp1}
\end{figure}


To illustrate how the discretization works in practice we take the alanine dipeptide system under an oscillatory EF,
as an example, the NEMD simulation of which was
extensively studied in Ref.~\cite{wang2014exploring}.
The system was simulated in a $2.7\times 2.7\times 2.7$~$\textrm{nm}^3$ periodic simulation
region, with one alanine dipeptide molecules described by the CHARMM27 force field~\cite{foloppe2000all} dissolved in 641 TIP3P water molecules~\cite{jorgensen1983comparison}.
The grid-based energy correction map (CMAP)~\cite{mackerell2004extending} was used
to correct the backbone dihedral angle energies.
All simulations were performed by a home-modified
Gromacs~4.6.5~\cite{pronk2013gromacs} with CHARMM27 force field implemented~\cite{bjelkmar2010implementation}.
The alanine dipeptide was put into the local thermostating
environment, with a spherical dynamical region of radius~1.0~nm
centered at the alpha-carbon.
The Langevin thermostat with target temperature $\mathcal T = 300$~K
and timescale $\tau_T = 0.1$~ps was
coupled to the thermostated region.
The whole system was coupled to the Parrinello-Rahman barostat~\cite{parrinello1981polymorphic} (in standard Gromacs implementation) with $\tau_P = 2.0$~ps to
keep the system at 1~Bar. The non-equilibrium trajectories
were integrated by the Leap-frog scheme with a time-step of 0.002~ps.
The short-range van der Waals interactions were cut-off at 1.00~nm, and were smoothed from
0.95~nm to 1.00~nm by the ``\texttt{shift}'' method provide by Gromacs.
The energy conserving 
Particle Mesh Ewald (PME)~\cite{darden1993pme, essmann1995spm} method (``\texttt{pme-switch}'') was
used to compute the long-range electrostatic interaction,
with the same real-space cut-off radius as the van der Waals interactions.
The Gromacs default Fourier spacing of 0.12~nm and B-spline interpolation order of 4 were adopted.
The splitting
parameter was optimized with respect to the electrostatic force computing
accuracy by Gromacs tool \texttt{g\char`_pme\char`_error}~\cite{wang2010optimizing}.
The neighbor list was updated every 5 time-steps with a list-building radius 1.20~nm.
All hydrogen involving covalent bonds were constrained by the LINCS algorithm~\cite{hess1997lincs}, except the water molecules that were constrained by the SETTLE algorithm~\cite{miyamoto2004settle}.
The whole system was driven by a periodic electric field
$E(t) = E_0\sin(2\pi t/T)$ and $D(x) = (1,0,0)^{\top}$
with intensity of the field being $E_0 = 1.0$~V/nm and period being
$T = 10$~ps.
The 20,000 branching trajectories were simulated from 20,000
initial configurations that sample the equilibrium distribution.
% \redc{Write a lot of details on NEMD.}
The equilibrium configurations were prepared by an equilibrium MD simulation
of length $10^6$~ps, along which snapshots were saved every 50~ps.
% In the
% equilibrium simulation the system was coupled to a global Langevin thermostat
% with coupling timescale $\tau_T = 0.5$~ps.
The branching NEMD
trajectories were each 4,000~ps long, and the system reached
non-equilibrium quasi-stationary state in roughly 300~ps.


For this periodically driven molecular system we will first show how to choose an appropriately fine spatial discretization. After validating this discretization we will consider
the time-discretized dynamics generated by the Floquet transition matrix $\vect P$
in comparison to the original NEMD simulation. Finally we will coarse grain this description further by construction of a $3$ state Markov State Model that is able to describe the long-term kinetics of the system correctly. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spatial discretization}

We choose the
two dihedral angles $\phi$ and $\psi$ as collective variables (see
Fig.~\ref{fig:tmp1}), and the discretization is a uniform partition of
the $\phi$--$\psi$ plane. We denote the number of discretization intervals on each
dihedral by $N_\dih$, then we get $N = N_\dih^2$ discretization sets 
$\{\Omega_i\},\ i\in S = \{1,\cdots,N_\dih^2\}$.

Based on a given spatial discretization we can aggregate the transition matrix $\vect P=\myphi^{\top}(T)$ just by counting the transition behavior of MD trajectories 
\begin{equation}\label{Pdirect}
\vect P_{ij}=\prob\left(\vect X_T=j\mid \vect X_0=i \right).
\end{equation}
However, $\vect P$ allows to approximate the original dynamics on multiples $mT$ of the period only. In order to have a time-continuous description we need the generator $L(t)$ of the Master equation. 
If the discretization is fine enough one possible approximation to $L(t)$ is via
the following forward finite difference scheme:
\begin{align}
  \label{eqn:tmp4}
  L_{ij}(t) \approx \frac{1}{\tau}
  \,[\, \prob (\vect X_{t+\tau} = j \mid \vect X_{t} = i) - \delta_{ji} \,],
  \quad i,j\in S
\end{align}
and $\tau$ is an appropriate small enough lag-time.
  Since the dimensionality is reduced by using only a few collective
  variables, the lag-time should be chosen large enough so that
  the original dynamics $x_t$ is properly relaxed with regard to
  the unresolved degrees of freedoms on timescales shorter than the lag-time
  (assuming  that the collective variables capture the slow dynamics).
  In the following 
we investigate the discretization
quality with respect to  the choice of $N_\dih$ and  lag-time $\tau$.

%\recheck{\underline{QUESTION}: Is the above discussion correct?
%  Does the ``Markovianity'' always need a time discretization with the
%  lag-time?
%}
%



\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{fig-cg-prob.eps}  
  \caption{Time-dependent probability $\prob\big(\phi_t\in[0,180), \psi_t\in [0,180)\big)$.  The brute force NEMD simulation is compared with different
    spatial discretization methods. The red shadow region indicates the
    statistical uncertainty of the NEMD simulation.}
  \label{fig:tmp2}
\end{figure}

We estimate the discretized generator $L(t), \ t\in[0,T)$
from NEMD trajectories generated by $\ml(t)$ in different time intervals $[t_1,
t_2]$.
As discussed above, whenever  the discretized dynamics approximates the original
dynamics well, the time-periodic generator $L(t)$ should not depend on the choice of the interval $[t_1,t_2]$ in the estimation procedure (\ref{eqn:tmp4}), provided that the initial state of the system
is not very far from the stationary state at long-time limit.
Therefore, this is an indicator for calibrating the discretization quality.
We compute $L(t)$ by two discretizations $N_\dih=2$ and $N_\dih=20$, and two
choices of time intervals $[0, 80]$~ps and $[320, 400]$~ps, and then
compare the time-dependent probability $\prob\big(\phi_t\in[0,180), \psi_t\in [0,180)\big)$
with the (brute force) NEMD result in Fig.~\ref{fig:tmp2} using a lag-time $\tau=0.5$~ps.
Using $N_\dih=2$ the dynamics depends on the time interval used for
calculating the generator: using time interval $[0, 80]$~ps the discretized
dynamics deviates from the NEMD result,
while using time interval $[320, 400]$~ps the discretized dynamics can only
reproduces the NEMD result after 300~ps.  This therefore indicates poor 
approximations to the original dynamics with $N_\dih=2$. The reason is that the
discretization with $N_\dih=2$ is too coarse so that the dynamics cannot be fully
equilibriated within the lag-time $\tau$ in each discretized set,
therefore, the discretization presents state dependency.  For
$N_\dih=20$, the discretized dynamics does not depend on the time interval of
calculating the generator, and is consistent with the
NEMD simulation within the error bar. Therefore, throughout this paper we use $N_\dih=20$
to discretize  the dihedral angle space of alanine dipeptide.
%For a good statistical accuracy, if not stated otherwise,
%we will use the full trajectories, i.e.~a time interval of
%$[0,4000]$~ps for estimating the discretized generator $L(t)$.


\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{fig-cg-prob-tau.eps}  
  \caption{Time-dependent probability $\prob\big(\phi\in[0,180), \psi\in [0,180)\big)$.  The NEMD simulation is compared with the Master equation using generators discretized with $N_\dih=20$ and different lag time $\tau$. The red shadow region indicates the
    statistical uncertainty of the NEMD simulation.}
  \label{fig:tmp3}
\end{figure}

Next we discuss the effect of the lag time $\tau$ on the estimation of the generator. Therefore, we consider 
different choices of $\tau$ (0.5, 1.0, 2.0 and 5.0~ps)
(see Fig.~\ref{fig:tmp3}), all based on the identical dihedral angle discretization using $N_\dih=20$.
It is clear that when the lag-time is close to the period (10~ps), the
discretized dynamics cannot resolve the probability change within a
period. However, it is surprising  that even quite large lag-times are able to capture the
the overall long time behavior of the original dynamics.
We observe no significant difference between $\tau=0.5$ and
$\tau=1.0$~ps, which means the discretized dynamics is not very sensitive
to the choice of $\tau$.
Therefore, throughout this paper $\tau=0.5$~ps will be used.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Quasi-stationary distribution $\mymu$}


\begin{figure}
  \centering  
  \includegraphics[width=0.4\textwidth]{fig-dist.eps}\\
  % \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-dist-msm.eps}
  \includegraphics[width=0.4\textwidth]{fig-floquet-vec-1.eps}
  \caption{The color-scale plot of the logarithmic quasi-stationary distribution $\mymu$
    of (a) the NEMD  and (b)
    the discretized dynamics governed by Floquet transition matrix $\vect P=\myphi^{\top}(T)$.
  }
  \label{fig:num-1}
\end{figure}

After having validated the fine-scale spatial discretization 
we will now consider the time-homogeneous process $\tilde X_{m}$ generated by
the Floquet transition matrix $P = \Phi^{\top}(T)$, and investigate whether it
reproduces the properties of the original  non-equilibrium process $x_t$.
In this context, only the configurations at the  integral periods $mT$ along the original process
are taken into consider.

An important check is the consistency between the
stationary probability density of $\Phi(T)$ (i.e.~the leading eigenvector $\mymu$) and that 
estimated form the original NEMD simulation,
% along which only integral periods $mT$ are considered:
\begin{align}
  \label{eq:num-tmp1}
  \rho_{\textrm{st}}(\phi,\psi) = \lim_{m\rightarrow\infty} \rho (\phi,\psi,mT),
\end{align}
On each NEMD branching trajectory the initial 320~ps are discarded and
the rest of the trajectory in time interval $[320,4000]$~ps is averaged to estimate
the quasi-stationary probability distribution $\rho_{\textrm{st}}$. 
$P$ is computed as described above, and then $\mymu$ is computed as its leading eigenvector. In order to make it comparable to the free energy in the equilibrium case, we take
the logarithm of the distributions, i.e.~$F_{\textrm{st}}(\phi,\psi)=
-k_B\mathcal T\log \rho_{\textrm{st}}(\phi,\psi)$
for NEMD and $F_{\textrm{st}}(\phi,\psi)=
-k_B\mathcal T\log \mu(\phi,\psi)$ for $P$, where $k_B$ is the
Boltzmann constant and $\mathcal T$ is the temperature of the system.
% Under the aformentioned discretization, the stationary distribution is
% defined for the each bin of the dihedral angle space, i.e.~$F_{pq} =
% \int_{ph}^{(p+1)h}d\phi\int_{qh}^{(q+1)h}d\psi
% F_{\textrm{st}}(\phi,\psi), \ 0\leq p,q<N_\dih-1$, where $h = 360/N_\dih$ being
% the size of the bin, $p$ and $q$ here being the bin indexes.
The
results are  compared in Fig.~\ref{fig:num-1}. A good consistency between
the  NEMD simulation and 
$P$ is observed.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Core set identification}

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig-cluster.eps}
  \caption{The core set identification. Different colors indicate different core sets: $C_{\confaa}$ (green), $C_\beta$ (yellow) and $C_{\confc}$ (red).
    The blue color indicates the transition region $C$ that does not belong to one of the core sets.}
  \label{fig:cluster}
\end{figure}

The procedure for identifying good metastable core sets of the irreversible Markov process associated with $\vect P$ is described in detail in Ref.~\cite{sarich2014utilizing}; here we just provide the fundamental idea behind it: If  strong metastable sets $C_j$, $j=1,\ldots,K$ exist they should have one main property: When starting from a state in $C_i$ the expected hitting time of a state in $C_i$ should be much shorter than that of any state in one of the other sets $C_j$, $j\not=i$; in fact, the hitting time distribution should exhibit roughly constant levels in each set $C_j$ and should vary significantly in the transition region $C=\Omega\setminus\cup_j C_j$ between the metastable sets. If starting from some randomly chosen initial states, one thus can identify the metastable core sets and the transition region by analyzing the hitting time distributions. This procedure is similar to the procedures used for reversible processes \cite{PCCAplus,A19-1,prinz2011markov} but utilizes hitting time distributions instead of any eigenvector information.

The metastable core sets identified by this procedure based on the estimate of $\vect P$ are illustrated in Fig.~\ref{fig:cluster} and denoted by $C_{\confaa}$ (green), $C_\beta$ (yellow) and $C_{\confc}$ (red). They correspond to the centers of the wells in the free energy landscapes shown in Fig.~\ref{fig:num-1} and to the
right-handed alpha-helix, beta-sheet and left-handed alpha-helix conformations of the peptide, respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{First mean hitting times}
\label{sec:alanine-fmht}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig-fht-1.eps}
  \includegraphics[width=0.23\textwidth]{fig-fht-msm-1.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-fht-2.eps}
  \includegraphics[width=0.23\textwidth]{fig-fht-msm-2.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-fht-3.eps}
  \includegraphics[width=0.23\textwidth]{fig-fht-msm-3.eps}\\
  \vskip -.5cm
  \caption{Comparisons of the first mean hitting time (FMHT) based on NEMD
    simulation (left column) and discretized dynamics (right column).  From top
    to bottom the first mean hitting times to the core sets $C_{\confaa}$, $C_{\beta}$,
    and $C_{\confc}$ are shown, respectively}
  \label{fig:num-6}
\end{figure}

The first mean hitting time as a function of the dihedral angles $(\phi,\psi)$,
is defined by the expected first time needed for hitting a certain core set $C_j$,
$j\in\{\alpha_R,\beta,\alpha_L\}$ conditioned on starting from the
conformation $(\phi,\psi)$, more exactly from equilibrium conformations $(\phi,\psi)\in\Omega_i$.  Since the largest first mean hitting
time (starting from states in core set $\confaa$ and hitting $\confc$) is longer than
600~ps the results will be biased if we use the NEMD trajectories of length 4000~ps for brute force Monte Carlo estimation of the hitting time. 
Therefore, we base our Monte Carlo estimate on 100 NEMD
trajectories of $2\times 10^5$~ps instead. For comparison we compute the first mean hitting
time of the discretized dynamics via its transition matrix $\vect P$: the first mean hitting time $h_{C_j}(i)$ of core set $C_j$ starting in $\Omega_i$ can  be computed by means of solving the linear problem \cite{A19-31}
\[
(\vect P-\id) h_{C_j}(i) = -1,\qquad \mathrm{if} \, C_j\cap \Omega_i=\emptyset.
\] 
The resulting first mean hitting times are presented in Fig.~\ref{fig:num-6}.  The
good consistency between the NEMD estimate and the discretized Markov process
$\tilde X_{m}$ indicates a good approximation quality.
One should note that the NEMD estimate of the first mean hitting time is subject to statistical sampling errors while the first mean hitting times $h_{C_j}$ only contain the statistical errors coming from the estimation of $\vect P$. 
Thus, using $P$ helps in calculating the observables
in a smoother  manner (less statistical error, no additional sampling).
Additionally, the computational cost of the
discretized process, if the cost for estimating $\Phi(T)$ is not included, is
essentially smaller than NEMD:
the computation of $h_{C_j}$ is an issue of milliseconds on a laptop, while the
NEMD trajectories took $1.6\times 10^4$ core hours for Intel Xeon E5-4650 CPUs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Forward and backward committors}
\label{sec:alanine-committor}
\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig-commitor-fw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-fw-msm-1.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-commitor-bw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-bw-msm-1.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-commitor-diff-1.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-diff-msm-1.eps}
  \vskip -.5cm
  \caption{Forward $q^\fwd_{\confaa}$ and backward 
    $q^\bwd_{\confaa}$ committors
    and their difference $q^\fwd_{\confaa} - q^\bwd_{\confaa}$
    computed from the NEMD trajectories (left
    column) and the  discretized dynamics (right column).}
  \label{fig:num-3}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig-commitor-fw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-fw-msm-2.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-commitor-bw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-bw-msm-2.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-commitor-diff-2.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-diff-msm-2.eps}\\
  \vskip -.5cm
  \caption{Forward $q^\fwd_{\beta}$ and backward
    $q^\bwd_{\beta}$ committors
    and their difference  $q^\fwd_{\beta} - q^\bwd_{\beta}$ 
    computed from NEMD trajectories (left
    column) and the  discretized dynamics (right column).}
  \label{fig:num-4}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig-commitor-fw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-fw-msm-3.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-commitor-bw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-bw-msm-3.eps}\\
  \vskip -.7cm
  \includegraphics[width=0.23\textwidth]{fig-commitor-diff-3.eps}
  \includegraphics[width=0.23\textwidth]{fig-commitor-diff-msm-3.eps}\\
  \vskip -.5cm
  \caption{Forward $q^\fwd_{\confc}$ and backward $q^\bwd_{\confc}$
    committors
    and their difference  $q^\fwd_{\confc} - q^\bwd_{\confc}$ 
    computed from NEMD trajectories (left
    column) and the  discretized dynamics (right column).}
  \label{fig:num-5}
\end{figure}


Committors are very important statistical properties of Markov processes \cite{PrinzHeldSmithNoe_Committorprep,PNAS09}, and play
an important role in MSM building \cite{A19-31,A19-29,djurdjevac2010markov} (see below). Therefore, it is worth
checking if the discretized process $\tilde X_m$ reproduces the NEMD committors.
The forward committor $q^\fwd_j(i)$ of a core set $C_j,\
j\in\{\confaa, \beta, \confc\}$ is defined as the probability of
visiting core set $C_j$ next conditioned on starting at conformation
$(\phi,\psi)\in\Omega_i$.  The backward committor $q^\bwd_j(i)$ of a
core set $C_j,\ j\in\{\confaa, \beta, \confc\}$ is defined as the
probability of last coming from $C_j$ conditioned on having arrived presently at
configuration $(\phi,\psi)\in\Omega_i$.
For reversible Markov processes, the
forward and backward committors are identical, however, this is in
general not the case for irreversible processes.
The committors estimated from NEMD simulations ($20000$ trajectories, $4000$~ps each) are compared with
those computed from $P$ by means of solving the linear equations (\ref{qfwd}) and (\ref{qbwd}).
Fig.~\ref{fig:num-3}--\ref{fig:num-5} presents both
committors as well as their difference corresponding to different core sets.
The committors of the discretized process are in good consistency with those of
the NEMD simulations. The non-zero values in the committor differences
indicate that the NEMD process, projected on the discretized
dihedral angle space, is irreversible, and
the discretized process is able to correctly describe this irreversiblity.
In addition, and subsequently of central importance, the accurate reproduction of the committors indicates it is reasonable to build the 
MSM out of the committors of the  discretized process.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{MSM building and validation}

Following the process described in Sec.~\ref{sec:build-msm}, we are able to build a 
three state MSM for the externally driven alanine dipeptide system,
where the quasi-stationary probability distribution $\mu$, the three core sets, and the forward and backward committors are
estimated as described above, and the MSM transition matrices $\hat P$, $\hat{M}$, and $\hat{T}$ are then evaluated using Eq.~\eqref{eq:msm-tmatrix-00}, \eqref{eq:msm-ht-1} and \eqref{eq:msm-hm-1}, correspondingly.
Alternatively, the MSM  transition matrix $\hat P$ is calculated directly from the NEMD trajectories using Eq.~\eqref{hatP_prob} (very good agreement with the one computed from the committors).
The leading eigenvalues of $P=\myphi^{\top}(T)$ are compared with those of $\hat P$ and $\hat{M}^{-1}\hat{T}$ in
Tab.~\ref{tab:tmp1}.
Without surprising, the two approaches for MSM building are consistent.
The MSM is able to accurately reproduce
the largest non-trivial eigenvalue, which means a precise reproduction
of the longest non-trivial implied timescale. The accuracy of the second non-trivial
timescale is not as good as the first, but is still acceptable.
The reason
for the lower accuracy may also be that
the corresponding time scale is 26.5~ps (calculated by $-T/\log(\lambda_2)$),
which is NOT significantly longer than the temporal resolution given by the period $T=10$~ps of the external driving force.
The difference between the eigenvalues of $\hat P$ and $\hat{M}^{-1}\hat T$
  can be taken as an indication for the non-Markovianity of the milestone process $\hat X_m$. This
  non-Markovianity seems to have stronger influence on the second non-trivial timescale in comparison to the first one; this may be caused by shorter decorrelation timescales due to weaker metastability of the core sets involved.
Numerically the two MSM transition matrices are:
\[
\hat{M}^{-1}\hat{T}=\left(\begin{array}{ccc}
   0.860 &   0.133 &   0.008 \\
    0.192  &  0.775  &  0.033\\
    0.019   & 0.066 &   0.915
\end{array}
\right),\qquad \hat{P}=\left(\begin{array}{ccc}
   0.882 &   0.110 &   0.008 \\
    0.158  &  0.815  &  0.028\\
    0.023   & 0.055 &   0.922
\end{array}
\right),
\]
from which we see that  the left-handed alpha-helix conformations of the peptide exhibits the strongest metastability. 

It is worth noting that although the discretized process $\tilde X_m$ is irreversible,
the MSM built out of it is almost reversible:
The magnitude of the anti-symmetric part of the
matrix $\textrm{diag}(\hat \mu)\cdot \hat P$ is only of order $10^{-4}$.

\begin{table}
  \centering
  \caption{
    Comparison of second and third eigenvalues of $\vect P$ and $3\times 3$ MSM transition matrices $\hat{P}$ and $\hat{M}^{-1}\hat{T}$, respectively, from the two different MSM approaches.
  }
  \begin{tabular*}{0.45\textwidth}{@{\extracolsep{\fill}}c rrr}\hline\hline
      &  $\lambda_2$ & $\lambda_3$ & $\lambda_4$ \\\hline
    $P$                 &0.905  &0.668 & 0.551       \\
    $\hat P$     & 0.909  &0.710 & --       \\
    $\hat{M}^{-1}\hat{T}$    & 0.901  &0.649 & --       \\
    \hline\hline
  \end{tabular*}
  \label{tab:tmp1}
\end{table}

% \begin{figure}
%   \centering
%   \includegraphics[width=0.23\textwidth]{fig-eig-vec-2.eps}
%   \includegraphics[width=0.23\textwidth]{fig-eig-vec-3.eps}
%   \includegraphics[width=0.23\textwidth]{fig-eig-vec-4.eps}\\
%   \caption{The eigenfunctions of $P$.}
%   \label{fig:num-6}
% \end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig-coreset-prob.eps}
  \caption{Comparison of NEMD and MSM long-term kinetics of alanine
    dipeptide in an oscillatory electric field. The plots show the
    time-dependent probability $\hat p_j(t)$ to be assigned to
    core set $C_j$ (corresponding to the observable $\mathcal A$ given
    in (\ref{A}) with $\alpha_j=1$ and $\alpha_k=0$ for $k\not=
    j$). Solid lines are from brute force NEMD simulations, while the
    dashed lines are from our MSM.}
  \label{fig:num-7}
\end{figure}

In fact, $\hat{P}$ can be considered as the fingerprint of the long-term kinetics (cf.~\cite{A19-39,PrinzKellerNoe_PCCP11_Perspective}) of alanine dipeptide in an oscillatory electric field.
In order to provide further validation of this statement, we study  time-dependent expectation values of
the form
\begin{align}
  \mathcal A(t) = \langle A(i)\rangle_t = \sum_{i\in S} A(i) p(i,t),
\end{align}
where $p(i,t)=\prob(X_t=i)$ is the probability to be in set $\Omega_i$ at time $t$ as governed by the Master equation, and the observable $\mathcal A$ is  spanned by the backward
committors, i.e.,
\begin{align}\label{A}
  A(i) = \sum_{j=1}^K \alpha_j q^\bwd_j(i).
\end{align}
Then
\begin{align}\nonumber
  \mathcal A(t) &=
  \sum_{i\in S} \sum_{j=1}^K \alpha_j q^\bwd_j(i)  p(i,t)=\sum_{i\in S} \sum_{j=1}^K \alpha_j \prob (\hat X_t = j \vert X_t = i) \prob (X_t = i) \\
  & =
  \sum_{i\in S} \sum_{j=1}^K \alpha_j \prob (\hat X_t = j ,X_t = i)  =
  \sum_{j=1}^K \alpha_j \prob (\hat X_t = j) 
 =
   \sum_{j=1}^K \alpha_j \,\hat p_j (t), \label{eq:num-28}
\end{align}
where the time-dependent probability $\hat{p}_j(t)$ of being assigned to MSM macrostate $j$ at time $t$ can be computed  by means of the MSM via simple matrix multiplications using (\ref{eq:num-29}).

In Fig.~\ref{fig:num-7} we compare the numerical calculation of $\hat p_j (mT), \ m\in\mathbb N$ from NEMD and MSM calculations.
In the NEMD case, the identity  $\hat p_j (mT) = \sum_{i\in S}  q^\bwd_j(i)  p(i,mT) $ is used, and
the backward committor and the probability density on the R.H.S.
are estimated directly from the
NEMD trajectories. For the MSM, the projection of the initial probability is applied, $\hat p_j (0) = \sum_{i\in S}  q^\bwd_j(i)  p(i,0) $, then
the time-dependent probability at $mT$ is generated by Eq.~\eqref{eq:num-29}, i.e., by simple matrix multiplication. The agreement is almost perfect.
% The projected probability, e.g.~$\hat p (l', mT)$ is calculated
% by Eq.~\eqref{eq:num-28} letting $\alpha_l = \delta_{l'l}$.

% \recheck{Han: Here we have $p_j(t)$, $p(j,t)$ and $\hat p_j (0)$. That's a little confusing since I do not see a clear distinction between the former two. What can we do? What do you want to express?}


\section{Concluding remarks and discussion}
\label{sec:conclusion}

\begin{figure}
  \centering
  \includegraphics[width=0.48\textwidth]{flowchart2.eps}
  \caption{Flowchart showing optional procedures for MSM building based on NEMD trajectories. A lighter color indicates
  a "coarser'' approximation to the original NEMD dynamics. Please note that "equivalence" only means that the respective procedures result in the same matrix/MSM if one assumes perfect sampling.}
  \label{fig:flowchart}
\end{figure}

In this paper we proposed methods of MSM building for a periodically driven
non-equilibrium system. We demonstrated their validity and performance by application to  alanine dipeptide under an oscillatory electric field. We showed that the proposed 
methods allow for capturing the long-time behavior of the original
non-equilibrium dynamics.

We provided effective methods for discretizing the original NEMD dynamics
both temporally and spatially; the end-product is a time-homogeneous, in general irreversible Markov jump process.
Discretization was done via two equivalent approaches:
either by a two-step version,
i.e.~first spatial and then temporal discretization,
or a one-step version that involves both discretizations simultaneously.
These two version are shown by the left-most and middle branches of the diagram  in Fig.~\ref{fig:flowchart}.

Although the end-product of the two-step and one-step discretization procedures are formally equivalent,
it is clear that the one-step discretization does not preserve any information
\emph{within} one period, because only the states
at integral multiples of the period of the external forcing are considered. This is no serious problem
whenever the long-time behavior of the system is of interest, and
the corresponding timescales are significantly longer than one
period. However, if the timescale of interest 
is comparable to the period, the two-step
discretization is preferable because it allows to recover the dynamics between multiples of
the period. 

Building the final MSM based on the time-homogeneous discretized dynamics is straightforward by
using Eq.~\eqref{eq:msm-tmatrix-00} and a set of core sets that are
derived from the discretized dynamics.  In application to alanine dipeptide numerical
results show that a three-state MSM can reproduce the leading non-trivial
eigenvalue with very good accuracy, and the second non-trivial
eigenvalue with acceptable accuracy. The lower accuracy regarding the
second non-trivial eigenvalue may result from the fact that the second
slowest timescale is not significantly longer than the period. By means of
this three-state MSM we can reproduce, with almost perfect
accuracy, the time-evolution of the population of the main conformations induced by the periodic forcing when starting from the  
equilibrium distribution of the unforced molecular system.


The right-most branch in Fig.~\ref{fig:flowchart} presents an
equivalent, and seemingly
much simpler alternative to the middle branch: MSM building directly from NEMD trajectories.
In practice, however, this method may not be applicable, because
it requires pre-defined core sets, and the identification of core sets 
usually is no trivial task, especially for molecular dynamics under non-equilibrium conditions.
This task is substantially simplified when an accurate time-homogeneous discretization 
to the original NEMD process is available (that is, has been constructed in advance).
In the present work, we computed the core sets by
finding almost constant levels of the hitting time distribution for the discretized dynamics. 
This procedures is itself a novelty since it does not require any spectral information like eigenvectors as in standard approaches, cf.~\cite{prinz2011markov,A19-1}.

% This method only works for the discretized dynamics. and its
% Therefore, a good discretization is  usually a must for computing the core set.

In this paper, we mainly focus on the development of the first available methods for MSM
building in non-equilibrium systems.
However, the application of these methods to the conformation dynamics of alanine dipeptide results in some observations that are interesting in itself: Under an
oscillatory EF, the population of the left-handed $\alpha$-helical conformation
significantly increases relative to the equilibrium population
(see also the discussions in Ref.~\cite{wang2014exploring}),
and the leading relaxation timescale of the system is much shorter than in the equilibrium case.

A final remark concerning the utilization of the proposed methodology may be in order. 
Based on an MSM for a given periodic forcing optimal control problems may come into reach:
Using available methods like non-equilibrium
linear response theory~\cite{wang2013linear} or computational alchemy for MSMs ~\cite{schutte2014markov} one can construct the MSM for slightly changed parameters (e.g., period and amplitude) of the external forcing by appropriate reweighting of the MSM for the given forcing. This in principle allows for  answering questions like the following:
For which parameters of the external forcing does one achieve maximal population of  the left-handed $\alpha$-helix?
Such questions, however, will
be treated in the future studies.


  



\appendix

\section{Reversibility of the original dynamics}
\label{sec:app-revs}

We consider the governing dynamics Eq.~\eqref{eq:disc-1}.
For simplicity we denote the force by $F(x_t,t) = -\nabla_x V(x_t)+ E(t)D(x_t) $.  We denote $\sigma =  \sqrt{2\beta^{-1}} $.
According to Girsanov, we have
\begin{align}
  \label{eq:tmp8}
  \frac{dp[x_t]}{dw[x_t]}  =
  \exp \bigg\{
  \frac 1{\sigma^2}\int_0^T F(x_t,t) dx_t -
  \frac1{2\sigma^2}\int_0^T F^2(x_t,t) dt
  \bigg\}
\end{align}
where $dp$ is the probability measure of trajectory $x_t$, while $dw$ is the
probability measure of the standard Wiener process $dx_t = \sigma dw_t$.
Assuming a discretization of the
stochastic process at time $0 < t_1 < t_2 < \cdots < t_N = T$, where
$t_i = iT / N$. We denote $x_i = x_{t_i}$, and $w_i = w_{t_i}$, then we have,
in the sense of Ito,
\begin{align}\label{eq:tmp9}
  \frac{dp[x_t]}{dw[x_t]}  \approx
  \exp\bigg\{\frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{i},t_{i})(x_{i+1} - x_i) -\frac1{2\sigma^2}\sum_{i=0}^{N-1}F^2(x_i,t_i)\dt\bigg\} 
\end{align}
Now, consider a conjugate trajectory $x^\dagger_t = x_{T-t}$ that starts at $x_T$, ends at $x_0$. The conjugate dynamics is driven by  $F^\dagger(x^\dagger_t,t) = F(x^\dagger_t, T-t)$.
Writing the Girsanov for the conjugate dynamics
\begin{align}\label{eq:dagger-0}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\ \nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},T - t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, T-t_i)]^2\dt\bigg\} \\\nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{N-i},t_{N-i})(x_{N-i-1} - x_{N-i}) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x_{N-i},t_{N-i})]^2\dt\bigg\} \\
  = \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=N}^{1} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=N}^{1}F^2(x_i,t_i)\dt\bigg\}
\end{align}
% Therefore,
% \begin{align}\nonumber
%   \frac{dp[x^\dagger_t]}{dw[x^\dagger_t]}  =
%   \,&
%   \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]} \\\nonumber
%   \approx\,&
%   \exp\bigg\{
%   \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
%   \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\\nonumber
% \end{align}
Since it is obvious that $dw[x^\dagger_t] / dw[x_t] = 1$,
\begin{align}
  \label{eq:tmp10}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x_t]}
  \approx \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=1}^{N} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=1}^{N}F^2(x_i,t_i)\dt\bigg\}
\end{align}
The difference between the single trajectory probabilities is
\begin{align}\label{eqn:tmp12}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
  -\frac1{\sigma^2}\sum_{i=1}^{N-1}
  \bigg[
  F(x_i,t_i)(x_{i+1} - x_{i}) + F(x_i,t_i)(x_{i} - x_{i-1})
  \bigg]
  \bigg\}
\end{align}
Assuming the smoothness of the external perturbation, consider the differentiation:
\begin{align}\nonumber
  F(x_{i},t_{i}) - F(x_{i-1},t_{i-1}) =
  &\,
  F(x_{i},t_{i}) - F(x_{i-1},t_{i}) + F(x_{i-1},t_{i}) -  F(x_{i-1},t_{i-1})\\\nonumber
  =&\,
  \nabla_x F(x_{i-1},t_{i})(x_i - x_{i-1}) + \mo(\dt) \\\label{eqn:tmp13}
  =&\,
  \nabla_x F(x_{i-1},t_{i-1})(x_i - x_{i-1}) + \mo(\dt)
\end{align}
The second order expansion w.r.t.~$x_i - x_{i-1}$ is of order $\dt$, so it is absorbed into $ \mo(\dt)$.
Then the \eqref{eqn:tmp12} becomes
\begin{align}\label{eqn:tmp14}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\sum_{i=0}^{N-1} F(x_i,t_i)(x_{i+1} - x_{i}) 
 -\frac1{\sigma^2}\sum_{i=0}^{N-1}\nabla_xF(x_i,t_i)(x_{i+1} - x_{i})^2
 \bigg\}
\end{align}
Using the identity
$  dt = (dw_t)^2 = {\sigma^{-2}} dx_t^2$,
Eq.~\eqref{eqn:tmp14} is written in the integral form
\begin{align}\label{eqn:tmp14-0}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\int_0^T F(x_t,t) dx_t
 -\int_0^T\nabla_xF(x_t,t)dt
 \bigg\}  
\end{align}
One would not have the second integral on the exponent if the first integral of the exponent were defined in the sense of Stratonovich.

We notice that
\begin{align}\nonumber
  dV(x, t) = &\, \frac{\partial V}{\partial x} dx + \frac{\partial V}{\partial t} dt\\\nonumber
  =&\,
  \frac12 \sigma^2 \nabla^2_x V dt +  \nabla V dx_t + \frac{\partial V}{\partial t} dt \\
  =&\,
  -\frac12 \sigma^2 \nabla_x F dt -  F dx_t + \frac{\partial V}{\partial t} dt
\end{align}
Eq.~\eqref{eqn:tmp14-0} becomes
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \exp\bigg\{
  \frac2{\sigma^2}\bigg[
  V(x_T,T) - V(x_0,t_0) - \int_0^T\partial_tV(x_t,t)dt
  \bigg]
  \bigg\}
\end{align}
% According to the  Einstein relation, the temperature $\mathcal T = \sigma^2/2$, we denote $\beta = 1/{\mathcal T} = 2/\sigma^2$.
Take the limit of infinite small time interval, notice the equilibrium
invariant probability density with respect to potential $V(x,0)$ satisfies $\mymu(x) \propto e^{-\beta V(x,0)}$, and replace $\sigma^2$ by $2\beta^{-1}$,
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \frac{\mymu(x_0)}{\mymu(x_T)}\times
  \exp\bigg\{
  - \beta\int_0^T\partial_tV(x_t,t)dt
  \bigg\}
\end{align}

\subsection{Irreversibility of the periodic time-symmetric dynamics}

In Eq.~\eqref{eq:dagger-0}, we assume the periodicity of the perturbation $F(x,t) = F(x,t+T)$, and the symmetry of the external perturbation, i.e.~$F(x, -t) = F(x, t)$, we have
\begin{align}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, t_i)]^2\dt\bigg\}  
\end{align}
By changing notation $x^\dagger$ back to $x$, and comparing with~\eqref{eq:tmp9}, the reversed dynamics is subject to the Eq.~\eqref{eq:disc-1},
i.e.~$dp^\dagger = dp$.
Therefore
\begin{align}\nonumber
  p(x_0,T\vert x_T,0)
  =&\,\int_{\mc\{x_T,0;x_0,T\}}
  dp[x^\dagger_t] \\\nonumber  
  =&\,
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\nonumber
  =&\,
  % \lim_{N\rightarrow\infty} 
  % \frac{1}{(2\pi\sigma^2\dt)^{(N-1)/2}} \int dx_{N-1}\cdots\int dx_{1}
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\label{eqn:tmp18}
  = &\,
  \frac{\mu(x_0)}{\mu(x_T)}
  \int_{\mc\{x_0,0;x_T,T\}}
  \exp\bigg\{
  -\beta\int_0^T \partial_t V(x_t,t)dt 
  \bigg\} \cdot dp[x_t]
\end{align}
where $\mc\{x_0,0;x_T,T\}$ denotes all continuous trajectories starting at $x_0$ and ending at $x_T$.
If $\partial_t V = 0$, i.e.~equilibrium, we have
\begin{align}
  p(x_0,T\vert x_T,0)e^{-\beta V(x_T,T)} =  p(x_T,T\vert x_0,0) e^{-\beta V(x_0,0)},
\end{align}
which proves the reversibility of the equilibrium dynamics.
The term
\begin{align}
  W[x_t] = \int_0^T \partial_t V(x_t,t)dt
\end{align}
is the non-equilibrium work associated to all possible
the dynamics $x_t$ starting at $x_0$ and ending at $x_T$ (see e.g.~Ref.~\cite{seifert2012stochastic}).
Therefore Eq.~\eqref{eqn:tmp18} is the detailed Jarzynski relation.
% Now the problem becomes if we can write a nice form (e.g.~the difference of a state function measured at $x_T$ and $x_0$) for the non-equilibrium work.
Noticing that
\begin{align}
  \label{eq:tmp21}
  p(x_T,T\vert x_0,0) = \int_{\mc\{x_0,0;x_T,T\}}dp[x_t],
\end{align}
From Eq.~\eqref{eqn:tmp18} we have
\begin{align}
  \label{eq:tmp22}
  \frac{p(x_0,T\vert x_T,0)}{  p(x_T,T\vert x_0,0)  }
  =
  \frac{\mu(x_0)}{\mu(x_T)}
  \mathbb E_{x_0\rightarrow x_T} [e^{-\beta W}]
\end{align}
% Maybe we want a more symmetric form.
% The expectation value of the reversed dynamics reads,
% \begin{align}\nonumber
%   \mathbb E_{x^\dagger_0\rightarrow x^\dagger_T} [e^{-\beta W^\dagger}]
%   =\,&
%   \int_{\mc\{x^\dagger_0,0;x^\dagger_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x^\dagger_t,t)dt 
%   \bigg\} \cdot dp[x^\dagger_t]   \\\nonumber
%   =\,&
%   \int_{\mc\{x_0,0;x_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x_{T-t},t)dt 
%   -\beta\int_0^T \partial_t V(x_{t},t)dt 
%   \bigg\}
%   \cdot dp[x_t]   \\  \nonumber
%   =\,&
%   \int_{\mc\{x_T,0;x_0,T\}}
%   \exp\bigg\{
%   \beta\int_0^T \partial_t V(x_t,t)dt 
%   \bigg\} \cdot dp[x_t]   \\
%   \label{eq:tmp23}
%   = \,&
%   \mathbb E_{x_0\rightarrow x_T} [e^{- 2\beta W}]  
% \end{align}
% Noticing that \eqref{eq:tmp22}  is true for the reversed dynamics, we have
% \begin{align}
%   \label{eq:24}
%   \frac{p(x_T,T\vert x_0,0)}{  p(x_0,T\vert x_T,0)  }
%   =
%   \frac{\mu(x_T)}{\mu(x_0)}
%   \mathbb E_{x_T\rightarrow x_0} [e^{\beta W}]  
% \end{align}


\section{Computation of $\hat{T}$ and $\hat{M}$ directly from trajectories}
\label{sec:app-prove}

In order to show how to compute $\hat{T}$ and $\hat{M}$ directly from trajectories let us start by denoting the first hitting time of set $A$ starting at time $t$ by $h_t(A)$.
In addition we define $\hat q^\bwd_j (i) = \prob (X_t = i \vert \hat X_t =
j)$, and always assume $t = mT$. Then due to the Bayes' Theorem we have
\begin{align}
  \hat q^\bwd_j (i) =
  \frac{\prob (\hat X_t = j \vert X_t = i) \prob(X_t = i)}{ \prob(\hat X_t = j) } =
  \frac{q^\bwd_j(i) \mu(i)}{\hat \mu_j}
\end{align}
Then
\begin{align}\nonumber
  \prob& [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) \,\vert\, \hat X_t = j\,]\\\nonumber
  &=
  \sum_{i=1}^N
  \frac{\prob [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) , X_t = i, \hat X_t = j\,]}
  { \prob(\hat X_t = j )} \\\nonumber
  &=
  \sum_{i=1}^N
  {\prob [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) \,\vert\, X_t = i, \hat X_t = j\,]}\,
  \hat q^\bwd_j(i) \\\nonumber
  &=
  \sum_{i=1}^N
  {\prob [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) \,\vert\, X_t = i\,]}\,
  \hat q^\bwd_j(i)  \\\label{eq:appb-m}
  &=
  \sum_{i=1}^N
  q^\fwd_k(i) \frac{q^\bwd_j(i) \mu(i)}{\hat \mu_j} =\frac{\langle q_j^\bwd, q_k^\fwd\rangle_\mu}{\hat \mu_j}={\hat M}_{jk}
\end{align}
where the third equation holds because of the Markovianity of the process $X_t$, and the fourth equation is due to the definition of the forward committor.
The interpretation of the result is that when starting with the milestone process in state $j$ we have to determine the fraction of all trajectories that hit core set $C_k$ first of all core sets to estimate $\hat{M}_{jk}$.

To see the same for $\hat{T}$, we first need
\begin{align*}
  \prob & [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \,\vert\, X_t = i\,]\\
  &=
  \sum_{l=1}^N
  \frac{\prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l), X_{t+T} = l, X_t = i\,]}
  {\prob (X_t = i)} \\
  &=
  \sum_{l=1}^N
  {\prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \vert X_{t+T} = l, X_t = i\,]}\,
  {\prob( X_{t+T} = l \vert X_t = i)}\\
  & =
  \sum_{l=1}^N
  {\prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \vert X_{t+T} = l\,]}\,
  {\prob( X_{t+T} = l \vert X_t = i)}  = \sum_{l=1}^N
  q^\fwd_k(l) P_{il}
\end{align*}
We used the Markovianity of $X_T$ at the third equation,
and the time-homogeneity in the fourth equation.
Therefore, following the same procedure as before we have
\begin{align}\label{eq:appb-t}
  \prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \,\vert\, \hat X_t = j\,]=
  \sum_{i=1}^N\sum_{l=1}^N
  q^\fwd_k(l) P_{il}
  \frac{q^\bwd_j(i) \mu(i)}{\hat \mu_j} = \frac{\langle q_j^\bwd, P q_k^\fwd\rangle_\mu}{\hat \mu_j}  = {\hat T}_{jk}
\end{align}
Thus, when starting with the milestone process in state $j$ at some time $t$ we have to determine the fraction of all trajectories of length at least $T$ that hit core set $C_k$ first of all core sets to estimate $\hat{T}_{jk}$.

\section{Prove of the identity $\hat P = \hat T\hat M^{-1}$}
\label{sec:app-ptm}
In this section we prove the identity  $\hat P = \hat T\hat M^{-1}$. Starting from the
result Eq.~\eqref{eq:appb-t},
\begin{align*}
  \hat T_{jk} &=
  \prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \,\vert\, \hat X_t = j\,]\\
  &=
  \frac{\prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l), \hat X_t = j\,] }{\prob(\hat X_t = j)}\\
  & =
  \sum_l \frac{\prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l), \hat X_{t+T} = l, \hat X_t = j\,] }{\prob(\hat X_t = j)}\\
  & =
  \sum_l \prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l)\vert \hat X_{t+T} = l, \hat X_t = j\,] \hat P_{jl}\\  
  & =
  \sum_l \prob [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l)\vert \hat X_{t+T} = l\,] \hat P_{jl}\\
  &= 
  \sum_l  \hat P_{jl}\hat M_{lk}.
\end{align*}
This proves the identity $\hat P = \hat T\hat M^{-1}$.
Notice that in the fifth equation we assumes the Markovianity of the milestone process $\hat X_m$. In the sixth equation we use the result Eq.~\eqref{eq:appb-m}, and the time-homogeneity of the milestone process.


\begin{thebibliography}{10}

\bibitem{bohr2000microwave}
Henrik Bohr and Jakob Bohr.
\newblock Microwave-enhanced folding and denaturation of globular proteins.
\newblock {\em Phys. Rev. E}, 61(4):4310, 2000.

\bibitem{bohr2000microwave-1}
Henrik Bohr and Jakob Bohr.
\newblock Microwave enhanced kinetics observed in ord studies of a protein.
\newblock {\em Bioelectromagnetics}, 21(1):68--72, 2000.

\bibitem{dePomerai2000cell}
David de~Pomerai, Clare Daniells, Helen David, Joanna Allan, Ian Duce, Mohammed
  Mutwakil, David Thomas, Phillip Sewell, John Tattersall, Don Jones, and Peter
  Candido.
\newblock Cell biology: Non-thermal heat-shock response to microwaves.
\newblock {\em Nature}, 405:417--418, 2000.

\bibitem{dePomerai2003microwave}
David~I de~Pomerai, Brette Smith, Adam Dawe, Kate North, Tim Smith, David~B
  Archer, Ian~R Duce, Donald Jones, and E~Peter~M Candido.
\newblock Microwave radiation can alter protein conformation without bulk
  heating.
\newblock {\em FEBS letters}, 543(1):93--97, 2003.

\bibitem{mancinelli2004non}
Fabrizio Mancinelli, Michele Caraglia, Alberto Abbruzzese, Guglielmo
  d'Ambrosio, Rita Massa, and Ettore Bismuto.
\newblock Non-thermal effects of electromagnetic fields at mobile phone
  frequency on the refolding of an intracellular protein: Myoglobin.
\newblock {\em J. Cell. Biochem.}, 93(1):188--196, 2004.

\bibitem{inskip2001cellular}
Peter~D Inskip, Robert~E Tarone, Elizabeth~E Hatch, Timothy~C Wilcosky,
  William~R Shapiro, Robert~G Selker, Howard~A Fine, Peter~M Black, Jay~S
  Loeffler, and Martha~S Linet.
\newblock Cellular-telephone use and brain tumors.
\newblock {\em N. Engl. J. Med.}, 344(2):79--86, 2001.

\bibitem{bekard2013electric}
I.~Bekard and D.E. Dunstan.
\newblock Electric field induced changes in protein conformation.
\newblock {\em Soft Matter}, pages~--, 2014.

\bibitem{budi2005electric}
A.~Budi, F.S. Legge, H.~Treutlein, and I.~Yarovsky.
\newblock Electric field effects on insulin chain-b conformation.
\newblock {\em J. Phys. Chem. B}, 109(47):22641--22648, 2005.

\bibitem{budi2007effect}
A.~Budi, F.S. Legge, H.~Treutlein, and I.~Yarovsky.
\newblock Effect of frequency on insulin response to electric field stress.
\newblock {\em J. Phys. Chem. B}, 111(20):5748--5756, 2007.

\bibitem{budi2008comparative}
Akin Budi, F~Sue Legge, Herbert Treutlein, and Irene Yarovsky.
\newblock Comparative study of insulin chain-b in isolated and monomeric
  environments under external stress.
\newblock {\em J. Phys. Chem. B}, 112(26):7916--7924, 2008.

\bibitem{astrakas2012structural}
Loukas~G Astrakas, Christos Gousias, and Margaret Tzaphlidou.
\newblock Structural destabilization of chignolin under the influence of
  oscillating electric fields.
\newblock {\em J. Appl. Phys.}, 111(7):074702--074702, 2012.

\bibitem{damm2012can}
Markus Damm, Christoph Nusshold, David Cantillo, Gerald~N Rechberger, Karl
  Gruber, Wolfgang Sattler, and C~Oliver Kappe.
\newblock Can electromagnetic fields influence the structure and enzymatic
  digest of proteins? a critical evaluation of microwave-assisted proteomics
  protocols.
\newblock {\em J. Proteomics}, 75:5533--5543, 2012.

\bibitem{english2009nonequilibrium}
N.J. English, G.Y. Solomentsev, and P.~O'Brien.
\newblock Nonequilibrium molecular dynamics study of electric and low-frequency
  microwave fields on hen egg white lysozyme.
\newblock {\em J. Chem. Phys.}, 131:035106, 2009.

\bibitem{solomentsev2012effects}
G.Y. Solomentsev, N.J. English, and D.A. Mooney.
\newblock Effects of external electromagnetic fields on the conformational
  sampling of a short alanine peptide.
\newblock {\em J. Comput. Chem.}, 33:917--923, 2012.

\bibitem{wang2014exploring}
Han Wang, Christof Sch{\"u}tte, Giovanni Ciccotti, and Luigi Delle~Site.
\newblock Exploring the conformational dynamics of alanine dipeptide in
  solution subjected to an external electric field: {A} nonequilibrium
  molecular dynamics simulation.
\newblock {\em Journal of Chemical Theory and Computation}, 10(4):1376--1386,
  2014.

\bibitem{A19-31}
Ch. Sch\"utte and M.~Sarich.
\newblock {\em Metastability and {{Markov}} State Models in Molecular Dynamics:
  Modeling, Analysis, Algorithmic Approaches}, volume~24 of {\em Courant
  Lecture Notes}.
\newblock American Mathematical Society, December 2013.

\bibitem{prinz2011markov}
J.H. Prinz, H.~Wu, M.~Sarich, B.~Keller, M.~Senne, M.~Held, J.D. Chodera,
  C.~Sch{\"u}tte, and F.~No{\'e}.
\newblock {{Markov} models of molecular kinetics: Generation and validation}.
\newblock {\em J. Chem. Phys.}, 134:174105, 2011.

\bibitem{A19-1}
G.~R. Bowman, V.~S. Pande, and F.~No\'e, editors.
\newblock {\em An Introduction to {{Markov}} State Models and Their Application
  to Long Timescale Molecular Simulation}, volume 797 of {\em Advances in
  Experimental Medicine and Biology}.
\newblock Springer, 2014.

\bibitem{A19-49}
M.~Senne, B.~Trendelkamp-Schroer, A.~S. J.~S. Mey, Ch. Sch\"utte, and F.~No\'e.
\newblock Emma - a software package for {{Markov}} model building and analysis.
\newblock {\em J. Chem. Theory Comput.}, 8:2223--2238, 2012.

\bibitem{MSMBuilder}
Kyle~A Beauchamp, Gregory R~Bowman andThomas J~Lane, Lutz Maibaum, Imran~S
  Haque, and Vijay~S Pande.
\newblock {MSMBuilder2}: {M}odeling conformational dynamics at the picosecond
  to millisecond scale.
\newblock {\em J Chem Theor Comput}, 2011.

\bibitem{schuette2011markov}
C.~Sch{\"u}tte, F.~No{\'e}, J.~Lu, M.~Sarich, and E.~Vanden-Eijnden.
\newblock {{Markov} State Models based on Milestoning}.
\newblock {\em J. Chem. Phys.}, 134:204105, 2011.

\bibitem{sarich2010approximation}
Marco Sarich, Frank No{\'e}, and Christof Sch{\"u}tte.
\newblock On the approximation quality of {Markov} state models.
\newblock {\em Multiscale Modeling \& Simulation}, 8(4):1154--1177, 2010.

\bibitem{Eigenvalues}
N.~Djurdjevac, M.~Sarich, and Ch~Sch{\"u}tte.
\newblock Estimating the eigenvalue error of {M}arkov state models.
\newblock {\em Multiscale Modeling \& Simulation}, 10(1):61--81, 2012.

\bibitem{PNAS09}
F.~No\'{e}, C.~Sch\"utte, E.~Vanden-Eijnden, L.~Reich, and T.~R. Weikl.
\newblock Constructing the full ensemble of folding pathways from short
  off-equilibrium simulations.
\newblock {\em Proc. Natl. Acad. Sci. USA}, 106:19011--19016, 2009.

\bibitem{kohlhoff2014cloud}
Kai~J Kohlhoff, Diwakar Shukla, Morgan Lawrenz, Gregory~R Bowman, David~E
  Konerding, Dan Belov, Russ~B Altman, and Vijay~S Pande.
\newblock Cloud-based simulations on google exacycle reveal ligand modulation
  of gpcr activation pathways.
\newblock {\em Nature chemistry}, 6(1):15--21, 2014.

\bibitem{A19-39}
B.~G. Keller, J.-H. Prinz, and F.~No\'e.
\newblock {{Markov}} models and dynamical fingerprints: {U}nraveling the
  complexity of molecular kinetics.
\newblock {\em Chem. Phys.}, 396:92--107, 2012.

\bibitem{PrinzKellerNoe_PCCP11_Perspective}
Jan-Hendrik Prinz, Bettina~G. Keller, and Frank No{\'e}.
\newblock Probing molecular kinetics with {{{Markov}}} models: Metastable
  states, transition pathways and spectroscopic observables.
\newblock {\em Phys. Chem. Chem. Phys.}, 13:16912--16927, 2011.

\bibitem{pande2010everything}
V.S. Pande, K.~Beauchamp, and G.R. Bowman.
\newblock Everything you wanted to know about {Markov} state models but were
  afraid to ask.
\newblock {\em Methods}, 52(1):99--105, 2010.

\bibitem{A19-29}
M.~Sarich, Ralf Banisch, C.~Hartmann, and Ch. Sch\"utte.
\newblock {{Markov}} state models for rare events in molecular dynamics.
\newblock {\em Entropy (Special Issue)}, 16(1):258--286, December 2013.

\bibitem{latorre2011structure}
Juan~C Latorre, Philipp Metzner, Carsten Hartmann, and Christof Sch{\"u}tte.
\newblock A structure-preserving numerical discretization of reversible
  diffusions.
\newblock {\em Commun. Math. Sci}, 9(4):1051--1072, 2011.

\bibitem{floquet1883equations}
G~Floquet.
\newblock Sur les {\'e}quations diff{\'e}rentielles lin{\'e}aires {\`a}
  coefficients p{\'e}riodiques.
\newblock {\em Annales scientifiques de l'{\'E}cole Normale Sup{\'e}rieure},
  12:47--82, 1883.

\bibitem{A19-26}
F.~No\'e, H.~Wu, J.-H. Prinz, and N.~Plattner.
\newblock Projected and hidden {{Markov}} models for calculating kinetics and
  metastable states of complex molecules.
\newblock {\em J. Chem. Phys.}, 139:184114, 2013.

\bibitem{BucheteHummer}
Nicaolae~V. Buchete and Gerhard Hummer.
\newblock Coarse master equations for peptide folding dynamics.
\newblock {\em J. Phys. Chem. B}, 112:6057--6069, 2008.

\bibitem{sarich2014utilizing}
Marco Sarich and Christof Sch{\"u}tte.
\newblock Utilizing hitting times for finding metastable sets in non-reversible
  {Markov} chains.
\newblock {\em submitted to the Journal of Computational Dynamics}, 2014.

\bibitem{discreteTPT}
P.~Metzner, Ch. Sch{\"u}tte, and E.~Vanden-Eijnden.
\newblock Transition path theory for {M}arkov jump processes.
\newblock {\em Multiscale Modeling and Simulation}, 7(3):1192--1219, 2009.

\bibitem{djurdjevac2010markov}
N.~Djurdjevac, M.~Sarich, and C.~Sch{\"u}tte.
\newblock On {{Markov}} state models for metastable processes.
\newblock In {\em Proceedings of the International Congress of Mathematicians},
  volume 901, pages 3105--3131, 2010.

\bibitem{chodera2007automatic}
J.D. Chodera, N.~Singhal, V.S. Pande, K.A. Dill, and W.C. Swope.
\newblock Automatic discovery of metastable states for the construction of
  {Markov} models of macromolecular conformational dynamics.
\newblock {\em J. Chem. Phys.}, 126:155101, 2007.

\bibitem{foloppe2000all}
Nicolas Foloppe and Alexander~D MacKerell~Jr.
\newblock All-atom empirical force field for nucleic acids: I. parameter
  optimization based on small molecule and condensed phase macromolecular
  target data.
\newblock {\em J. Comput. Chem.}, 21(2):86--104, 2000.

\bibitem{jorgensen1983comparison}
William~L Jorgensen, Jayaraman Chandrasekhar, Jeffry~D Madura, Roger~W Impey,
  and Michael~L Klein.
\newblock Comparison of simple potential functions for simulating liquid water.
\newblock {\em J. Chem. Phys.}, 79(2):926--935, 1983.

\bibitem{mackerell2004extending}
Alexander~D MacKerell, Michael Feig, and Charles~L Brooks~III.
\newblock Extending the treatment of backbone energetics in protein force
  fields: Limitations of gas-phase quantum mechanics in reproducing protein
  conformational distributions in molecular dynamics simulations.
\newblock {\em J. Comput. Chem.}, 25(11):1400--1415, 2004.

\bibitem{pronk2013gromacs}
S.~Pronk, S.~P{\'a}ll, R.~Schulz, P.~Larsson, P.~Bjelkmar, R.~Apostolov, M.R.
  Shirts, J.C. Smith, P.M. Kasson, D.~van~der Spoel, Hess B., and Lindahl E.
\newblock Gromacs 4.5: a high-throughput and highly parallel open source
  molecular simulation toolkit.
\newblock {\em Bioinformatics}, pages 1--10, 2013.

\bibitem{bjelkmar2010implementation}
P\"{a}r Bjelkmar, Per Larsson, Michel~A Cuendet, Berk Hess, and Erik Lindahl.
\newblock Implementation of the charmm force field in gromacs: Analysis of
  protein stability effects from correction maps, virtual interaction sites,
  and water models.
\newblock {\em J. Chem. Theory Comput.}, 6(2):459--466, 2010.

\bibitem{parrinello1981polymorphic}
M.~Parrinello and A.~Rahman.
\newblock Polymorphic transitions in single crystals: A new molecular dynamics
  method.
\newblock {\em J. Appl. Phys.}, 52:7182, 1981.

\bibitem{darden1993pme}
T.~Darden, D.~York, and L.~Pedersen.
\newblock {Particle mesh Ewald: An $N \log (N)$ method for Ewald sums in large
  systems}.
\newblock {\em J. Chem. Phys.}, 98:10089, 1993.

\bibitem{essmann1995spm}
U.~Essmann, L.~Perera, M.L. Berkowitz, T.~Darden, H.~Lee, and L.G. Pedersen.
\newblock {A smooth Particle Mesh Ewald method}.
\newblock {\em J. Chem. Phys.}, 103(19):8577, 1995.

\bibitem{wang2010optimizing}
Han Wang, Florian Dommert, and Christian Holm.
\newblock Optimizing working parameters of the smooth particle mesh ewald
  algorithm in terms of accuracy and efficiency.
\newblock {\em The Journal of chemical physics}, 133(3):034117, 2010.

\bibitem{hess1997lincs}
B.~Hess, H.~Bekker, H.J.C. Berendsen, and J.G.E.M. Fraaije.
\newblock {LINCS: a linear constraint solver for molecular simulations}.
\newblock {\em J. Comput. Chem.}, 18(12):1463--1472, 1997.

\bibitem{miyamoto2004settle}
S.~Miyamoto and P.A. Kollman.
\newblock {SETTLE: an analytical version of the SHAKE and RATTLE algorithm for
  rigid water models}.
\newblock {\em J. Comput. Chem.}, 13(8):952--962, 2004.

\bibitem{PCCAplus}
P.~Deuflhard and M.~Weber.
\newblock Robust {P}erron cluster analysis in conformation dynamics.
\newblock {\em Linear Algebra and its Applications}, 161(184), 2005.
\newblock 398 Special issue on matrices and mathematical biology.

\bibitem{PrinzHeldSmithNoe_Committorprep}
Jan-Hendrik Prinz, Martin Held, Jeremy~C. Smith, and Frank No{\'e}.
\newblock Efficient computation of committor probabilities and transition state
  ensembles.
\newblock {\em SIAM Multiscale Model. Simul.}, 9:545, 2011.

\bibitem{wang2013linear}
Han Wang, Carsten Hartmann, and Christof Sch{\"u}tte.
\newblock Linear response theory and optimal control for a molecular system
  under non-equilibrium conditions.
\newblock {\em Molecular Physics}, 111(22-23):3555--3564, 2013.

\bibitem{schutte2014markov}
Christof Sch{\"u}tte, Adam Nielsen, and Marcus Weber.
\newblock Markov state models and molecular alchemy.
\newblock {\em Molecular Physics}, ahead-of-print, 2014.

\bibitem{seifert2012stochastic}
Udo Seifert.
\newblock Stochastic thermodynamics, fluctuation theorems and molecular
  machines.
\newblock {\em Reports on Progress in Physics}, 75(12):126001, 2012.

\end{thebibliography}
% \bibliography{ref}{}
% % \bibliographystyle{unsrt}



\end{document}

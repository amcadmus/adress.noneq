\documentclass[aps, pre, preprint,unsortedaddress,a4paper,onecolumn]{revtex4}
% \documentclass[aps, pre, preprint,unsortedaddress,a4paper,twocolumn]{revtex4}
% \documentclass[acs, jctcce, a4paper,preprint,unsortedaddress,onecolumn]{revtex4-1}
% \documentclass[aps,pre,twocolumn,unsortedaddress]{revtex4-1}
% \documentclass[aps,jcp,groupedaddress,twocolumn,unsortedaddress]{revtex4}

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage[dvips]{graphicx}
\usepackage{color}
\usepackage{tabularx}
\usepackage{algorithm}
\usepackage{algorithmic}

\makeatletter
\makeatother

\newcommand{\recheck}[1]{{\color{red} #1}}
\newcommand{\redc}[1]{{\color{red} #1}}
\newcommand{\bluec}[1]{{\color{red} #1}}
\newcommand{\greenc}[1]{{\color{green} #1}}
% \newcommand{\vect}[1]{\textbf{\textit{#1}}}
\newcommand{\vect}[1]{#1}
\newcommand{\dd}[1]{\textsf{#1}}
\newcommand{\fwd}[0]{\textrm{fw}}
\newcommand{\bwd}[0]{\textrm{bw}}
\newcommand{\period}[0]{T_{\textrm{P}}}
\newcommand{\ml}[0]{\mathcal {L}}
\newcommand{\mo}[0]{\mathcal {O}}
\newcommand{\mbp}[0]{\mathbb {P}}
\newcommand{\mc}[0]{\mathcal {C}}
\newcommand{\dt}[0]{\Delta t}
\newcommand{\id}{\mathrm{Id}}
% \newcommand{\myphi}{\boldsymbol\Phi}
% \newcommand{\mymu}{\boldsymbol\mu}
\newcommand{\myphi}{\Phi}
\newcommand{\mymu}{\mu}
\newcommand{\prob}{\textrm{P}}

\newcommand{\confaa}[0]{{\alpha_{\textrm{R}}}}
\newcommand{\confab}[0]{{\alpha_{\textrm{R}}'}}
\newcommand{\confba}[0]{{\textrm{C}7_{\textrm{eq}}}}
\newcommand{\confbb}[0]{{\textrm{C}5}}
\newcommand{\confc}[0]{{\alpha_{\textrm{L}}}}



\begin{document}

\title{Building Markov State Model for a Periodically Driven Non-Equilibrium System}
\author{Han Wang}
\email{han.wang@fu-berlin.de}
\affiliation{Zuse Institut Berlin, Germany}
\author{Christof Sch\"utte}
\email{Christof.Schuette@fu-berlin.de}
\affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}
\affiliation{Zuse Institut Berlin, Germany}
   
\begin{abstract}
\end{abstract}

\maketitle

\section{Introduction}
Non-equilibrium, especically periodically driven system. Interesting.

MSM tools for analyzing, provide profund understanding.

Current achievement of MSM in equilibrium cases.

Importance: first application of MSM in a non-equilibrium system.

\section{Discretization of the non-equilibrium molecular dynamics}
\label{sec:disc}

We consider  the following SDE form of the externally driven MD:
\begin{align}
  \label{eq:disc-1}
  d\vect x_t = \Big(-\nabla V(\vect x_t) + E(t) D(\vect x_t)\Big)dt + \sqrt{2\beta^{-1}} d\vect w_t, 
\end{align}
where the configurational space is denoted by $\Omega$, and the variable by
$\vect x$.   $V(\vect x)$ is the molecular interaction potential and
$E(t)D(x_t)$ the time-dependent external perturbation with the
$T$-periodic external field $E(t)$. $\beta$ is the inversed temperature,
i.e.~$\beta = 1/(k_B\mathcal T)$.
The propagation of probability
densities $\rho=\rho(\vect x,t)$ based on this kind of dynamics in the sense
of $\rho(\vect x,t)dx=\prob[\vect x_t\in [\vect x,\vect x+d\vect x)]$ is governed by
Fokker-Planck equation:
\begin{align}
  \label{eq:disc-2}
  \frac{\partial \rho}{\partial t} = \ml^\dagger(t) \rho,
\end{align}
where $\ml^\dagger(t)$ is the adjoint of the generator
\begin{align}
  \label{eq:disc-3}
  \ml(t)=\beta^{-1}\Delta_{\vect x}+\Big(-\nabla V(\vect x) + E(t)D(\vect x)\Big)\cdot\nabla_{\vect x},
\end{align}
where $\Delta_{\vect x}$ denotes the Laplacian operator and $\nabla_{\vect x}$
the nabla-operator wrt to $\vect x$. 
The periodicity of the external driven indicates the periodicity of the generator,
i.e.~$\ml(t) = \ml(t+T)$.  Now
introduce a partition of the configurational space $\Omega$ into finite number of disjoint
sets $\{ \Omega_1, \cdots, \Omega_n\}$, which satisfy $\Omega = \cup_i \Omega_i$,
$\Omega_j\cap \Omega_j = \emptyset,\ \forall i\neq j$.
Following Ref.~\cite{latorre2011structure}, the Fokker-Planck Eq.~\ref{eq:disc-2}
is discretized, which results in a time-inhomogeneous Markov jump process in state
space $S = \{1, \cdots, n\}$ with time-dependent rate
matrix $\vect L(t) \in \mathbb R^{n\times n}$ satisfying
\begin{align}\label{eq:disc-4}
\sum\limits_{j=1}^n L_{ij}(t) & =  0\\ \label{eq:disc-5}
L_{ij}(t) & \ge  0, \quad i\not= j\\
L_{ij}(t) & =  L_{ij}(t+T)
\end{align}
for all real time $t\geq 0$.
\recheck{Moreover,
the rate matrix $L$ has the form $\vect L(t)=\vect L_0+E(t)\vect L_1$
where $E(t)$ is periodic with period $T>0$.}
One possible approximation to $L(t)$ is via the following forward finite difference scheme:
\begin{align}
  \label{eqn:tmp4}
  L_{ij}(t) \approx \frac{1}{\tau}
  \,[\, \prob (\vect X_{t+\tau} = i \vert \vect X_{t} = j) - \delta_{ij} \,]
\end{align}
where $\vect X_t$ denotes the Markov jump process generated by $\vect L(t)$, 
and $\tau$ is the disretization time-step.
In analogy to \eqref{eq:disc-2}, the Markov jump process generated by
$\vect L(t)$ transports probability densities according to the associated Master equation
\begin{align}
  \label{eq:disc-7}
  \frac{d\vect p(t)}{dt} = \vect L^T(t)\cdot \vect p(t)
\end{align}
where $\vect L(t)^T$ denotes the matrix transpose of $\vect L(t)$ and
$p_i(t)$, for example, the probability to be in state $i$ at time $t$.
As usual the properties (\ref{eq:disc-4}) and (\ref{eq:disc-5}) of
$\vect L(t)$ guarantee that the total probability mass is conserved,
i.e., if $p_i(0)\ge 0$ componentwise, then $p_i(t)\ge 0$ and $\sum_i
p_i(t) = \sum_ip_i(0)$.
% The solution of the master equation need no be
% periodic.
It can be formally written
\begin{align}  \label{eq:disc-8}
\vect p(t)=\myphi(t)\vect p(0)
\end{align}
by using the
associated propagator matrix $\myphi(t)\in\mathbb R^{n\times n}$ that solves
\begin{align}
  \label{eq:disc-9}
  \frac{d}{dt}\myphi(t) = \vect L^T(t)\myphi(t), \quad \myphi(0) = \id
\end{align}
Since the last equation can be considered column-wise, the propagator matrix inherits column-wise conservation properties:
$\Phi_{ij}(t) \ge  0$
and $\sum\limits_{i=1}^n \Phi_{ij}(t)  =  1$,
that is, $\myphi^T(t)$ is a
stochastic matrix satisfying $\myphi^T(t)\vect e=\vect e$
with $\vect e=(1,\ldots,1)^T\in \mathbb R^n$.
Regarding these considerations, we find
\begin{align}
\label{eq:disc-10}  
\myphi_{ij}(t)=\prob\left(\vect X_t=i\mid \vect X_0=j \right),
\end{align}
 The
discretization sets that we used to go from $\vect x_t$ and $\ml(t)$ to $\vect X_t$
and $\vect L(t)$, respectively, can be assumed to provide an arbitrarily fine
partition of the original state space; then the transport properties
of $\vect L(t)$ are almost perfect approximations of the transport properties
of $\ml(t)$, in particular $p_i(t)=\prob[x_t\in \Omega_i]$.


\section{Floquet theory}
\label{sec:floquet}

As an effect of the periodicity of $\vect L(t)$ the propagator $\myphi(t+T)$
satisfies
\begin{equation}\label{compo-1}
\myphi(t+T)=\myphi(t)\myphi(T),
\end{equation}
for all $t\ge 0$. This can be seen by considering $\vect Y(t)=\myphi(t+T)$. $\vect Y$ satisfies
\[
\frac{d\ }{dt}\vect Y(t)=\vect L(t+T)^T \vect Y(t)=\vect L(t)^T\vect Y(t),\quad \vect Y(0)=\myphi(T).
\]
When we consider this identity column-wise and use the propagator property of $\myphi(t)$ we get $\myphi(t+T)=\vect Y(t)=\myphi(t)\myphi(T)$. As a consequence of (\ref{compo-1}) we get for all integers $m=0,1,2,\ldots$ that 
\begin{equation}\label{compo-2}
\myphi(t+mT)=\myphi(t)\myphi^m(T),
\end{equation}
and in particular we get the long-term evolution of the propagator:
\begin{align}
\label{eq:floq-13}  
\myphi(mT)=\myphi^m(T).
\end{align}
In combination with Eq.~\eqref{eq:disc-8}, we therefore
know the solution $\vect p(t)$ of the Master equation for all $t\ge 0$,
if we can compute $\myphi(t)$ for $t\in (0,T]$.  

Since $\myphi(T)$ is a stochastic matrix, the spectrum $\sigma(\myphi(T))$
of the matrix $\myphi(T)$ is contained in the circle in
the complex plane, i.e., each eigenvalue $\lambda\in \sigma(\myphi(T))$
satisfies $|\lambda|\le 1$. Furthermore $1\in\sigma(\myphi(T))$ is an
eigenvalue with left eigenvector $\vect e$ and a right eigenvector $\mymu$
satisfying
$\myphi(T)\mymu=\mymu$.
From now on, we assume $\myphi(T)$ to be irreducible and aperiodic such that the Perron Frobenius theorem the eigenvalue $\lambda=1$ is  non-negative componentwise, and unique (up to normalization $\sum_j\mu_j=1$). In this case $\mymu$ is the stationary measure in the sense that
\begin{align}
\label{eq:floq-14}  
\myphi(mT) \mymu = \mymu,\quad m=0,1,2,\ldots,
\end{align}
and (more precisely) the asymptotic evolution of an initial probability distribution $\vect p(t=0)=\vect p_0$ by the process satisfies
\begin{align}
\label{eq:floq-15}  
\myphi(mT)\vect p_0\to \mymu,\quad m\to\infty.
\end{align}


\section{Building the Markov state model}
\label{sec:build-msm}

If the discretization cells $\Omega_i$, $i=1,\ldots,n$ form a fine
partition of the molecular state space, the Markov chain defined via
the transition matrix $\vect P=\myphi^T(T)$ still is a fine-scale description of the
dynamics.  Now we want to coarse our description much further by
constructing a Markov State Model (MSM) for $\vect P$ with $k\ll n$
macrostates: The resulting $k\times k$ MSM transition matrix $\hat{\vect P}$
then defines the coarse grained long term kinetics that should
approximate the original long term kinetics well. In Ref.~\cite{sarich2010approximation}
and \cite{schuette2011markov} it
has been shown how to do this if $\vect P$ satisfies the detailed balance
condition: (1) Identify the cores of the metastable sets of the
dynamics, (2) use them as milestones to construct an MSM in which the
macrostates are the metastable core sets and $\hat{\vect P}$ is the transition
matrix of the milestone process that models the jumping behavior of
the original dynamics between the metastable regions.


However, since we cannot assume $P$ to satisfy detailed balance, we
instead follow the approach recently proposed in Ref.~\cite{sarich2014utilizing}.
It allows to identify the metastable core sets for the
non-reversible transition matrix $P$. Assume that this approach leads
to the $k$ core sets $C_1,\ldots, C_k\subset S$, and we denote $C=S\setminus\cup_j C_j$. Following
Ref.~\cite{djurdjevac2010markov}, Thm. 3.1, the coarse grained transition
matrix $\hat{P}$ has to be computed as follows:
\begin{enumerate}
\item For the process associated with $P$ compute the forward and backward committors $q^\fwd_j$ and $q^\bwd_j$  for each core set $C_j$. This can be done by solving the linear equations
\begin{align}
(P-\id) q^\fwd_j(i) & =  0, \quad i\in C\\
q^\fwd_j(i) & =  1,\quad i\in C_j\\
q^\fwd_j(i) & =  0,\quad i\in C_l,l\not=j
\end{align}
and
\begin{align}
(P^b-\id) q^\bwd_j(i) & =  0, \quad i\in C\\
q^\bwd_j(i) & =  1,\quad i\in C_j\\
q^\bwd_j(i) & =  0,\quad i\in C_l,l\not=j
\end{align}
where $P^b$ denotes the transition matrix of the time-reversed process
given by $P^b_{ji}=\mu_i P_{ij}/\mu_j$.

Alternatively, the forward and
backward committors can be sampled via the definitions: The forward
committor $q^\fwd_j(i)$ is defined as the probability of visiting coreset
$C_j$ next conditioned on being at state $i$.  The
backward committor $q^\bwd_j(i)$  is defined as the probability
of last coming from $C_j$ conditioned on being at state $i$.
\item Compute $\hat{\mu}(j)=\sum_{i\in S} q^\bwd_j(i)\mu(i)$,
  which is the invariant measure of the MSM
\item Construct the MSM transition matrix $\hat{P}$ according to
  \begin{align}
    \label{eq:msm-tmatrix}
    \hat{\vect P}_{jk}
    = &
    \frac{1}{\hat{\mu}(j)}
    \langle (\vect P^b - \id) q^\bwd_j,q^\fwd_k \rangle_\mu,\qquad j\not= k, \\
    \hat{\vect P}_{jj}
    =&
    1-\sum_{k\not=j} \hat{\vect P}_{jk}
  \end{align}
where the inner product is defined by
$\langle u,v \rangle_\mu=\sum_{i\in S} u_i v_i \mu_i$.
\end{enumerate}





\section{Numerical example:
  Alanine dipeptide under oscillatory electric field}

If the spacial discretization is fine enough, the Markov jump
process~\eqref{eq:disc-7} is a good approximation to the original
MD~\eqref{eq:disc-1}.  In practice, it is firstly difficult to predict
how many discret set is fine enough; Secondly, since the
total configurational dimension of the system is $3N$ ($N$ being the
number of atoms), it is prohibitive to do a very fine discretization
over all DOFs for most of systems of practical interest.  In the
simulation of biomolecules, in most cases it is reasonable to assume a
time-scale separation in the system.
For example, the conformational
change of the molecules is much faster than the covalent bond
vibrations. 
% It should be noted that we do NOT assume that the fast time-scales are decoupled with the slow time-scales~\footnote{If the fast time-scales
%   are decoupled from the slow ones, then the story would become much simpler,
% however, this situation is lack of generality, we will not discuss.}.
In this context,
it is usually possible to pick a relatively small number of discrete sets that
correctly describe the slow dynamics in the sense that
the original dynamics fully relaxes in every set
within the discretization time-step (denoted by $\tau$). Or equivalently the discretized
dynamics~\eqref{eq:disc-7} is a good approximation to~\eqref{eq:disc-1}.
One possible way to define the discretized set is to firstly find few collective
variables, and then to discretize the dynamics as fine as possible only on these
variables either by uniform or adaptive
discretization~\cite{chodera2007automatic, prinz2011markov}.
This process also suggests that the choice of the lag-time should be 
shorter than the dominant implied timescale so that they can be resolved,
and be longer than the fast time-scales to relax the unresolved dynamics
within the discretized sets.
However, it is in general difficult to tell in priori how to choose the collect
variables, how fine the discretization should be and how large
the time-steps should be.
For large system, these questions are usually
not trivial to answer. 

\begin{figure}
  \centering
  \includegraphics[width=0.3\textwidth]{fig/confs/c-2.eps}
  \caption{A schematic plot of the alanine dipeptide molecule and the dihedral angles $\phi$ and $\psi$.}
  \label{fig:tmp1}
\end{figure}

To illustrate how the procedure works in practice, it is therefore
useful to investigate the discussed approximations by a numerical
example.  We take the alanine dipeptide system under an oscillatory EF,
as an example, the non-equilibrium MD simulation of which was
extensively studied by Ref.~\cite{wang2014exploring}.  
The alanine dipeptide was put into the local thermostating
environment, and was driven by a periodic electric field with period
$T = 10$~ps. The 20,000 branching trajectories started from 20,000
initial configurations that samples the equilibrium distribution.
\redc{Write a lot of details on non-equilibrium MD.}  The branching
trajectories were each 4000~ps long, and the system reaches
non-equilibrium steady state in roughly 300~ps.

We choose the
two dihedral angles $\phi$ and $\psi$ as collective variables (see
Fig.~\ref{fig:tmp1}), and the discretization is a uniform division of
the $\phi$--$\psi$ plane. We denote the number of division on each
dihedral by $K$. In the following subsections, we investigate the discretization
quality firstly by considering the choice of $K$ and time-step $\tau$. Then
the discretized dynamics is compared with original (non-equilibrium brute force simulation)
via considering the steady state probability density, the first mean hitting time
and the forward and backward committors.


\subsection{Discretizing the dihedral angles}
\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig/t010/discrete/fig-cg-prob.eps}  
  \caption{The time-dependent probability $\mathbb
    P\big(\phi\in[0,180), \psi\in [0,180)\big)$.  The brute force
    non-equilibrium MD simulation is compared with different
    discretization methods. The red shadow region indicates the
    statsitical uncertainty of the brute force simulation.}
  \label{fig:tmp2}
\end{figure}

We estimate the discretized generator $L(t), \ t\in[0,T)$
from non-equilibrium trajectories generated by $\ml(t)$ in time interval $[t_1,
t_2]$.
Due to the periodicity of $\ml(t)$, if the discretized dynamics approximate the original
dynamics good enough, generator  $L(t)$ should not depend on in which interval
it is estimated, provided that the initial state of the system
is not very far from the steady state.
This is a good indicator of the discretization quality.
We compute $L(t)$ by two discretizations $K=2$ and $K=20$, and two
choices of time intervals $[0, 80]$~ps and $[320, 400]$~ps, and then
compare the time-dependent
probability $\prob\big(\phi_t\in[0,180), \psi_t\in [0,180)\big)$
with the brute force result in
Fig.~\ref{fig:tmp2}. 
Using $K=2$ the dynamics depends on the time interval used for
calculating the generator: using time interval $[0, 80]$~ps the discretized
dynamics deviates the brute force result,
while using time interval $[320, 400]$~ps the discretized dynamics can only
reproduces the brute force result after 300~ps.  This therefore indicates poor 
approximations to the original dynamics with $K=2$. The reason is that the
discretization is too coarse so that the dynamics cannot be fully
equilibriated within the lag-time $\tau$ in each discretized set,
therefore, the discretization presents state dependency.  For
$K=20$, the discretized dynamics does not depend on the time interval of
calculating the generator, and is consistent with the brute force
non-equilibrium simulation within the error bar. Therefore, in this paper we use $K=20$
to discretize  the dihedral angle space of the alanine dipeptide.
For a good statistical accuracy, if not stated otherwise,
we will use the full trajectories, i.e.~a time interval of
$[0,4000]$~ps for estimating the discretized dynamics.


\subsection{The choice of lag-time $\tau$}

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig/t010/discrete/fig-cg-prob-tau.eps}  
  \caption{The time-dependent probability $\mathbb
    P\big(\phi\in[0,180), \psi\in [0,180)\big)$.  The brute force
    non-equilibrium MD simulation is compared with different
    discretization methods. The red shadow region indicates the
    statsitical uncertainty of the brute force simulation.}
  \label{fig:tmp3}
\end{figure}

As discussed before, the lag-time should be chosen a value that lies
in the spectrum gap of the original dynamics, so that it resolves the
slow dynamics, and at the same time relaxes the fast dynamics. In
practice, it is very difficult to estimate the lag-time in
priori. Therefore, we consider 
different choices of $\tau$ (0.5, 1.0, 2.0 and 5.0~ps)
discretizing the same original dynamics, and compare the
time-dependent probability $\prob\big(\phi\in[0,180), \psi\in
[0,180)\big)$ calculated from different time discretization with the brute force simulation
of the original dynamics
(see Fig.~\ref{fig:tmp3}).  All cases use idential dihedral angle discretization: $K=20$.
It is clear that when lag-time is close to the period (10~ps), the
discretized dynamics cannot resolve the probability change within a
period. However, it is surprising  that the large lag-times are able to capture the
the overall log time behavior of the probability.
We observe no significant difference between $\tau=0.5$ and
$\tau=1.0$~ps, which means the discretized dynamics is not very sensitive
to the choice of $\tau$. 
We do not investigate the small $\tau$ limit, because saving trajectories
more frequently requires more hard disk space, and is usually not preferred.

\subsection{Steady state distribution}

\begin{figure}
  \centering  
  \includegraphics[width=0.4\textwidth]{fig/t010/cluster.marco.40.steadyDist//fig-dist.eps}
  % \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-dist-msm.eps}
  \includegraphics[width=0.4\textwidth]{fig/t010/cluster.marco.40/fig-floquet-vec-1.eps}
  \caption{The steady state distribution calculated by brute force non-equilibrium is compared with that by the discretized dynamics.}
  \label{fig:num-1}
\end{figure}

An important check of the discretized dynamics is that if it reporduces the steady probability
density $\mymu$ of $\myphi(T)$.
To make it comparible to
the free energy in equilibrium case, we take the logrithm of the properties, i.e.
\begin{align}
  \label{eq:num-tmp1}
  F_{\textrm{st}}(\phi,\psi) = \lim_{m\rightarrow\infty} -k_B\mathcal T \log p(\phi,\psi,mT),
\end{align}
where $k_B$ is the Boltzmann constant and $\mathcal T$ is the temperature of the system.
The result is given in Fig.~\ref{fig:num-1}. A good consistency between the brute force
MD simulation and the discretized dynamics is observed.

\subsection{Coreset identification}

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig/t040/cluster.marco/fig-cluster-2.eps}
  \caption{The coreset identification. Different colors indicate different coresets: $C_{\confaa}$ (yellow), $C_\beta$ (red) and $C_{\confc}$ (green).
    The blue color means out of any coreset. (By Marco)}
  \label{fig:cluster}
\end{figure}

\redc{Write how to detact the core sets for irreversible Markovian process}.

The coresets (see Fig.~\ref{fig:cluster}) are denoted by $C_{\confaa}$ (yellow), $C_\beta$ (red) and $C_{\confc}$ (green), which correspond to
right-handed alpha-helix, beta-sheet and left-handed alpha-helix, respectively.

\subsection{First mean hitting time}

Since the largest first mean hitting time (starting fom coreset $\confaa$ to $\confc$) is
longer than 600~ps, if we use the trajectories of length 4000~ps, the
results will be biased. Therefore, we use 100 non-equilibrium trajectories
of $2\times 10^5$~ps instead.
The first mean hitting time is presented in Fig.~\ref{fig:num-6}.

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40.fht/fig-fht-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40.fht/fig-fht-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40.fht/fig-fht-3.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40.fht/fig-fht-msm-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40.fht/fig-fht-msm-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40.fht/fig-fht-msm-3.eps}
  \caption{The first mean htting time comparsion between the brute
    force simulation (first row) and the discretized dynamics (second row).  From left
    to right are first mean hitting time to coresets $C_{\confc}$,
    $C_{\confaa}$ and $C_{\beta}$, respectively}
  \label{fig:num-6}
\end{figure}

\subsection{Forward and backward committors}

The forward committor $q^\fwd_i(\phi,\psi)$ of a coreset $C_i,\
i\in\{\confaa, \beta, \confc\}$ is defined as the probability of
visiting coreset $C_i$ next conditioned on being at configuration
$(\phi,\psi)$.  The backward committor $q^\bwd_i(\phi,\psi)$ of a
coreset $C_i,\ i\in\{\confaa, \beta, \confc\}$ is defined as the
probability of last coming from $C_i$ conditioned on being at
configuration $(\phi,\psi)$.  For reversible Markov processes, the
forward and backward committors are identical, however, it is in
general not the case for irreversible processes. Please see
Fig.~\ref{fig:num-3}--\ref{fig:num-5} for the committors.

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-1.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-msm-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-msm-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-msm-1.eps}
  \caption{The forward $q^\fwd_{\confc}$ and backward committors
    $q^\bwd_{\confc}$ computed by discretized dynamics (second row) is compared with
    those computed by brute force non-equilibrium simulations (first
    row).}
  \label{fig:num-3}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-2.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-msm-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-msm-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-msm-2.eps}
  \caption{The forward $q^\fwd_{\confaa}$ and backward
    $q^\bwd_{\confaa}$ committors computed by discretized dynamics (second row) is
    compared with those computed by brute force non-equilibrium
    simulations (first row).}
  \label{fig:num-4}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-3.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-fw-msm-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-bw-msm-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-commitor-diff-msm-3.eps}
  \caption{The forward $q^\fwd_{\beta}$ and backward $q^\bwd_{\beta}$
    committors computed by discretized dynamics (second row) is
    compared with those computed by brute force non-equilibrium
    simulations (first row).}
  \label{fig:num-5}
\end{figure}


\subsection{Building MSM}
Following the process described in Sec.~\ref{sec:build-msm}, we are able to build a 
three states MSM for the alanine dipeptide system.
The leading eigenvalues of $P$ is compared with those of the MSM, i.e.~$\hat P$ in
Tab.~\ref{tab:tmp1}.

\begin{table}
  \centering
  \caption{
    The eigenvalue comparison
  }
  \begin{tabular*}{0.5\textwidth}{@{\extracolsep{\fill}}c rrr}\hline\hline
      &  $\lambda_2$ & $\lambda_3$ & $\lambda_4$ \\\hline
    $P$         &0.907  &0.686 & 0.553       \\
    $\hat P$    &0.914  &0.744 & --       \\
    \hline\hline
  \end{tabular*}
  \label{tab:tmp1}
\end{table}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-eig-vec-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-eig-vec-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.40/fig-eig-vec-4.eps}\\
  \caption{The eigenfunctions of $P$.}
  \label{fig:num-6}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig/t010/cluster.marco.40/fig-coreset-prob.eps}
  \caption{The time-dependent probability $\hat P_l$. Solid lines are from brute force MD simulation, while the dashed lines are from MSM.}
  \label{fig:num-7}
\end{figure}

We study the time-dependent expectation values of
the properties, i.e.
\begin{align}
  \mathcal A(t) = \langle A(i)\rangle_t = \sum_{i\in S} A(i) p(i,t),
\end{align}
which are linear combinations of the backward
committor, i.e.
\begin{align}
  A(i) = \sum_{l=1}^k \alpha_l q^\bwd_l(i)
\end{align}
then
\begin{align}\nonumber
  \mathcal A(t) &=
  \sum_{i\in S} \sum_{l=1}^k \alpha_l q^\bwd_l(i)  p(i,t) \\\nonumber
  & =
  \sum_{i\in S} \sum_{l=1}^k \alpha_l \prob (\hat X_t = l \vert X_t = i) \prob (X_t = i) \\\nonumber
  & =
  \sum_{i\in S} \sum_{l=1}^k \alpha_l \prob (\hat X_t = l ,X_t = i) \\\nonumber
  & =
  \sum_{l=1}^k \alpha_l \prob (\hat X_t = l) \\\label{eq:num-28}
  & =
   \sum_{l=1}^k \alpha_l \,\hat p (l, t),
\end{align}
where the time-dependent projected probability is governed by the MSM:
\begin{align}\label{eq:num-29}
  \hat p(i, t+T) = \sum_{j\in S} \hat p(j,t)\hat P_{ji}
\end{align}
In Fig.~\ref{fig:num-7} we compare the numerical calculation of $\hat p (l, mT), \ m\in\mathbb N$ from brute force and MSM calculations.
In the brute force calculation, the RHS terms on the projection $\hat p (l, mT) = \sum_{i\in S}  q^\bwd_l(i)  p(i,mT) $ are estimated from the
non-equilibrium MD simulations. For MSM, the projection for the initial probability is applied $\hat p (l, 0) = \sum_{i\in S}  q^\bwd_l(i)  p(i,0) $, then
the time-dependent probability at $mT$ is generated by Eq.~\eqref{eq:num-29}.
% The projected probability, e.g.~$\hat p (l', mT)$ is calculated
% by Eq.~\eqref{eq:num-28} letting $\alpha_l = \delta_{l'l}$.



\appendix



\section{Reversibility of the original dynamics}
\label{sec:revs}

We consider the gonverning dynamics Eq.~\eqref{eq:disc-1}.
For simplicity we denote the force by $F(x_t,t) = -\nabla_x V(x_t)+ E(t)D(x_t) $.  We denote $\sigma =  \sqrt{2\beta^{-1}} $.
According to Girsanov, we have
\begin{align}
  \label{eq:tmp8}
  \frac{dp[x_t]}{dw[x_t]}  =
  \exp \bigg\{
  \frac 1{\sigma^2}\int_0^T F(x_t,t) dx_t -
  \frac1{2\sigma^2}\int_0^T F^2(x_t,t) dt
  \bigg\}
\end{align}
where $dp$ is the probability measure of trajectory $x_t$, while $dw$ is the
probability measure of the standard Wiener process $dx_t = \sigma dw_t$.
Assuming a discretization of the
stochastic process at time $0 < t_1 < t_2 < \cdots < t_N = T$, where
$t_i = iT / N$. We denote $x_i = x_{t_i}$, and $w_i = w_{t_i}$, then we have,
in the sense of Ito,
\begin{align}\label{eq:tmp9}
  \frac{dp[x_t]}{dw[x_t]}  \approx
  \exp\bigg\{\frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{i},t_{i})(x_{i+1} - x_i) -\frac1{2\sigma^2}\sum_{i=0}^{N-1}F^2(x_i,t_i)\dt\bigg\} 
\end{align}
Now, consider a conjugate trajectory $x^\dagger_t = x_{T-t}$ that starts at $x_T$, ends at $x_0$. The conjugate dynamics is driven by  $F^\dagger(x^\dagger_t,t) = F(x^\dagger_t, T-t)$.
Writting the Girsanov for the conjugate dynamics
\begin{align}\label{eq:dagger-0}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\ \nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},T - t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, T-t_i)]^2\dt\bigg\} \\\nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{N-i},t_{N-i})(x_{N-i-1} - x_{N-i}) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x_{N-i},t_{N-i})]^2\dt\bigg\} \\
  = \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=N}^{1} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=N}^{1}F^2(x_i,t_i)\dt\bigg\}
\end{align}
% Therefore,
% \begin{align}\nonumber
%   \frac{dp[x^\dagger_t]}{dw[x^\dagger_t]}  =
%   \,&
%   \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]} \\\nonumber
%   \approx\,&
%   \exp\bigg\{
%   \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
%   \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\\nonumber
% \end{align}
Since it is obvious that $dw[x^\dagger_t] / dw[x_t] = 1$,
\begin{align}
  \label{eq:tmp10}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x_t]}
  \approx \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=1}^{N} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=1}^{N}F^2(x_i,t_i)\dt\bigg\}
\end{align}
The difference between the single trajectory probabilities is
\begin{align}\label{eqn:tmp12}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
  -\frac1{\sigma^2}\sum_{i=1}^{N-1}
  \bigg[
  F(x_i,t_i)(x_{i+1} - x_{i}) + F(x_i,t_i)(x_{i} - x_{i-1})
  \bigg]
  \bigg\}
\end{align}
Assuming the smoothness of the external perturbation, consider the differentiation:
\begin{align}\nonumber
  F(x_{i},t_{i}) - F(x_{i-1},t_{i-1}) =
  &\,
  F(x_{i},t_{i}) - F(x_{i-1},t_{i}) + F(x_{i-1},t_{i}) -  F(x_{i-1},t_{i-1})\\\nonumber
  =&\,
  \nabla_x F(x_{i-1},t_{i})(x_i - x_{i-1}) + \mo(\dt) \\\label{eqn:tmp13}
  =&\,
  \nabla_x F(x_{i-1},t_{i-1})(x_i - x_{i-1}) + \mo(\dt)
\end{align}
The second order expansion w.r.t.~$x_i - x_{i-1}$ is of order $\dt$, so it is absorbed into $ \mo(\dt)$.
Then the \eqref{eqn:tmp12} becomes
\begin{align}\label{eqn:tmp14}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\sum_{i=0}^{N-1} F(x_i,t_i)(x_{i+1} - x_{i}) 
 -\frac1{\sigma^2}\sum_{i=0}^{N-1}\nabla_xF(x_i,t_i)(x_{i+1} - x_{i})^2
 \bigg\}
\end{align}
Using the identity
$  dt = (dw_t)^2 = {\sigma^{-2}} dx_t^2$,
Eq.~\eqref{eqn:tmp14} is written in the integral form
\begin{align}\label{eqn:tmp14-0}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\int_0^T F(x_t,t) dx_t
 -\int_0^T\nabla_xF(x_t,t)dt
 \bigg\}  
\end{align}
One would not have the second integral on the exponent if the first integral of the exponent were defined in the sense of Stratonovich.

We notice that
\begin{align}\nonumber
  dV(x, t) = &\, \frac{\partial V}{\partial x} dx + \frac{\partial V}{\partial t} dt\\\nonumber
  =&\,
  \frac12 \sigma^2 \nabla^2_x V dt +  \nabla V dx_t + \frac{\partial V}{\partial t} dt \\
  =&\,
  -\frac12 \sigma^2 \nabla_x F dt -  F dx_t + \frac{\partial V}{\partial t} dt
\end{align}
Eq.~\eqref{eqn:tmp14-0} becomes
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \exp\bigg\{
  \frac2{\sigma^2}\bigg[
  V(x_T,T) - V(x_0,t_0) - \int_0^T\partial_tV(x_t,t)dt
  \bigg]
  \bigg\}
\end{align}
% According to the  Einstein relation, the temperature $\mathcal T = \sigma^2/2$, we denote $\beta = 1/{\mathcal T} = 2/\sigma^2$.
Take the limit of infinite small time interval, notice the equilibrium
invariant probability density with respect to potential $V(x,0)$ satisfies $\mymu(x) \propto e^{-\beta V(x,0)}$, and replace $\sigma^2$ by $2\beta^{-1}$,
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \frac{\mymu(x_0)}{\mymu(x_T)}\times
  \exp\bigg\{
  - \beta\int_0^T\partial_tV(x_t,t)dt
  \bigg\}
\end{align}

\subsection{Irreversibility of the perodical symmetrical dynamics}

In Eq.~\eqref{eq:dagger-0}, we assume the periodicity of the perturbation $F(x,t) = F(x,t+T)$, and the symmetry of the external perturbation, i.e.~$F(x, -t) = F(x, t)$, we have
\begin{align}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, t_i)]^2\dt\bigg\}  
\end{align}
By changing notation $x^\dagger$ back to $x$, and comparing with~\eqref{eq:tmp9}, the reversed dynamics is subject to the Eq.~\eqref{eq:disc-1},
i.e.~$dp^\dagger = dp$.
Therefore
\begin{align}\nonumber
  p(x_0,T\vert x_T,0)
  =&\,\int_{\mc\{x_T,0;x_0,T\}}
  dp[x^\dagger_t] \\\nonumber  
  =&\,
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\nonumber
  =&\,
  % \lim_{N\rightarrow\infty} 
  % \frac{1}{(2\pi\sigma^2\dt)^{(N-1)/2}} \int dx_{N-1}\cdots\int dx_{1}
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\label{eqn:tmp18}
  = &\,
  \frac{\mu(x_0)}{\mu(x_T)}
  \int_{\mc\{x_0,0;x_T,T\}}
  \exp\bigg\{
  -\beta\int_0^T \partial_t V(x_t,t)dt 
  \bigg\} \cdot dp[x_t]
\end{align}
where $\mc\{x_0,0;x_T,T\}$ denotes all continuous trajectories starting at $x_0$ and ending at $x_T$.
If $\partial_t V = 0$, i.e.~equilibrium, we have
\begin{align}
  p(x_0,T\vert x_T,0)e^{-\beta V(x_T,T)} =  p(x_T,T\vert x_0,0) e^{-\beta V(x_0,0)},
\end{align}
which proves the reversibility of the equilibrium dynamics.
The term
\begin{align}
  W[x_t] = \int_0^T \partial_t V(x_t,t)dt
\end{align}
is the non-equilibrium work associated to all possible
the dynamics $x_t$ starting at $x_0$ and ending at $x_T$ (see e.g.~Ref.~\cite{seifert2012stochastic}).
Therefore Eq.~\eqref{eqn:tmp18} is the detailed Jarzynski relation.
% Now the problem becomes if we can write a nice form (e.g.~the difference of a state function measured at $x_T$ and $x_0$) for the non-equilibrium work.
Noticing that
\begin{align}
  \label{eq:tmp21}
  p(x_T,T\vert x_0,0) = \int_{\mc\{x_0,0;x_T,T\}}dp[x_t],
\end{align}
From Eq.~\eqref{eqn:tmp18} we have
\begin{align}
  \label{eq:tmp22}
  \frac{p(x_0,T\vert x_T,0)}{  p(x_T,T\vert x_0,0)  }
  =
  \frac{\mu(x_0)}{\mu(x_T)}
  \mathbb E_{x_0\rightarrow x_T} [e^{-\beta W}]
\end{align}
% Maybe we want a more symmetric form.
% The expectation value of the reversed dynamics reads,
% \begin{align}\nonumber
%   \mathbb E_{x^\dagger_0\rightarrow x^\dagger_T} [e^{-\beta W^\dagger}]
%   =\,&
%   \int_{\mc\{x^\dagger_0,0;x^\dagger_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x^\dagger_t,t)dt 
%   \bigg\} \cdot dp[x^\dagger_t]   \\\nonumber
%   =\,&
%   \int_{\mc\{x_0,0;x_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x_{T-t},t)dt 
%   -\beta\int_0^T \partial_t V(x_{t},t)dt 
%   \bigg\}
%   \cdot dp[x_t]   \\  \nonumber
%   =\,&
%   \int_{\mc\{x_T,0;x_0,T\}}
%   \exp\bigg\{
%   \beta\int_0^T \partial_t V(x_t,t)dt 
%   \bigg\} \cdot dp[x_t]   \\
%   \label{eq:tmp23}
%   = \,&
%   \mathbb E_{x_0\rightarrow x_T} [e^{- 2\beta W}]  
% \end{align}
% Noticing that \eqref{eq:tmp22}  is true for the reversed dynamics, we have
% \begin{align}
%   \label{eq:24}
%   \frac{p(x_T,T\vert x_0,0)}{  p(x_0,T\vert x_T,0)  }
%   =
%   \frac{\mu(x_T)}{\mu(x_0)}
%   \mathbb E_{x_T\rightarrow x_0} [e^{\beta W}]  
% \end{align}


\bibliography{ref}{}
\bibliographystyle{unsrt}



\end{document}

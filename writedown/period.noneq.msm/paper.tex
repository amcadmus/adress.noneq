\documentclass[aps, pre, preprint,unsortedaddress,a4paper,onecolumn]{revtex4}
% \documentclass[aps, pre, preprint,unsortedaddress,a4paper,twocolumn]{revtex4}
% \documentclass[acs, jctcce, a4paper,preprint,unsortedaddress,onecolumn]{revtex4-1}
% \documentclass[aps,pre,twocolumn,unsortedaddress]{revtex4-1}
% \documentclass[aps,jcp,groupedaddress,twocolumn,unsortedaddress]{revtex4}

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage[dvips]{graphicx}
\usepackage{color}
\usepackage{tabularx}
\usepackage{algorithm}
\usepackage{algorithmic}

\makeatletter
\makeatother

\newcommand{\recheck}[1]{{\color{red} #1}}
\newcommand{\redc}[1]{{\color{red} #1}}
\newcommand{\bluec}[1]{{\color{red} #1}}
\newcommand{\greenc}[1]{{\color{green} #1}}
% \newcommand{\vect}[1]{\textbf{\textit{#1}}}
\newcommand{\vect}[1]{#1}
\newcommand{\dd}[1]{\textsf{#1}}
% \newcommand{\fwd}[0]{\textrm{fw}}
% \newcommand{\bwd}[0]{\textrm{bw}}
\newcommand{\fwd}[0]{+}
\newcommand{\bwd}[0]{-}
\newcommand{\period}[0]{T_{\textrm{P}}}
\newcommand{\ml}[0]{\mathcal {L}}
\newcommand{\mo}[0]{\mathcal {O}}
\newcommand{\mbp}[0]{\mathbb {P}}
\newcommand{\mc}[0]{\mathcal {C}}
\newcommand{\dt}[0]{\Delta t}
\newcommand{\id}{\mathrm{Id}}
% \newcommand{\myphi}{\boldsymbol\Phi}
% \newcommand{\mymu}{\boldsymbol\mu}
\newcommand{\myphi}{\Phi}
\newcommand{\mymu}{\mu}
\newcommand{\prob}{\textrm{P}}

\newcommand{\confaa}[0]{{\alpha_{\textrm{R}}}}
\newcommand{\confab}[0]{{\alpha_{\textrm{R}}'}}
\newcommand{\confba}[0]{{\textrm{C}7_{\textrm{eq}}}}
\newcommand{\confbb}[0]{{\textrm{C}5}}
\newcommand{\confc}[0]{{\alpha_{\textrm{L}}}}



\begin{document}

\title{Building Markov State Models for Periodically Driven Non-Equilibrium Systems}
\author{Han Wang}
\email{han.wang@fu-berlin.de}
\affiliation{Zuse Institut Berlin, Germany}
\author{Christof Sch\"utte}
\email{Christof.Schuette@fu-berlin.de}
\affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}
\affiliation{Zuse Institut Berlin, Germany}
   
\begin{abstract}
\end{abstract}

\maketitle

\section{Introduction}
Non-equilibrium, especially periodically driven system. Interesting.

MSM tools for analyzing, provide profound understanding.

Current achievement of MSM in equilibrium cases:
\begin{itemize}
\item well developed in theory and applications \cite{A19-31, A19-1}
\item software for MSM building \cite{A19-49, MSMBuilder}
\end{itemize}

Importance: first application of MSM in a non-equilibrium system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Non-equilibrium molecular dynamics and its discretization}
\label{sec:disc}
For the sake of simplicity we consider diffusive molecular dynamics in an energy landscape $V$ driven by the time-dependet external driving force $E(t)D(x_t)$ with the
$T$-periodic external field $E(t)$:
\begin{align}
  \label{eq:disc-1}
  d\vect x_t = \Big(-\nabla V(\vect x_t) + E(t) D(\vect x_t)\Big)dt + \sqrt{2\beta^{-1}} d\vect w_t, 
\end{align}
where $x_t\in\Omega$ denotes the state of the molecular system at time $t$ in state space $\Omega$, $\vect w_t$ denotes standard $n$-dimensional Brownian motion, and $\beta$ the inverse temperature,
i.e.~$\beta = 1/(k_B\mathcal T)$.
The propagation of probability
densities $\rho=\rho(\vect x,t)$ based on this kind of dynamics in the sense
of $\rho(\vect x,t)dx=\prob[\vect x_t\in [\vect x,\vect x+d\vect x)]$ is governed by
Fokker-Planck equation:
\begin{align}
  \label{eq:disc-fp}
  \frac{\partial \rho}{\partial t} = \ml^\dagger(t) \rho,
\end{align}
where $\ml^\dagger(t)$ is the adjoint of the generator
\begin{align}
  \label{eq:disc-3}
  \ml(t)=\beta^{-1}\Delta_{\vect x}+\Big(-\nabla_x V(\vect x) + E(t)D(\vect x)\Big)\cdot\nabla_{\vect x},
\end{align}
where $\Delta_{\vect x}$ denotes the Laplacian operator and $\nabla_{\vect x}$
the nabla-operator wrt to $\vect x$. 
The periodicity of the external driving force induces the periodicity of the generator,
i.e.~$\ml(t) = \ml(t+T)$.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spatial discretization: Master equation}
We will now introduce an appropriate spatial discretization of this kind of non-equilibirium MD -- this is done for reasons of simplicity only; we could completely avoid it for the price of more technical arguments.
For achieving this discretization, we 
introduce a partition of state space $\Omega$ into a finite number of disjoint
sets $\{ \Omega_1, \cdots, \Omega_n\}$ satisfying $\Omega = \cup_i \Omega_i$,
$\Omega_j\cap \Omega_j = \emptyset,\ \forall i\neq j$.
Utilizing the procedure described in Ref.~\cite{latorre2011structure} the original Fokker-Planck equation~(\ref{eq:disc-fp})
is discretized, resulting in a time-inhomogeneous Markov jump process in state
space $S = \{1, \cdots, n\}$ with time-dependent rate
matrix $\vect L(t) \in \mathbb R^{n\times n}$ satisfying
\begin{align}\label{eq:disc-4}
\sum\limits_{j=1}^n L_{ij}(t) & =  0\\ \label{eq:disc-5}
L_{ij}(t) & \ge  0, \quad i\not= j\\
L_{ij}(t) & =  L_{ij}(t+T)
\end{align}
for all real time $t\geq 0$.
Moreover, the rate matrix $L$ has the form $\vect L(t)=\vect L_0+E(t)\vect L_1$
where $E(t)$ is periodic with period $T>0$.
In analogy to \eqref{eq:disc-fp}, the Markov jump process generated by
$\vect L(t)$ transports probability distributions according to the associated Master equation
\begin{align}
  \label{eq:disc-master}
  \frac{d\vect p(t)}{dt} = \vect L^T(t)\cdot \vect p(t)
\end{align}
where $\vect L(t)^T$ denotes the matrix transpose of $\vect L(t)$, $\vect p(t)$ is an $n$-vector denoting the probability distribution on $S$ at time $t$, and
$p_i(t)$, for example, the probability to be in state $i$ (which corresponds to set $\Omega_i$) at time $t$.
As usual the properties (\ref{eq:disc-4}) and (\ref{eq:disc-5}) of
$\vect L(t)$ guarantee that the total probability mass is conserved,
i.e., if $p_i(0)\ge 0$ componentwise, then $p_i(t)\ge 0$ and $\sum_i
p_i(t) = \sum_ip_i(0)$.
% The solution of the master equation need no be
% periodic.
The temporal evolution of the probability distribution $\vect p(t)$ can be formally written
\begin{align}  \label{eq:disc-8}
\vect p(t)=\myphi(t)\vect p(0)
\end{align}
by using the
associated propagator matrix $\myphi(t)\in\mathbb R^{n\times n}$ that solves
\begin{align}
  \label{eq:disc-master-phi}
  \frac{d}{dt}\myphi(t) = \vect L^T(t)\myphi(t), \quad \myphi(0) = \id .
\end{align}
Since the last equation can be considered column-wise, the propagator matrix inherits column-wise conservation properties:
$\Phi_{ij}(t) \ge  0$
and $\sum\limits_{i=1}^n \Phi_{ij}(t)  =  1$,
that is, $\myphi^T(t)$ is a
stochastic matrix satisfying $\myphi^T(t)\vect e=\vect e$
with $\vect e=(1,\ldots,1)^T\in \mathbb R^n$.
Regarding these considerations, we find
\begin{align}
\label{eq:disc-10}  
\myphi_{ij}(t)=\prob\left(\vect X_t=i\mid \vect X_0=j \right),
\end{align}
where $\vect X_t$ denotes the Markov process generated by $\vect L(t)$.
 
The discretization sets that we used to go from $\vect x_t$ and $\ml(t)$ to $\vect X_t$
and $\vect L(t)$, respectively, can be assumed to provide an arbitrarily fine
partition of the original state space; then the transport properties
of $\vect L(t)$ are almost perfect approximations of the transport properties
of $\ml(t)$, in particular the approximation $p_i(t)\approx \prob(x_t\in \Omega_i)$ is almost perfect.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Temporal discretization: Floquet theory}
\label{sec:floquet}

As an effect of the periodicity of $\vect L(t)$ the propagator $\myphi(t+T)$
satisfies
\begin{equation}\label{compo-1}
\myphi(t+T)=\myphi(t)\myphi(T),
\end{equation}
for all $t\ge 0$. This can be seen by considering $\vect Y(t)=\myphi(t+T)$. It satisfies
\[
\frac{d\ }{dt}\vect Y(t)=\vect L(t+T)^T \vect Y(t)=\vect L(t)^T\vect Y(t),\quad \vect Y(0)=\myphi(T).
\]
When we consider this identity column-wise and use the propagator property of $\myphi(t)$ we get $\myphi(t+T)=\vect Y(t)=\myphi(t)\myphi(T)$. As a consequence of (\ref{compo-1}) we get for all integers $m=0,1,2,\ldots$ that 
\begin{equation}\label{compo-2}
\myphi(t+mT)=\myphi(t)\myphi^m(T).
\end{equation}
In combination with Eq.~\eqref{eq:disc-8}, we therefore
know the solution $\vect p(t)$ of the Master equation for all $t\ge 0$,
if we can compute $\myphi(t)$ for $t\in (0,T)$.  
In particular we get the long-term evolution of the propagator:
\begin{align}
\label{eq:floq-13}  
\myphi(mT)=\myphi^m(T),
\end{align}
and for the probability at integral period we have
\begin{align}
  \label{eq:floq-dynamics}
  p(mT) =  \myphi(mT)\, p(0) = \myphi^m(T)\, p(0),
\end{align}
where $\myphi^m(T)$ denotes the $m$th power of the matrix $\myphi(T)$.
Since $\myphi(T)$ is a stochastic matrix, its eigenvalues are contained in the unit circle in
the complex plane, i.e., each eigenvalue $\lambda$ (potentially coomplex-valued)
satisfies $|\lambda|\le 1$. Furthermore $\lambda=1$ is an
eigenvalue with left eigenvector $\vect e=(1,\ldots,1)^T$ and a right eigenvector $\mymu$
satisfying
$\myphi(T)\mymu=\mymu$.
From now on, we assume $\myphi(T)$ to be irreducible and aperiodic such that the Perron Frobenius theorem the eigenvalue $\lambda=1$ is  non-negative componentwise, and unique (up to normalization $\sum_j\mu_j=1$). In this case $\mymu$ is the stationary measure in the sense that
\begin{align}
\label{eq:floq-14}  
\myphi(mT) \mymu = \mymu,\quad m=0,1,2,\ldots,
\end{align}
and (more precisely) the asymptotic evolution of an initial probability distribution $\vect p(t=0)$ by the process satisfies
\begin{align}
\label{eq:floq-15}  
\myphi(mT)\vect p(0)\to \mymu,\quad m\to\infty,
\end{align}
so that $\mymu$ can be seen as the quasi-stationary distribution of our non-stationary process.

Using the Floquet theorem, the time-inhomogeneous Markov jump process $X_t$
is simplified into a \emph{time-homogeneous} (not necessarily
reversible) Markov jump process $\tilde X_{m} = X_{mT}, \ m\in\mathbb
N$.
Therefore, we prefer to consider the discrete-time process $\tilde X_{m}$ instead of the time-continuous process $X_t$
because the powerful theories and
computational tools for time-homogeneous Markov processes can be directly applied. Many of these tools require the transition matrix $\myphi(T)$ to satisfy the detailed balance condition. The computations in the Appendix show that $\myphi$ will in general \emph{not} satisfy this condition; in fact  the deviation form reversibility can be estimated from the work of the periodic driving does to the system.


There is no doubt that information within one period is lost by using this temporal
discretization, however, information regarding the long-term behavior of the system on time-scales
much longer than the period will be perfectly described because of $\tilde X_{m} = X_{mT}\approx x_{mT}$ whenever our spatial discretization is fine enough.
At the same time,
the computational cost of generating $\tilde X_{m}$ is much less demanding
than the brute force simulations of NEMD, which implies lower
statistically uncertainty in calculating the observables of interest.

% due to the discretization in both the spacial and temperal directions.
% In the numercal example in Sec.~\ref{sec:alanine}, we
% compute the 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Markov State Model}
\label{sec:build-msm}


% \subsection{Building the Markov State Model from the Floquet transition matrix}
If the discretization cells $\Omega_i$, $i=1,\ldots,n$ form a fine
partition of the molecular state space, the Markov chain defined via
the transition matrix 
\begin{equation}\label{P}
\vect P=\myphi^T(T)
\end{equation}
 is discrete in time but in space it still is a fine-scale description of the transport properties of the
dynamics with a very large number $n$ of states.  Now we want to coarsen our description much further by
constructing a Markov State Model (MSM) for $\vect P$ with $k\ll n$
\emph{macrostates} that should be the metastable states of the system: The resulting $k\times k$ MSM transition matrix $\hat{\vect P}$
then defines the coarse grained long term kinetics that shall
approximate the original long term kinetics well. 
The idea behind MSM building is that given the molecular system under consideration exhibits metastable conformations then it is usually possible to construct a
relatively small number of discrete sets --the metastable sets that form the so-called macrostates-- that
correctly describe the slow  dynamics, and 
in each set the fast dynamics relaxes on some timescale significantly shorter than the metastable timescales.
Then if the MSM dynamics reproduces the slow timescales and the corresponding transitions
of the original dynamics~\eqref{eq:disc-1},
the former is considered to be a good approximation of the later.

MSM building has been attracted a lot of attention recently, and theory  \cite{A19-31} as well as algorithms \cite{A19-1}, applications (see e.g. \cite{A19-26,PNAS09} for two of hundreds of articles) and software \cite{A19-49, MSMBuilder} have been developed to quite an extend. However, 
by far most of the literature is related to building \emph{standard} MSMs for equilibirium MD. In standard MSM also the transition region has to be discretized, a feature that often forces the user to incorporate more macrostates than essentially needed to approximate the long-term kinetics.
In Ref.~\cite{sarich2010approximation, A19-31,schuette2011markov,BucheteHummer} it has been shown how to construct \emph{non-standard} MSM that avoid this problem for equilibrium MD, i.e., if $\vect P$ satisfies the detailed balance
condition: (1) Identify the cores of the metastable sets of the
dynamics, (2) use them as milestones to construct an MSM in which the
macrostates are the metastable core sets and $\hat{\vect P}$ is the transition
matrix of the milestone process \cite{A19-31,schuette2011markov,A19-29} that models the jumping behavior of
the original dynamics between the metastable regions. 

However, since we cannot assume $P$ to satisfy detailed balance, we
instead follow the approach to non-standard MSMs recently proposed in Ref.~\cite{sarich2014utilizing}.
It allows to identify the metastable core sets for the
non-reversible transition matrix $P$. Assume that this approach leads
to the $k$ core sets $C_1,\ldots, C_k\subset S$, and we denote $C=S\setminus\cup_j C_j$. Following
Ref.~\cite{djurdjevac2010markov}, Thm. 3.1, the coarse grained transition
matrix $\hat{P}$ then has to be computed as follows:
\begin{enumerate}
\item For the process associated with $P$ compute the forward and backward committors $q^\fwd_j$ and $q^\bwd_j$  for each core set $C_j$. This can be done by solving the linear equations
\begin{align}
(P-\id) q^\fwd_j(i) & =  0, \quad i\in C\label{qfwd}\\
q^\fwd_j(i) & =  1,\quad i\in C_j\nonumber\\
q^\fwd_j(i) & =  0,\quad i\in C_l,l\not=j\nonumber
\end{align}
and
\begin{align}
(P^b-\id) q^\bwd_j(i) & =  0, \quad i\in C\label{qbwd}\\
q^\bwd_j(i) & =  1,\quad i\in C_j\nonumber \\
q^\bwd_j(i) & =  0,\quad i\in C_l,l\not=j\nonumber
\end{align}
where $P^b$ denotes the transition matrix of the time-reversed process
given by $P^b_{ji}=\mu_i P_{ij}/\mu_j$.
\item Compute $\hat{\mu}(j)=\sum_{i\in S} q^\bwd_j(i)\mu(i)$,
  which is the invariant measure of the MSM
\item Construct the MSM transition matrix $\hat{P}$ according to
  \begin{align}
    \label{eq:msm-tmatrix-00}
    \begin{split}      
    \hat{\vect P}_{jk}
    = &
    \frac{1}{\hat{\mu}(j)}
    \langle (\vect P^b - \id) q^\bwd_j,q^\fwd_k \rangle_\mu,\qquad j\not= k, \\    %\label{eq:msm-tmatrix-01}
    \hat{\vect P}_{jj}
    =&
    1-\sum_{k\not=j} \hat{\vect P}_{jk}
    \end{split}
  \end{align}
where the inner product is defined by
$\langle u,v \rangle_\mu=\sum_{i\in S} u_i v_i \mu_i$.
\end{enumerate}

\noindent\textbf{Remark 1:}
Alternatively, the forward and
backward committors can be \emph{sampled} by means of the following procedure: The forward
committor $q^\fwd_j(i)$ is defined as the probability of visiting coreset
$C_j$ next conditioned on being at state $i$.  The
backward committor $q^\bwd_j(i)$  is defined as the probability
of last coming from $C_j$ conditioned on being at state $i$.

% \subsection{Building the Markov State Model from the NEMD simulation}
\noindent\textbf{Remark 2:}
Sometimes, it is not easy to have an explicit expression for the committors, however, we
can still build the MSM by using the following procedure: Firstly compute the
matrixes $\hat T$ and $\hat M$ by
\begin{align}\label{eq:msm-ht}
  \hat M_{jk} &= P [\,h_{mT}(C_k) < h_{mT}(\cup_{l\neq k}C_l) \,\vert\, \hat x_{mT} = j\,],\\\label{eq:msm-hm}
  \hat T_{jk} &= P [\,h_{mT+T}(C_k) < h_{mT+T}(\cup_{l\neq k}C_l) \,\vert\, \hat x_{mT} = j\,],
\end{align}
where $\hat x_{mT}$ is milestone process corresponding to the NEMD trajectory $x_{mT}$ (notice here
only integral periods $mT$ along the NEMD trajectories are used for building the milestone process).
In Eq.~\eqref{eq:msm-ht} and \eqref{eq:msm-hm}, the time parameterized first hitting time of  set $A$ is defined by:
\begin{align}
  h_{t}(A) = \inf_{s\geq t}\{ s : x_s \in A \}.
\end{align}
It can be shown that (see Appendix~\ref{sec:app-prove} for details):
\begin{align}\label{eq:msm-ht-1}
  \hat T_{jk} &= \frac{\langle q_j^\bwd, P q_k^\fwd \rangle_\mu}{\hat \mu(j)},\\\label{eq:msm-hm-1}
  \hat M_{jk} &= \frac{\langle q_j^\bwd, q_k^\fwd \rangle_\mu}{\hat \mu(j)}.
\end{align}
% \recheck{We may need to write why do these formula works, because in literature it is only available for reversible processes.}
Therefore we have
\begin{align}\label{eq:msm-tmp26}
  \hat T_{ij} - \hat M_{ij}
  = \frac{\langle q_j^\bwd, P q_k^\fwd \rangle_\mu}{\hat \mu(j)}
  - \frac{\langle q_j^\bwd,  q_k^\fwd \rangle_\mu}{\hat \mu(j)}
  = \frac{\langle (P^b - \id) q_j^\bwd, q_k^\fwd \rangle_\mu}{\hat \mu(j)}
  = \hat P_{jk}, \quad j\neq k
\end{align}
By Eq.~\eqref{eq:msm-ht} and \eqref{eq:msm-hm}, we have $\sum_i\hat M_{ij} = \sum_i\hat T_{ij} = 1$, then
$\sum_k(\hat M_{jk}- \hat T_{jk}) = 0$. By the second line of \eqref{eq:msm-tmatrix-00}, $\sum_k\hat P_{jk} = 1$, so using \eqref{eq:msm-tmp26} we have
$\hat T_{jj} - \hat M_{jj} + 1 = \hat P_{jj}$.
In the matrix expression the MSM transition matrix $\hat P$ is given by
\begin{align}\label{eq:msm-tmatrix-10}
  \hat P = \hat T - \hat M + \id
\end{align}
% Given coresets $\{C_1, \cdots, C_k\}$, the procedure \eqref{eq:msm-ht}--\eqref{eq:msm-tmatrix-10}
% If assuming that we have the coresets $\{C_1, \cdots, C_k\}$, no matter how they are identified,
In constrast to Eq.~\eqref{eq:msm-tmatrix-00}, which needs the intermediate spacial and
temporal discretization (i.e.~the Floquet transition matrix $P$), 
Eq.~\eqref{eq:msm-ht}, \eqref{eq:msm-hm} and \eqref{eq:msm-tmatrix-10} allows a direct derivation of the MSM from the original NEMD
trajectories, which substantially simplified the MSM building.
However, in the present paper, we present both the approachs,
because the former contains more information regarding the original dynamics in $P$ and $L(t)$ than in $\hat P$.
Moreover, the coreset identification may need a good spacial discretization to the original NEMD trajectories, which is
usually consisten with that used to go from $\ml(T)$ to $L(t)$. In the end, the MSM
built from both approachs should be consistent, taking no account of the statistical uncertainty in the samplings.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Numerical example:
  Alanine dipeptide under oscillatory electric field}
\label{sec:alanine}

We know that --in theory-- whenever the spatial discretization is fine enough, the Markov jump
process $X_t$ associated with the Master equation \eqref{eq:disc-master} is a good approximation to the original
MD process $x_t$ governed by \eqref{eq:disc-1}.  In practice, however, it is difficult to predict
how many discrete sets we need to be fine enough. Moreover, since the
total dimension of $x_t$ is $3N$ ($N$ being the number of atoms), it is prohibitive to do a really fine discretization
over all DOFs for most systems of practical interest.

One possible way to define appropriate discretization sets is firstly to find a few collective
variables, and then to discretize these collective variables as finely as needed either by uniform or adaptive
discretization~\cite{chodera2007automatic, prinz2011markov}.
% This process also suggests that the choice of the lag-time should be 
% shorter than the dominant implied timescale so that they can be resolved,
% and be longer than the fast time-scales to relax the unresolved dynamics
% within the discretized sets.
However, it is difficult to give a general answer in prior regarding
how to choose the collect variables and how fine their discretization should be.
For large or high dimensional systems, these questions usually become non-trivial. 

\begin{figure}
  \centering
  \includegraphics[width=0.3\textwidth]{fig/confs/c-2.eps}
  \caption{A schematic plot of the alanine dipeptide molecule and the dihedral angles $\phi$ and $\psi$.}
  \label{fig:tmp1}
\end{figure}


To illustrate how the discretization works in practice we take the alanine dipeptide system under an oscillatory EF,
as an example, the NEMD simulation of which was
extensively studied in Ref.~\cite{wang2014exploring}.
The system was simulated in a $2.7\times 2.7\times 2.7$~$\textrm{nm}^3$ periodic simulation
region, with one alanine dipeptide molecules described by the CHARMM27 force field~\cite{foloppe2000all} dissolved in 641 TIP3P water molecules~\cite{jorgensen1983comparison}.
The grid-based energy correction map (CMAP)~\cite{mackerell2004extending} was used
to correct the backbone dihedral angle energies.
All simulations were performed by a home-modified
Gromacs~4.6.5~\cite{pronk2013gromacs} with CHARMM27 force field implemented~\cite{bjelkmar2010implementation}.
The alanine dipeptide was put into the local thermostating
environment, with a spherical dynamical region of radius~1.0~nm
centered at the alpha-carbon.
The Langevin thermostat with target temperature $\mathcal T = 300$~K
and time-scale $\tau_T = 0.1$~ps was
coupled to the thermostated region.
The whole system was coupled to the Parrinello-Rahman barostat~\cite{parrinello1981polymorphic} (in standard Gromacs implementation) with $\tau_P = 2.0$~ps to
keep the system at 1~Bar. The non-equilibirium trajectories
were integrated by the Leap-frog scheme with a time-step of 0.002~ps.
The short-range van der Waals interactions were cut-off at 1.00~nm, and were smoothed from
0.95~nm to 1.00~nm by the ``\texttt{shift}'' method provide by Gromacs.
The energy conserving 
Particle Mesh Ewald (PME)~\cite{darden1993pme, essmann1995spm} method (``\texttt{pme-switch}'') was
used to compute the long-range electrostatic interaction,
with the same real-space cut-off radius as the van der Waals interactoins,
and the Gromacs default Fourier spacing of 0.12~nm.
The splitting
parameter optimized with respect to the electrostatic force computing
accuracy by Gromacs tool \texttt{g\char`_pme\char`_error}~\cite{wang2010optimizing}.
The neighbor list was updated every 5 time-steps with a list-building radius 1.20~nm.
All hydrogen involving covalent bonds were constrained by the LINCS algorithm~\cite{hess1997lincs}, except the water molecules that were constrained by the SETTLE algorithm~\cite{miyamoto2004settle}.
The whole system was driven by a periodic electric field
$E(t) = E_0\sin(2\pi t/T)$ and $D(x) = (1,0,0)^T$
with intensity of the field being $E_0 = 1.0$~V/nm and period being
$T = 10$~ps.
The 20,000 branching trajectories were simulated from 20,000
initial configurations that sample the equilibrium distribution.
% \redc{Write a lot of details on NEMD.}
The equilibrium configurations were prepared by an equilibrium MD simulation
of $10^6$~ps long, along which the snapshots were saved every 50~ps.
% In the
% equilibrium simulation the system was coupled to a global Langevin thermostat
% with coupling time-scale $\tau_T = 0.5$~ps.
The branching
trajectories were each 4000~ps long, and the system reached
non-equilibrium quasi-stationary state in roughly 300~ps.


For this periodically driven molecular system we will first show how to choose an appropriately fine discretization. After validating this discretization we will consider
the discretized dynamics generated by the Floquet transition matrix $\vect P$
in comparison to the original NEMD simulation. Finally we will coarse grain this description further by constructiion of a $3$ state Markov State Model that is able to describe the long-term kinetics of the system correctly. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spatial discretization}

We choose the
two dihedral angles $\phi$ and $\psi$ as collective variables (see
Fig.~\ref{fig:tmp1}), and the discretization is a uniform partition of
the $\phi$--$\psi$ plane. We denote the number of discretization intervals on each
dihedral by $K$, then we get $K^2$ discretization sets 
$\{\Omega_i\},\ i\in S = \{1,\cdots,K^2\}$.

Based on a given spatial discretization we can aggregate the transition matrix $\vect P=\myphi^T(T)$ just by counting the transition behavior of MD trajectories 
\[
\vect P_{ij}=\prob\left(\vect x_T=j\mid \vect x_0=i \right).
\]
However, $\vect P$ allows to approximate the original dynamics on multiples $mT$ of the period only. In order to have a time-continuos description we need the generator $L(t)$ of the Master equation. 
If the discretization is fine enough one possible approximation to $L(t)$ is via
the following forward finite difference scheme:
\begin{align}
  \label{eqn:tmp4}
  L_{ij}(t) \approx \frac{1}{\tau}
  \,[\, \prob (\vect x_{t+\tau} = i \vert \vect x_{t} = j) - \delta_{ij} \,],
  \quad i,j\in S
\end{align}
and $\tau$ is an appropriate small enough lag-time.
In the following 
we investigate the discretization
quality with respect to  the choice of $K$ and  lag-time $\tau$.





\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{fig/t010/discrete/fig-cg-prob.eps}  
  \caption{Time-dependent probability $\mathbb
    P\big(\phi\in[0,180), \psi\in [0,180)\big)$.  The brute force NEMD simulation is compared with different
    spatial discretization methods. The red shadow region indicates the
    statistical uncertainty of the NEMD simulation.}
  \label{fig:tmp2}
\end{figure}

We estimate the discretized generator $L(t), \ t\in[0,T)$
from NEMD trajectories generated by $\ml(t)$ in different time intervals $[t_1,
t_2]$.
Whenever the discretization is fine enough the discretized dynamics approximates the original
dynamics well, and the time-periodic generator $L(t)$ should not depend on the choice of the interval $[t_1,t_2]$ in the estimation procedure (\ref{eqn:tmp4}), provided that the initial state of the system
is not very far from the stationary state at long-time limit.
Therefore, this is an indicator for calibrating the discretization quality.
We compute $L(t)$ by two discretizations $K=2$ and $K=20$, and two
choices of time intervals $[0, 80]$~ps and $[320, 400]$~ps, and then
compare the time-dependent probability $\prob\big(\phi_t\in[0,180), \psi_t\in [0,180)\big)$
with the (brute force) NEMD result in Fig.~\ref{fig:tmp2} using a lag-time $\tau=0.5$~ps.
Using $K=2$ the dynamics depends on the time interval used for
calculating the generator: using time interval $[0, 80]$~ps the discretized
dynamics deviates from the NEMD result,
while using time interval $[320, 400]$~ps the discretized dynamics can only
reproduces the NEMD result after 300~ps.  This therefore indicates poor 
approximations to the original dynamics with $K=2$. The reason is that the
discretization with $K=2$ is too coarse so that the dynamics cannot be fully
equilibriated within the lag-time $\tau$ in each discretized set,
therefore, the discretization presents state dependency.  For
$K=20$, the discretized dynamics does not depend on the time interval of
calculating the generator, and is consistent with the
NEMD simulation within the error bar. Therefore, throughout this paper we use $K=20$
to discretize  the dihedral angle space of alanine dipeptide.
%For a good statistical accuracy, if not stated otherwise,
%we will use the full trajectories, i.e.~a time interval of
%$[0,4000]$~ps for estimating the discretized generator $L(t)$.


\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{fig/t010/discrete/fig-cg-prob-tau.eps}  
  \caption{Time-dependent probability $\mathbb
    P\big(\phi\in[0,180), \psi\in [0,180)\big)$.  The NEMD simulation is compared with the Master equation using generators discretized with $K=20$ and different lag time $\tau$. The red shadow region indicates the
    statistical uncertainty of the NEMD simulation.}
  \label{fig:tmp3}
\end{figure}

Next we discuss the effect of the lag time $\tau$ on the estimation of the generator. Therefore, we consider 
different choices of $\tau$ (0.5, 1.0, 2.0 and 5.0~ps)
(see Fig.~\ref{fig:tmp3}), all based on the identical dihedral angle discretization using $K=20$.
It is clear that when the lag-time is close to the period (10~ps), the
discretized dynamics cannot resolve the probability change within a
period. However, it is surprising  that even quite large lag-times are able to capture the
the overall long time behavior of the original dynamics.
We observe no significant difference between $\tau=0.5$ and
$\tau=1.0$~ps, which means the discretized dynamics is not very sensitive
to the choice of $\tau$.
Therefore, throughout this paper $\tau=0.5$~ps will be used.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Quasi-stationary distribution $\mymu$}


\begin{figure}
  \centering  
  \includegraphics[width=0.4\textwidth]{fig/t010/cluster.marco.3.steadyDist//fig-dist.eps}
  % \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-dist-msm.eps}
  \includegraphics[width=0.4\textwidth]{fig/t010/cluster.marco.3/fig-floquet-vec-1.eps}
  \caption{The color scale plot of the logarithmic quasi-stationary distribution $\mymu$
    of (a) the NEMD  and (b)
    the Floquet matrix $\vect P=\myphi^T(T)$.
  }
  \label{fig:num-1}
\end{figure}

After having validated the fine-scale spatial discretization 
we will now consider the time-homogeneous process $\tilde X_{m}$ generated by
the Floquet transition matrix $P = \Phi^T(T)$, and investigate whether it
reproduces the properties of the original  non-equilibrium process $x_t$.
In this context, only the configurations at the  integral periods $mT$ along the original process
are taken into consider.

An important check is the consistency between the
stationary probability density of $\Phi(T)$ (i.e.~the leading eigenvector $\mymu$) and that 
estimated form the original NEMD simulation,
% along which only integral periods $mT$ are considered:
\begin{align}
  \label{eq:num-tmp1}
  \rho_{\textrm{st}}(\phi,\psi) = \lim_{m\rightarrow\infty} \rho (\phi,\psi,mT),
\end{align}
On each NEMD branching trajectory the initial 320~ps is discarded and
the rest of the trajectory in time interval $[320,4000]$~ps is used to estimate
the quasi-stationary probability distribution $\rho_{\textrm{st}}$. 
$\myphi(T)$ is computed as described above, and then $\mymu$ is computed as its leading eigenvector. In order to make it comparable to the free energy in the equilibrium case, we take
the logarithm of the distributions, i.e.~$F_{\textrm{st}}(\phi,\psi)=
-k_B\mathcal T\log \rho_{\textrm{st}}(\phi,\psi)$
for NEMD and $F_{\textrm{st}}(\phi,\psi)=
-k_B\mathcal T\log \mu(\phi,\psi)$ for $\Phi(T)$, where $k_B$ is the
Boltzmann constant and $\mathcal T$ is the temperature of the system.
% Under the aformentioned discretization, the stationary distribution is
% defined for the each bin of the dihedral angle space, i.e.~$F_{pq} =
% \int_{ph}^{(p+1)h}d\phi\int_{qh}^{(q+1)h}d\psi
% F_{\textrm{st}}(\phi,\psi), \ 0\leq p,q<K-1$, where $h = 360/K$ being
% the size of the bin, $p$ and $q$ here being the bin indexes.
The
results are  compared in Fig.~\ref{fig:num-1}. A good consistency between
the  NEMD simulation and 
$\Phi(T)$ is observed.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Core set identification}

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth]{fig/t010/cluster.marco.3/fig-cluster.eps}
  \caption{The coreset identification. Different colors indicate different core sets: $C_{\confaa}$ (green), $C_\beta$ (yellow) and $C_{\confc}$ (red).
    The blue color indicates the transition region $C$ that does not belong to one of the core sets.}
  \label{fig:cluster}
\end{figure}

The procedure for identifying good metastable core sets of the irreversible Markov process associated with $\vect P$ is described in detail in Ref.~\cite{sarich2014utilizing}; here we just provide the fundamental idea behind it: If  strong metastable sets $C_j$, $j=1,\ldots,k$ exist they should have one main property: When starting from a state in $C_i$ the expected hitting time of a state in $C_i$ should be much shorter than that of any state in one of the other sets $C_j$, $j\not=i$; in fact, the hitting time distribution should exhibit roughly constant levels in each set $C_j$ and should vary significantly in the transition region $C=\Omega\setminus\cup_j C_j$ between the metastable sets. If starting from some randomly chosen initial states, one thus can identify the metastable core sets and the transition region by analyzing the hitting time distributions. This procedure is similar to the procedures used for reversible processes \cite{PCCAplus,A19-1,prinz2011markov} but utilizes hitting time distributions instead of any eigenvector information.

The metastable core sets identified by this procedure based on the estimate of $\vect P$ are illustrated in Fig.~\ref{fig:cluster} and denoted by $C_{\confaa}$ (yellow), $C_\beta$ (red) and $C_{\confc}$ (green). They correspond to the centers of the wells in the free energy landscapes shown in Fig.~\ref{fig:num-1} and to the
right-handed alpha-helix, beta-sheet and left-handed alpha-helix conformations of the peptide, respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{First mean hitting times}
\label{sec:alanine-fmht}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3.fht/fig-fht-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3.fht/fig-fht-msm-1.eps}\\
  \vskip -.5cm
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3.fht/fig-fht-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3.fht/fig-fht-msm-2.eps}\\
  \vskip -.5cm
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3.fht/fig-fht-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3.fht/fig-fht-msm-3.eps}\\
  \caption{Comparisons of the first mean hitting time (FMHT) based on NEMD
    simulation (first column) and discretized dynamics (second column).  From top
    to bottom the first mean hitting times to the core sets $C_{\confaa}$, $C_{\beta}$,
    and $C_{\confc}$ are shown, respectively}
  \label{fig:num-6}
\end{figure}

The first mean hitting time as a function of the dihedral angles $(\phi,\psi)$,
is defined by the expected first time needed for hitting a certain core set $C_j$,
$j\in\{\alpha_R,\beta,\alpha_L\}$ conditioned on starting from the
conformation $(\phi,\psi)$, more exactly from equilibirum conformations $(\phi,\psi)\in\Omega_i$.  Since the largest first mean hitting
time (starting from states in coreset $\confaa$ and hitting $\confc$) is longer than
600~ps the results will be biased if we use the NEMD trajectories of length 4000~ps for brute force Monte Carlo estimation of the hitting time. 
Therefore, we base our Monte Carlo estimate on 100 NEMD
trajectories of $2\times 10^5$~ps instead. For comparison we compute the first mean hitting
time of the discretized dynamics via its transition matrix $\vect P$: the first mean hitting time $h_C(i)$ of core set $C$ starting in $\Omega_i$ can  be computed by means of solving the linear problem \cite{A19-31}
\[
(\vect P-\id) h_C(i) = -1,\qquad \mathrm{if} \, C\cap \Omega_i=\emptyset.
\] 
The resulting first mean hitting times are presented in Fig.~\ref{fig:num-6}.  The
good consistency between the NEMD and the discretized Markov process
$\tilde X_{m}$ indicates a good approximation quality.
One should note that the NEMD estimate of the first mean hitting time is subject to statistical sampling errors while the first mean hitting times $h_C$ only contain the statistical errors coming from the estimation of $\vect P$. 
Thus, using $P$ helps in calculating the observables
in a smoother  manner (less statistical error, no additional sampling).
Additionally, the computational cost of the
discretized process, if the cost for estimating $\Phi(T)$ is not included, is
essentially smaller than NEMD:
the computation of $h_C$ is an issue of miiliseconds on a laptop, while the
NEMD trajectories took $1.6\times 10^4$ core hours for Intel Xeon E5-4650 CPUs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Forward and backward committors}
\label{sec:alanine-committor}
\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-fw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-bw-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-diff-1.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-fw-msm-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-bw-msm-1.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-diff-msm-1.eps}
  \caption{The forward $q^\fwd_{\confc}$ and backward committors
    $q^\bwd_{\confc}$ computed by the discretized dynamics (second row) and NEMD simulations (first
    row).}
  \label{fig:num-3}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-fw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-bw-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-diff-2.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-fw-msm-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-bw-msm-2.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-diff-msm-2.eps}
  \caption{The forward $q^\fwd_{\confaa}$ and backward
    $q^\bwd_{\confaa}$ committors computed by discretized dynamics (second row) and NEMD
    simulations (first row).}
  \label{fig:num-4}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-fw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-bw-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-diff-3.eps}\\
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-fw-msm-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-bw-msm-3.eps}
  \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-commitor-diff-msm-3.eps}
  \caption{The forward $q^\fwd_{\beta}$ and backward $q^\bwd_{\beta}$
    committors computed by discretized dynamics (second row) and  NEMD
    simulations (first row).}
  \label{fig:num-5}
\end{figure}


Committors are very important statistical properties of Markov processes \cite{PrinzHeldSmithNoe_Committorprep,PNAS09}, and play
an important role in MSM building \cite{A19-31,A19-29,djurdjevac2010markov} (see below), therefore, it is worth
checking if the discretized process $\tilde X_m$ reproduces the NEMD committors.
The forward committor $q^\fwd_i(\phi,\psi)$ of a coreset $C_i,\
i\in\{\confaa, \beta, \confc\}$ is defined as the probability of
visiting coreset $C_i$ next conditioned on starting at conformation
$(\phi,\psi)$.  The backward committor $q^\bwd_i(\phi,\psi)$ of a
coreset $C_i,\ i\in\{\confaa, \beta, \confc\}$ is defined as the
probability of last coming from $C_i$ conditioned on having arrived presently at
configuration $(\phi,\psi)$.
For reversible Markov processes, the
forward and backward committors are identical, however, it is in
general not the case for irreversible processes.
The committors estimated from NEMD simulations ($20000$ trajectories $4000$~ps each) are compared with
those computed from $P$ by means of solving the linear equations (\ref{qfwd}) and (\ref{qbwd}).
Fig.~\ref{fig:num-3}--\ref{fig:num-5} presents both
committors as well as their difference corresponding to different core sets.
The committors of the discretized process are in good consistency with those of
the NEMD simulations. The non-zero values in the committor differences
indicate that the NEMD process, projected on the discretized
dihedral angle space, is irreversible, and
the discretized process is able to correctly describe this irreversiblity.
In addition, and subsequently of central importance, the accurate reproduction of the committors indicates it is reasonable to build the 
MSM out of the committors of the  discretized process.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{MSM building and validation}

Following the process described in Sec.~\ref{sec:build-msm}, we are able to build a 
three state MSM for the externally driven alanine dipeptide system,
where the quasi-stationary probability distribution $\mu$, the three core sets, and the forward and backward committors are
estimated as described above, and the MSM transition matrix $\hat P$ is then evaluated using Eq.~\eqref{eq:msm-tmatrix-00}.
Alternatively, the MSM  transition matrix $\hat P$ is calculated directly from the NEMD trajectories by Eq.~\eqref{eq:msm-tmatrix-10}.
The leading eigenvalues of $P=\myphi^T(T)$ are compared with those of $\hat P$ in
Tab.~\ref{tab:tmp1}.
Without surprising, the two approaches for MSM building are consitent.
The MSM is able to accurately reproduce
the largest non-trivial eigenvalue, which means a precise reproduction
of the longest non-trivial implied time-scale. The accuracy of the second non-trivial
time-scale is not as good as the first, but is still acceptable. The reason
for the lower accuracy is that
the corresponding time scale is 26.5~ps (calculated by $-T/\log(\lambda_2)$),
which is NOT significantly longer than the temporal resolution given by the period $T=10$~ps of the external driving force.
It is worth noting that although the discretized process $\tilde X_m$ is irreversible,
the MSM built out of it is almost reversible:
The magnitude of the anti-symmetric part of the
matrix $\textrm{diag}(\hat \mu)\cdot \hat P$ is only of order $10^{-4}$.

\begin{table}
  \centering
  \caption{
    Comparison of second and third eigenvalues of $\vect P$ and $3\times 3$ MSM transition matrix $\hat{P}$ from two approaches.
  }
  \begin{tabular*}{0.5\textwidth}{@{\extracolsep{\fill}}cc rrr}\hline\hline
      & method &  $\lambda_2$ & $\lambda_3$ & $\lambda_4$ \\\hline
    $P$         & --         &0.907  &0.686 & 0.553       \\
    $\hat P$    &\eqref{eq:msm-tmatrix-00} & 0.911  &0.724 & --       \\
    $\hat P$    &\eqref{eq:msm-tmatrix-10} & 0.909  &0.712 & --       \\
    \hline\hline
  \end{tabular*}
  \label{tab:tmp1}
\end{table}

% \begin{figure}
%   \centering
%   \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-eig-vec-2.eps}
%   \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-eig-vec-3.eps}
%   \includegraphics[width=0.23\textwidth]{fig/t010/cluster.marco.3/fig-eig-vec-4.eps}\\
%   \caption{The eigenfunctions of $P$.}
%   \label{fig:num-6}
% \end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.85\textwidth]{fig/t010/cluster.marco.3/fig-coreset-prob.eps}
  \caption{Comparison of NEMD and MSM long-term kinetics of alanine dipeptide in an oscillatory electrc field. The plots show the time-dependent probability $p_j=\hat p(j,t)$ to be assigned to core set $C_j$ (corresponding to the observable $\mathcal A$ given in (\ref{A}) with $\alpha_j=1$ and $\alpha_i=0$ for $i\not= j$). Solid lines are from brute force NEMD simulations, while the dashed lines are from our MSM.}
  \label{fig:num-7}
\end{figure}

In fact, $\hat{P}$ can be considered as the fingerprint of the long-term kinetics (cf. \cite{A19-39,PrinzKellerNoe_PCCP11_Perspective}) of alanine dipeptide in an oscillatory electric field.
In order to provide further validation of this statement, we study  time-dependent expectation values of
the form
\begin{align}
  \mathcal A(t) = \langle A(i)\rangle_t = \sum_{i\in S} A(i) p(i,t),
\end{align}
where $p_i(t)=\prob(X_t=i)$ denotes the probability to be in set $\Omega_i$ at time $t$ as governed by the Master equation, and the observable $\mathcal A$ is spanned by the backward
committors, i.e.,
\begin{align}\label{A}
  A(i) = \sum_{l=1}^k \alpha_l q^\bwd_l(i).
\end{align}
Then
\begin{align}\nonumber
  \mathcal A(t) &=
  \sum_{i\in S} \sum_{l=1}^k \alpha_l q^\bwd_l(i)  p(i,t)=\sum_{i\in S} \sum_{l=1}^k \alpha_l \prob (\hat X_t = l \vert X_t = i) \prob (X_t = i) \\
  & =
  \sum_{i\in S} \sum_{l=1}^k \alpha_l \prob (\hat X_t = l ,X_t = i)  =
  \sum_{l=1}^k \alpha_l \prob (\hat X_t = l) 
 =
   \sum_{l=1}^k \alpha_l \,\hat p (l, t), \label{eq:num-28}
\end{align}
where the time-dependent probability $\hat{p}(i,t)$ of being assigned to MSM macrostate $i$ at time $t$ can be computed  by means of the MSM via simple matrix multiplications:
\begin{align}\label{eq:num-29}
  \hat p(i, t+T) = \sum_{j\in S} \hat p(j,t)\hat P_{ji}.
\end{align}
In Fig.~\ref{fig:num-7} we compare the numerical calculation of $\hat p (l, mT), \ m\in\mathbb N$ from NEMD and MSM calculations.
In the NEMD case, the backward committor and the probability density $\hat p (l, mT) = \sum_{i\in S}  q^\bwd_l(i)  p(i,mT) $
are estimated directly from the
NEMD trajectories. For the MSM, the projection of the initial probability is applied, $\hat p (l, 0) = \sum_{i\in S}  q^\bwd_l(i)  p(i,0) $, then
the time-dependent probability at $mT$ is generated by Eq.~\eqref{eq:num-29}, i.e., by simple matrix multiplication. The agreement is almost perfect.
% The projected probability, e.g.~$\hat p (l', mT)$ is calculated
% by Eq.~\eqref{eq:num-28} letting $\alpha_l = \delta_{l'l}$.


\section{Concluding remarks and discussions}

\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{fig/flowchart/flowchart.eps}
  \caption{The flowchart of this work. A lighter color indicates
  a ``more coarse'' approximation to the original NEMD dynamics.}
  \label{fig:flowchart}
\end{figure}

In this paper we developped methods of building MSM for a periodically driven
non-equilibrium system. By a numerical example
of the alanine dipeptide under periodically oscillatory EF,
the methods are shown  to be
valid and be able to capture the long-time behavior of the original
non-equilibrium dynamics. We have provided and verified two equivalent
pathways of building MSM, as is shown by the two branches in
Fig.~\ref{fig:flowchart}.

The the key steps of the first pathway are
summarized as following:
\begin{enumerate}
\item By a fine discretization of the molecular configuration space,
  the original NEMD dynamics is discretized into a (in principle)
  time-continuous \recheck{Markov} jump process with a time-dependent generator $L(t)$.
  If the discretization is good enough, then the discretized
  dynamics is expected to reproduce the original dynamics.
  In principle most of the discretiztion methods for the
  equilibirum case can be generalized to  non-equilibrium without
  substantial difficulty, however,
  we have not discussed which discretiztion method is the best choice,
  since it is out of the scope of the present work.
  \recheck{It should be noticed that
    we assume the jump process is Markovian, althogh in
    general it is not true. However, if (1) the system present time-scale
    seperation; (2) the spatial discretiztion is fine enough; (3)
    we approximately consider a discretizted time
    (can be very fine, and in computer the molecular configurations are
    saved at discretizted time steps)
    by lag-time $\tau$, so that within the lag-time
    the fast dynamics of the system is fully relaxed; then
    the Markovianity is a good assumption for the discretizted dynamics.
  }
  We show that, by numerical example, a uniform $20\times20$ discretiztion 
  over the dihedral angles $\phi$--$\psi$ space is a good choice for
  alanine dipeptide.
  In the tests, the state independency in computing $L(t)$
  is used as an indicator for
  the quality of the discretiztion.
\item By the Floquet thoerem, the time-inhomogeneous process generated
  by $L(t)$ is temporally discretized in to a time-homogeneous,
  but not necessarily reversible, jump process that has a transition
  matrix denoted by $P$. This temporal discretiztion only  considers
  the state of the system at integral periods, therefore all information
  within the period is not preserved. This is, however, not a serious
  problem whenever the long-time hehaviors of the system is of interst, and
  their corresponding time-scales are significantly longer than one period.
  The advantage of this discretiztion
  is also obvious: All well-developed theories and computational tools
  for time-homogeneous Markov processes
  can be directly appled. In the
  alanine dipeptide system, we compare
  the the quasi-stationary probability,
  first mean hitting time, and the forward and backward committors
  of the discretized dynamics with those computed directly from the
  NEMD simulation. An almost perfect consistency 
  indicates a good approximation quality of the discretized dynamics.
\item From the disretized dynamics, building the MSM is straightforward
  by using Eq.~\eqref{eq:msm-tmatrix-00} and a set of coresets.
  Numerical results shows that a 3-state MSM can reporduce the leading
  non-trivial eigenvalue with very good accuracy, while the second
  non-trivial eigenvalue with acceptable accuracy. The lower accuracy
  regarding the second non-trivial eigenvalue may be due to the fact that
  the second slowest time-scale is not significantly longer than the
  period. Using this three state MSM, we can also reproduce, with
  almost perfect accuracy, the 
  time-evolution of the metastable state
  pobabilities from equilibirum (no external driven)
  to the non-equilibrium quasi-stationary state.
\end{enumerate}

The right branch in Fig.~\ref{fig:flowchart} presents a
equivalent, and seemingly
much simpler alternative to the left branch, provided the
coresets are known. Neverthless, in pactice, identifying
the coresets is not a trivial task, especially for the
non-equilibrium molecular systems.
Therefore, a good discretization is  usually a must for computing the coreset.
For example, in the present work, we computed the coresets by
finding the roughly constant levels of the hitting time distribution.
This method only works for the discretized dynamics $P$, and its continuous
counterpart is still an open question.

In this paper, we mainly focus on the methodology development for MSM
building in non-equilibrium systems. It is worth noting that the
numerical example itself presenst interesting phenomena: under the
oscillatory EF, the population of the left-handed $\alpha$-helix
significantly increases with respect to the equilibirum population
(see also the discussions in Ref.~\cite{wang2014exploring}),
and the leading time-scale is much shorter than the equilibirum case.
It is in principle possible to apply the non-equilibrium
linear response theory~\cite{wang2013linear} to build a MSM for the perturbed
non-equilibrium system with respect to original
non-equilibrium system
(the equilibirum counterpart is provided by Ref.~\cite{schutte2014markov}).
This makes possible the molecular design under
oscillatory EF, and could be used to answer the question like:
in order to achieve a certain population of  the left-handed $\alpha$-helix,
what kind of EF should be used to drive the system.
In this work, we have not investigated in this direction, however, it will
be treated in the future studies.



\appendix

\section{Reversibility of the original dynamics}
\label{sec:revs}

We consider the governing dynamics Eq.~\eqref{eq:disc-1}.
For simplicity we denote the force by $F(x_t,t) = -\nabla_x V(x_t)+ E(t)D(x_t) $.  We denote $\sigma =  \sqrt{2\beta^{-1}} $.
According to Girsanov, we have
\begin{align}
  \label{eq:tmp8}
  \frac{dp[x_t]}{dw[x_t]}  =
  \exp \bigg\{
  \frac 1{\sigma^2}\int_0^T F(x_t,t) dx_t -
  \frac1{2\sigma^2}\int_0^T F^2(x_t,t) dt
  \bigg\}
\end{align}
where $dp$ is the probability measure of trajectory $x_t$, while $dw$ is the
probability measure of the standard Wiener process $dx_t = \sigma dw_t$.
Assuming a discretization of the
stochastic process at time $0 < t_1 < t_2 < \cdots < t_N = T$, where
$t_i = iT / N$. We denote $x_i = x_{t_i}$, and $w_i = w_{t_i}$, then we have,
in the sense of Ito,
\begin{align}\label{eq:tmp9}
  \frac{dp[x_t]}{dw[x_t]}  \approx
  \exp\bigg\{\frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{i},t_{i})(x_{i+1} - x_i) -\frac1{2\sigma^2}\sum_{i=0}^{N-1}F^2(x_i,t_i)\dt\bigg\} 
\end{align}
Now, consider a conjugate trajectory $x^\dagger_t = x_{T-t}$ that starts at $x_T$, ends at $x_0$. The conjugate dynamics is driven by  $F^\dagger(x^\dagger_t,t) = F(x^\dagger_t, T-t)$.
Writing the Girsanov for the conjugate dynamics
\begin{align}\label{eq:dagger-0}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\ \nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},T - t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, T-t_i)]^2\dt\bigg\} \\\nonumber
  =\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x_{N-i},t_{N-i})(x_{N-i-1} - x_{N-i}) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x_{N-i},t_{N-i})]^2\dt\bigg\} \\
  = \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=N}^{1} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=N}^{1}F^2(x_i,t_i)\dt\bigg\}
\end{align}
% Therefore,
% \begin{align}\nonumber
%   \frac{dp[x^\dagger_t]}{dw[x^\dagger_t]}  =
%   \,&
%   \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]} \\\nonumber
%   \approx\,&
%   \exp\bigg\{
%   \frac1{\sigma^2}\sum_{i=0}^{N-1} F^\dagger(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
%   \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F^\dagger(x^\dagger_i,t_i)]^2\dt\bigg\} \\\nonumber
% \end{align}
Since it is obvious that $dw[x^\dagger_t] / dw[x_t] = 1$,
\begin{align}
  \label{eq:tmp10}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x_t]}
  \approx \,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=1}^{N} F(x_{i},t_{i})(x_{i-1} - x_i) -
  \frac1{2\sigma^2}\sum_{i=1}^{N}F^2(x_i,t_i)\dt\bigg\}
\end{align}
The difference between the single trajectory probabilities is
\begin{align}\label{eqn:tmp12}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
  -\frac1{\sigma^2}\sum_{i=1}^{N-1}
  \bigg[
  F(x_i,t_i)(x_{i+1} - x_{i}) + F(x_i,t_i)(x_{i} - x_{i-1})
  \bigg]
  \bigg\}
\end{align}
Assuming the smoothness of the external perturbation, consider the differentiation:
\begin{align}\nonumber
  F(x_{i},t_{i}) - F(x_{i-1},t_{i-1}) =
  &\,
  F(x_{i},t_{i}) - F(x_{i-1},t_{i}) + F(x_{i-1},t_{i}) -  F(x_{i-1},t_{i-1})\\\nonumber
  =&\,
  \nabla_x F(x_{i-1},t_{i})(x_i - x_{i-1}) + \mo(\dt) \\\label{eqn:tmp13}
  =&\,
  \nabla_x F(x_{i-1},t_{i-1})(x_i - x_{i-1}) + \mo(\dt)
\end{align}
The second order expansion w.r.t.~$x_i - x_{i-1}$ is of order $\dt$, so it is absorbed into $ \mo(\dt)$.
Then the \eqref{eqn:tmp12} becomes
\begin{align}\label{eqn:tmp14}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\sum_{i=0}^{N-1} F(x_i,t_i)(x_{i+1} - x_{i}) 
 -\frac1{\sigma^2}\sum_{i=0}^{N-1}\nabla_xF(x_i,t_i)(x_{i+1} - x_{i})^2
 \bigg\}
\end{align}
Using the identity
$  dt = (dw_t)^2 = {\sigma^{-2}} dx_t^2$,
Eq.~\eqref{eqn:tmp14} is written in the integral form
\begin{align}\label{eqn:tmp14-0}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  \approx&\,
  \exp\bigg\{
 -\frac2{\sigma^2}\int_0^T F(x_t,t) dx_t
 -\int_0^T\nabla_xF(x_t,t)dt
 \bigg\}  
\end{align}
One would not have the second integral on the exponent if the first integral of the exponent were defined in the sense of Stratonovich.

We notice that
\begin{align}\nonumber
  dV(x, t) = &\, \frac{\partial V}{\partial x} dx + \frac{\partial V}{\partial t} dt\\\nonumber
  =&\,
  \frac12 \sigma^2 \nabla^2_x V dt +  \nabla V dx_t + \frac{\partial V}{\partial t} dt \\
  =&\,
  -\frac12 \sigma^2 \nabla_x F dt -  F dx_t + \frac{\partial V}{\partial t} dt
\end{align}
Eq.~\eqref{eqn:tmp14-0} becomes
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \exp\bigg\{
  \frac2{\sigma^2}\bigg[
  V(x_T,T) - V(x_0,t_0) - \int_0^T\partial_tV(x_t,t)dt
  \bigg]
  \bigg\}
\end{align}
% According to the  Einstein relation, the temperature $\mathcal T = \sigma^2/2$, we denote $\beta = 1/{\mathcal T} = 2/\sigma^2$.
Take the limit of infinite small time interval, notice the equilibrium
invariant probability density with respect to potential $V(x,0)$ satisfies $\mymu(x) \propto e^{-\beta V(x,0)}$, and replace $\sigma^2$ by $2\beta^{-1}$,
\begin{align}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]}
  =&\,
  \frac{\mymu(x_0)}{\mymu(x_T)}\times
  \exp\bigg\{
  - \beta\int_0^T\partial_tV(x_t,t)dt
  \bigg\}
\end{align}

\subsection{Irreversibility of the periodical symmetrical dynamics}

In Eq.~\eqref{eq:dagger-0}, we assume the periodicity of the perturbation $F(x,t) = F(x,t+T)$, and the symmetry of the external perturbation, i.e.~$F(x, -t) = F(x, t)$, we have
\begin{align}
  \frac{dp^\dagger[x^\dagger_t]}{dw[x^\dagger_t]}  
  \approx\,&
  \exp\bigg\{
  \frac1{\sigma^2}\sum_{i=0}^{N-1} F(x^\dagger_{i},t_{i})(x^\dagger_{i+1} - x^\dagger_i) -
  \frac1{2\sigma^2}\sum_{i=0}^{N-1}[F(x^\dagger_i, t_i)]^2\dt\bigg\}  
\end{align}
By changing notation $x^\dagger$ back to $x$, and comparing with~\eqref{eq:tmp9}, the reversed dynamics is subject to the Eq.~\eqref{eq:disc-1},
i.e.~$dp^\dagger = dp$.
Therefore
\begin{align}\nonumber
  p(x_0,T\vert x_T,0)
  =&\,\int_{\mc\{x_T,0;x_0,T\}}
  dp[x^\dagger_t] \\\nonumber  
  =&\,
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\nonumber
  =&\,
  % \lim_{N\rightarrow\infty} 
  % \frac{1}{(2\pi\sigma^2\dt)^{(N-1)/2}} \int dx_{N-1}\cdots\int dx_{1}
  \int_{\mc\{x_0,0;x_T,T\}}
  \frac{  dp^\dagger[x^\dagger_t] }{ dp[x_t]} \cdot dp[x_t] \\\label{eqn:tmp18}
  = &\,
  \frac{\mu(x_0)}{\mu(x_T)}
  \int_{\mc\{x_0,0;x_T,T\}}
  \exp\bigg\{
  -\beta\int_0^T \partial_t V(x_t,t)dt 
  \bigg\} \cdot dp[x_t]
\end{align}
where $\mc\{x_0,0;x_T,T\}$ denotes all continuous trajectories starting at $x_0$ and ending at $x_T$.
If $\partial_t V = 0$, i.e.~equilibrium, we have
\begin{align}
  p(x_0,T\vert x_T,0)e^{-\beta V(x_T,T)} =  p(x_T,T\vert x_0,0) e^{-\beta V(x_0,0)},
\end{align}
which proves the reversibility of the equilibrium dynamics.
The term
\begin{align}
  W[x_t] = \int_0^T \partial_t V(x_t,t)dt
\end{align}
is the non-equilibrium work associated to all possible
the dynamics $x_t$ starting at $x_0$ and ending at $x_T$ (see e.g.~Ref.~\cite{seifert2012stochastic}).
Therefore Eq.~\eqref{eqn:tmp18} is the detailed Jarzynski relation.
% Now the problem becomes if we can write a nice form (e.g.~the difference of a state function measured at $x_T$ and $x_0$) for the non-equilibrium work.
Noticing that
\begin{align}
  \label{eq:tmp21}
  p(x_T,T\vert x_0,0) = \int_{\mc\{x_0,0;x_T,T\}}dp[x_t],
\end{align}
From Eq.~\eqref{eqn:tmp18} we have
\begin{align}
  \label{eq:tmp22}
  \frac{p(x_0,T\vert x_T,0)}{  p(x_T,T\vert x_0,0)  }
  =
  \frac{\mu(x_0)}{\mu(x_T)}
  \mathbb E_{x_0\rightarrow x_T} [e^{-\beta W}]
\end{align}
% Maybe we want a more symmetric form.
% The expectation value of the reversed dynamics reads,
% \begin{align}\nonumber
%   \mathbb E_{x^\dagger_0\rightarrow x^\dagger_T} [e^{-\beta W^\dagger}]
%   =\,&
%   \int_{\mc\{x^\dagger_0,0;x^\dagger_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x^\dagger_t,t)dt 
%   \bigg\} \cdot dp[x^\dagger_t]   \\\nonumber
%   =\,&
%   \int_{\mc\{x_0,0;x_T,T\}}
%   \exp\bigg\{
%   -\beta\int_0^T \partial_t V(x_{T-t},t)dt 
%   -\beta\int_0^T \partial_t V(x_{t},t)dt 
%   \bigg\}
%   \cdot dp[x_t]   \\  \nonumber
%   =\,&
%   \int_{\mc\{x_T,0;x_0,T\}}
%   \exp\bigg\{
%   \beta\int_0^T \partial_t V(x_t,t)dt 
%   \bigg\} \cdot dp[x_t]   \\
%   \label{eq:tmp23}
%   = \,&
%   \mathbb E_{x_0\rightarrow x_T} [e^{- 2\beta W}]  
% \end{align}
% Noticing that \eqref{eq:tmp22}  is true for the reversed dynamics, we have
% \begin{align}
%   \label{eq:24}
%   \frac{p(x_T,T\vert x_0,0)}{  p(x_0,T\vert x_T,0)  }
%   =
%   \frac{\mu(x_T)}{\mu(x_0)}
%   \mathbb E_{x_T\rightarrow x_0} [e^{\beta W}]  
% \end{align}


\section{Proves for Equations~\eqref{eq:msm-ht-1} and \eqref{eq:msm-hm-1} }
\label{sec:app-prove}

We firstly define $\hat q^\bwd_j (i) = P (X_t = i \vert \hat X_t =
j)$, and always assume $t = mT$. Then due to the Bayes' Theorem we have
\begin{align}
  \hat q^\bwd_j (i) =
  \frac{P (\hat X_t = j \vert X_t = i) P(X_t = i)}{ P(\hat X_t = j) } =
  \frac{q^\bwd_j(i) \mu(i)}{\hat \mu(j)}
\end{align}
Then
\begin{align*}
  P& [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) \,\vert\, \hat X_t = j\,]\\
  &=
  \sum_{i=1}^n
  \frac{P [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) , X_t = i, \hat X_t = j\,]}
  { P(\hat X_t = j )} \\
  &=
  \sum_{i=1}^n
  {P [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) \,\vert\, X_t = i, \hat X_t = j\,]}\,
  \hat q^\bwd_j(i) \\
  &=
  \sum_{i=1}^n
  {P [\,h_t(C_k) < h_t(\cup_{l\neq k} C_l) \,\vert\, X_t = i\,]}\,
  \hat q^\bwd_j(i)  \\
  &=
  \sum_{i=1}^n
  q^\fwd_k(i) \frac{q^\bwd_j(i) \mu(i)}{\hat \mu(i)} \\
  &=
  \frac{\langle q_j^\bwd, q_k^\fwd\rangle_\mu}{\hat \mu(j)}
\end{align*}
The third equation holds because of the Markovianity of the process $X_t$.
The fourth equation is due to the definition of the forward committor.
This proves Eq.~\eqref{eq:msm-ht-1}.
To prove Eq.~\eqref{eq:msm-hm-1}, we firstly need
\begin{align*}
  P & [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \,\vert\, X_t = i\,]\\
  &=
  \sum_{l=1}^n
  \frac{P [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l), X_{t+T} = l, X_t = i\,]}
  {X_t = i} \\
  &=
  \sum_{l=1}^n
  {P [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \vert X_{t+T} = l, X_t = i\,]}
  {P( X_{t+T} = l \vert X_t = i)}\\
  & =
  \sum_{l=1}^n
  {P [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \vert X_{t+T} = l\,]}
  {P( X_{t+T} = l \vert X_t = i)} \\
  &=
  \sum_{l=1}^n
  q^\fwd_k(l) P_{il}
\end{align*}
We used the Markovianity of $X_T$ at the third equation,
and the time-homogeneity at the fourth equation.
Therefore, following the same procedure proving Eq.~\eqref{eq:msm-ht-1}, we have
\begin{align*}
  P& [\,h_{t+T}(C_k) < h_{t+T}(\cup_{l\neq k} C_l) \,\vert\, \hat X_t = j\,]\\
  &=
  \sum_{i=1}^n\sum_{l=1}^n
  q^\fwd_k(l) P_{il}
  \frac{q^\bwd_j(i) \mu(i)}{\hat \mu(i)} \\
  &=
  \frac{\langle q_j^\bwd, P q_k^\fwd\rangle_\mu}{\hat \mu(j)}  
\end{align*}
This proves Eq.~\eqref{eq:msm-hm-1}.

\bibliography{ref}{}
\bibliographystyle{unsrt}



\end{document}
